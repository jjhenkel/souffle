---------------
synth_query
source_text_shuffle	start_line_shuffle	start_col_shuffle	end_line_shuffle	end_col_shuffle	gid_shuffle	source_text_call	start_line_call	start_col_call	end_line_call	end_col_call	gid_call
===============
10	12	40	12	42	-3653811976940513027	cross_val_score(rfc, X, Y, cv=10)	12	10	12	43	-2091019307916221133
10	16	16	16	18	-8868587980977213866	interact(f, x = 10)	16	0	16	19	2652916181399700620
10	17	78	17	80	3417690518024172708	NCBIWWW.qblast("blastn", "nr", fasta_string, hitlist_size=10)	17	20	17	81	2108388527464680519
10	20	26	20	28	3787518812814309136	setup_text_plots(fontsize=10, usetex=True)	20	0	20	42	6596831126661140257
10	25	32	25	34	-7997080588722313053	sns.distplot(control, bins=10)	25	5	25	35	2714666640376246070
10	26	49	26	51	6601346498412321850	sns.distplot(experimental, color='darkred', bins=10, ax=ax)	26	0	26	59	-6575019324331639243
10	30	40	30	42	7375817247293516719	model.recommend(users=None, k=10)	30	10	30	43	-5195084183981963085
10	35	32	35	34	-1160113828131104824	sns.distplot(control, bins=10)	35	5	35	35	-7692058730349025495
10	36	44	36	46	4338424438879072828	plt.plot(0, 0, 's', markerfacecolor='r', ms=10)	36	0	36	47	-4817389375054943487
10	36	49	36	51	8049745693120580406	sns.distplot(experimental, color='darkred', bins=10, ax=ax)	36	0	36	59	1319834367251616819
10	38	41	38	43	113946413180211221	KNeighborsClassifier(n_neighbors = 10)	38	6	38	44	1475935516268444566
10	39	35	39	37	-7491936659713210419	stats.expon.pdf(x, scale = 10)	39	8	39	38	-8608026304908746956
10	41	64	41	66	-5899222210805521250	model.query(wiki[wiki['name']=='Barack Obama'], label='name', k=10)	41	0	41	67	9004606706631290078
10	43	29	43	31	-5020740118887898363	np.random.randint(0, 5, size=10)	43	0	43	32	7404176109574200109
10	46	57	46	59	8848198087148727814	net.train( targetData, bal.T, epochs = 100, show = 10, goal =0.2)	46	6	46	71	-6743005386240515941
10	48	31	48	33	-8345606044841881402	ThisPCA(n_components=10)	48	10	48	34	4986050656972065772
10	52	49	52	51	8140425092013415257	titanic_df.hist(column="Fare",by="Survived",bins=10)	52	0	52	52	8015776213570571527
10	60	52	60	54	-9091790506137856408	yule_walker(x[:,j], order_max=10)	60	22	60	55	4802972224809051582
10	65	47	65	49	-737629565248134732	KNeighborsClassifier(n_neighbors=10)	65	14	65	50	6991063458082345683
10	67	37	67	39	2252003442767672281	plot_dist('run_modulation_dg', bins =10, plot_range=[-1,6],log=False)	67	0	67	69	7645918165590054440
10	67	53	67	55	5247028435792379438	RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)	67	4	67	72	4944537880148559078
10	72	63	72	65	600059437447772398	RandomizedSearchCV(model, paramDistribution, cv=10, scoring = 'precision', n_iter = 5)	72	15	72	101	2314207138524811725
10	73	17	73	19	6683467195041473177	fig.scatter(source=pca_src, x='x', y='y',\n            size=10, fill_alpha=0.9, line_alpha=0.5, line_color='black',\n            fill_color='color')	72	0	74	31	-2001428934515013859
10	74	37	74	39	4759851962602725471	HalfCauchy('sigma', beta=10, testval=1.)	74	12	74	52	-3568396619348609185
10	76	44	76	46	4808036969073660313	cv2.erode(th3,kernel,iterations = 10)	76	10	76	47	1933888805339631395
10	77	52	77	54	-5517498846868587238	cv2.dilate(erosion, kernel, iterations = 10)	77	11	77	55	-3549858279231079703
10	81	100	81	102	-4070174010189541084	get_lattice(H, keep_max_radii=True, border_correction=False, filter_percentile = 10)	81	19	81	103	6255649888209851521
10	84	50	84	52	-6360943498484463206	fig.colorbar(utility_surface, shrink=0.75, aspect=10)	84	0	84	53	-6703162041828458151
10	87	27	87	29	7774130859983290371	plt.ylabel('$\Theta$',size=10)	87	0	87	30	1571869038661483009
10	88	22	88	24	4592272884826891050	plt.xlabel('$x$',size=10)	88	0	88	25	6293361195275505730
10	93	62	93	64	-7407027695565487073	np.random.choice(np.arange(10000), size=10)	93	22	93	65	4669662378902844696
10	95	74	95	76	-8920137870158123925	datavis.animate(training_step, iterations=10000+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)	95	0	95	129	589201280056976940
10	95	99	95	101	7092142683915768356	get_lattice(H, keep_max_radii=True, border_correction=True, filter_percentile = 10)	95	19	95	102	-7446795532889840832
10	100	41	100	43	-7082379082399150566	df.hist(['Temperature','Humidity'], bins=10)	100	0	100	44	950751880627879883
10	101	42	101	44	9010099417954695310	GradientBoostingClassifier(learning_rate=0.005, n_estimators=250,\n                                max_depth=10, subsample=0.5,\n                                max_features=0.5)	100	6	102	49	6862921282232108663
10	103	38	103	40	1557589480133507038	plt.ylabel('Total injuries', fontsize=10)	103	0	103	41	3345576646075503728
10	104	25	104	27	-7475467488735432132	merge_predicted.sample(n=10)	104	0	104	28	-7100580560948628013
10	104	31	104	33	-3199146766009757057	plt.xlabel('Hour bin',fontsize=10)	104	0	104	34	-5067677842508057605
10	106	18	106	20	1404801139035115941	SLP(h_units=10)	106	6	106	21	-3192073045705939173
10	106	19	106	21	-6611125272253280476	sh.cell_value(rowx=10,colx = 0)	106	0	106	31	8541017035171007974
10	107	42	107	44	-3624778603142203443	stats.expon.pdf(x, loc=0, scale = 10)	107	8	107	45	-7820479375097189532
10	111	19	111	21	-9098894368273267480	interactive(f, a = 10, b = 20)	111	0	111	30	-8115307443564119381
10	111	58	111	60	6493395599985754732	model.fit(X_train, y_train, batch_size=128, epochs=10,\n          validation_split=0.2, callbacks=[checkpointer],\n          verbose=2, shuffle=True)	111	7	113	34	-1052891680331590484
10	113	77	113	79	1506645508513640544	ot_mapping_kernel.fit(xs,xt,mu=mu,eta=eta,sigma=sigma,bias=bias,numItermax = 10,verbose=True)	113	0	113	93	803245976098564532
10	114	53	114	55	7789102153894035232	train_test_split(X, y,\n                                        test_size=0.30,\n                                        random_state=10)	112	35	114	56	2680864737687506012
10	116	20	116	22	-8293737498607364074	KFold(n_splits=10, shuffle=True)	116	5	116	37	-2612747494700654347
10	116	23	116	25	-1837854412271126909	interactive(f, a = 10, b = 20)	116	4	116	34	8868400013529343130
10	117	38	117	40	-9154074432986697419	plt.ylabel('Total injuries', fontsize=10)	117	0	117	41	4401221243603951777
10	117	86	117	88	3725580548583457874	Circle(x=text_x - 0.1, y=text_y + 2, fill_color=Spectral6[i], size=10, line_color=None, fill_alpha=0.8)	117	19	117	122	4646149199085641666
10	118	27	118	29	-691524137281426888	plt.xlabel('Year',fontsize=10)	118	0	118	30	956575114158189748
10	121	64	121	66	4941813214189164712	plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)	121	0	121	67	-3934763009691706448
10	122	40	122	42	6975512630259737392	cross_val_score(rfc, X, Y, cv=10)	122	10	122	43	6181767449863847193
10	122	52	122	54	1129828703825349847	plt.yticks(range(len(list_fams)),list_fams,fontsize=10)	122	0	122	55	-4566556657368823657
10	132	37	132	39	3320447506836062555	HalfCauchy('sigma', beta=10, testval=1.)	132	12	132	52	1912089764023524771
10	133	61	133	63	-385252212122370816	axis.set_title('Arms Import vs. GDP \(per capita\)',fontsize=10)	133	0	133	64	4606737418004499009
10	134	44	134	46	-1876606965454722668	Normal('x', 1,sd=sigma, shape=10)	134	14	134	47	-6235328645696201551
10	134	57	134	59	6054626913606112113	axis.set_xlabel(result['IndicatorName'].iloc[0],fontsize=10)	134	0	134	60	4073769746895373061
10	135	55	135	57	-4262499031670382337	axis.set_ylabel(res2['IndicatorName'].iloc[0],fontsize=10)	135	0	135	58	-3660203632164416026
10	135	57	135	59	7439801515152339743	my_map.plot(x_expo, y_expo, '.', color='#ff0080', zorder=10)	135	0	135	60	-3456049874202145056
10	137	71	137	73	6422908436153878367	StratifiedShuffleSplit(train_y, n_iter=10, test_size=0.2,\n                                                       train_size=None, random_state=123)	137	32	138	89	-7420353396887594154
10	140	41	140	43	7595244895400669078	plt.ylabel("Number of injuries",fontsize=10)	140	0	140	44	1821388733080844967
10	141	30	141	32	-961803773732212134	plt.xlabel("Weekday",fontsize=10)	141	0	141	33	-8754414962719483573
10	144	73	144	75	8709902176617170877	model_tf_idf.query(wiki[wiki['name'] == 'Barack Obama'], label='name', k=10)	144	0	144	76	7450210269431793473
10	151	36	151	38	-1527425628341594910	CircosPlot(nodes, edges, radius=10, ax=ax, fig=fig)	151	4	151	55	1147966173282344886
10	157	64	157	66	2395364412141164559	plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)	157	0	157	67	5392588869502803694
10	158	52	158	54	-4447661806823932399	plt.yticks(range(len(list_fams)),list_fams,fontsize=10)	158	0	158	55	-8893114806647666508
10	162	41	162	43	6333812067894050725	plt.ylabel("Number of injuries",fontsize=10)	162	0	162	44	9085254535897418034
10	163	28	163	30	9117621582199076637	plt.xlabel("Month",fontsize=10)	163	0	163	31	6675153161359963902
10	165	95	165	97	1813847819180101129	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(5)], batch_size= 32, nb_epoch= 10,\\n          verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(5)]))	165	0	166	97	-2486106478044164558
10	171	35	171	37	-6734482402812711823	my_map.plot(x, y, 'bo', markersize=10)	171	0	171	38	-8641397141694138084
10	175	57	175	59	9110450116117305108	kernel_mean_matching(test, train, kern='rbf', B=10)	175	9	175	60	-6565075359733155911
10	176	40	176	42	4388341296217942315	cross_val_score(rfc, X, Y, cv=10)	176	10	176	43	4721909410083141157
10	180	17	180	19	-6234498475929793997	fig.scatter(X_pca[:, 0], X_pca[:, 1],\n            size=10, line_color='black', line_alpha=0.5,\n                fill_color=pal.linear_map(y, seqcolors))	179	0	181	56	2147455249932199249
10	183	35	183	37	1623869676426481467	my_map.plot(x, y, 'ro', markersize=10)	183	0	183	38	-6817145389225296091
10	183	55	183	57	-4972332825623640993	knn_model.query(image_test[0:1], k=10)	183	20	183	58	-5655179698540228576
10	191	73	191	75	-1856226769824635571	model_tf_idf.query(wiki[wiki['name'] == 'Barack Obama'], label='name', k=10)	191	0	191	76	-7529356735320209428
10	193	35	193	37	-9073465931935603477	my_map.plot(x, y, 'bo', markersize=10)	193	0	193	38	-4041193302458254860
10	197	17	197	19	5796434644446674149	city.head(n=10)	197	5	197	20	1627579928078839916
10	204	17	204	19	-853745275411046812	fig.scatter(X_lle[:, 0], X_lle[:, 1],\n            size=10, line_color='black', line_alpha=0.75,\n            fill_color=pal.linear_map(y, seqcolors))	203	0	205	52	1223296373083678376
10	218	35	218	37	6838096968834464495	my_map.plot(x, y, 'bo', markersize=10)	218	0	218	38	-5694797876856928812
10	219	54	219	56	-2816050527871192345	plt.hist(nearest_neighbors_euclidean['length'], 50, color='r', edgecolor='None', histtype='stepfilled', normed=True,\n         label='100 NNs of Obama (Euclidean)', zorder=10, alpha=0.8)	218	0	219	68	-6770913241965234420
10	224	70	224	72	7521387632991679299	GaussianMixture(n_components=n_clusters, random_state=10)	224	16	224	73	6336780952563812497
10	228	50	228	52	-3052642225402667593	fig.colorbar(utility_surface, shrink=0.75, aspect=10)	228	0	228	53	-5294716592668674453
10	230	68	230	70	3422907416706251290	plt.arrow(0, 0, x_arrow, y_arrow, color='red', zorder=2, head_width=10, width=2)	230	0	230	80	1747813031023141340
10	232	43	232	45	6271876726831477716	plt.legend(loc=4, framealpha=0.3, fontsize=10)	232	0	232	46	-6219394705429567535
10	235	33	235	35	6048149357456687913	dict(kernel='rbf', gamma=10)	235	8	235	36	273290910339874279
10	236	33	236	35	6036633862220827814	DBSCAN(eps=0.3, min_samples=10)	236	5	236	36	-1945892206716383394
10	236	34	236	36	7712920258963479767	dict(kernel='poly', gamma=10)	236	8	236	37	-6137797123951018865
10	237	36	237	38	-4358235665876662713	dict(kernel='cosine', gamma=10)	237	8	237	39	-1971185475638674004
10	246	19	246	21	-783049862754353602	interaction_plot(E, M, U, colors=['red','blue'], markers=['^','D'],\n        markersize=10, ax=ax)	245	5	246	29	1297011610787245351
10	258	54	258	56	-977791480412451397	plt.hist(nearest_neighbors_euclidean['length'], 50, color='r', edgecolor='None', histtype='stepfilled', normed=True,\n         label='100 NNs of Obama (Euclidean)', zorder=10, alpha=0.8)	257	0	258	68	-4247384235090986851
10	268	30	268	32	183593806462042229	dict(offset=10, trim=False)	268	18	268	45	4068714737987296959
10	270	49	270	51	7417640323343551821	L.InnerProduct(n.relu1, num_output=10, weight_filler=dict(type='xavier'))	270	14	270	87	-5432783497922477646
10	275	30	275	32	7046440088449558579	dict(offset=10, trim=False)	275	18	275	45	1312486137533671740
10	279	102	279	104	7946469236228916634	plt.scatter(points[:,0], points[:,1], linewidth=2, s=50, color='white', edgecolor='black', zorder=10)	279	4	279	105	-5637123221761941515
10	284	56	284	58	-1446327925843123100	decision_tree_create(train_data, features, 'safe_loans', max_depth = 2,\n                                        min_node_size = 10, min_error_reduction=0.0)	283	22	284	84	4966024280047886206
10	286	50	286	52	-9074526093681022749	fig.colorbar(utility_surface, shrink=0.75, aspect=10)	286	0	286	53	3376881429558075869
10	297	48	297	50	-497439589454010138	sph.image(s.gas,qty="rho",units="g cm^-2",width=10,cmap='viridis',\n    vmin=1.0e1,vmax=1.0e6)	297	0	298	26	7949396800166144919
10	305	43	305	45	-8759670071311941966	model2_tf_idf.query(obama, label='name', k=10)	305	0	305	46	-1473681432096464063
10	308	35	308	37	9074341010992928106	ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)	308	0	308	50	3049535754483964854
10	308	47	308	49	6838892229397797972	ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)	308	0	308	50	3049535754483964854
10	312	46	312	48	-6384206986138083030	model.get_loss_func(k=10)	312	24	312	49	7282840390004924061
10	312	47	312	49	-2174212195259646415	StratifiedKFold( Y_train, n_folds = 10 )	312	11	312	51	-1408540599918330317
10	312	89	312	91	-1536910886185066818	x.rolling(window=10,min_periods=1)	312	72	312	106	-8057621588932967960
10	318	34	318	36	-7077867487708157553	plt.clabel(CS, inline=1, fontsize=10)	318	0	318	37	-529377627355772990
10	336	30	336	32	-1951605776731680361	SVC(kernel = 'linear',C=10, gamma=0.01, probability = True)	336	6	336	65	8327018167672242305
10	350	41	350	43	-6815412255453676055	StratifiedKFold(y_temp, n_folds=10, shuffle=True, random_state=66)	350	9	350	75	3245634889605426771
10	360	59	360	61	604616387533989526	KMeans(n_clusters=n_clusters, random_state=10)	360	16	360	62	1520940389561260195
10	363	43	363	45	-4003666366642641627	plt.legend(loc=4, framealpha=0.3, fontsize=10)	363	0	363	46	5875386820789535258
10	365	44	365	46	7151285420058040721	ax.set_ylabel('Relative flux', fontsize=10)	365	4	365	47	6680545827330733675
10	373	59	373	61	7608187524029807074	KMeans(n_clusters=n_clusters, random_state=10)	373	16	373	62	-3546245418801806304
10	379	34	379	36	5873793649707030756	plt.clabel(CS, inline=1, fontsize=10)	379	0	379	37	-8837687480196764555
10	384	50	384	52	9134465774977747458	fig.colorbar(utility_surface, shrink=0.75, aspect=10)	384	0	384	53	-7512923942954399959
10	389	34	389	36	-4402233973842587472	plt.clabel(CS, inline=1, fontsize=10, manual=manual_locations)	389	0	389	62	5246727740047935580
10	405	54	405	56	-3209779509957942264	interaction_plot(kt['Weight'], kt['Duration'], np.log(kt['Days']+1),\n        colors=['red', 'blue'], markers=['D','^'], ms=10, ax=ax)	404	6	405	64	343666475218022348
10	424	50	424	52	2435428742330075736	fig.colorbar(utility_surface, shrink=0.75, aspect=10)	424	0	424	53	7868123764859966220
10	445	29	445	31	3807985114033416372	KMeans(n_clusters=10)	445	11	445	32	8042781002534308530
10	449	35	449	37	-4946470063549055394	ax1.set_xlabel('Cluster', fontsize=10)	449	0	449	38	6731993604688475645
10	450	55	450	57	-978529070133795675	ax1.set_ylabel('Avg Airport Departure Delay', fontsize=10)	450	0	450	58	-3922482436612536162
10	451	49	451	51	8633297888155526320	L.InnerProduct(n.fc2, num_output=10, weight_filler=dict(type='xavier'))	451	16	451	87	-432084125338808352
10	454	35	454	37	-6982462189207724395	ax2.set_xlabel('Cluster', fontsize=10)	454	0	454	38	-7615828381507295322
10	455	45	455	47	-7110639059007822783	ax2.set_ylabel('Avg Taxi Out Time', fontsize=10)	455	0	455	48	6387567194068221503
10	459	35	459	37	-718732656061909758	ax3.set_xlabel('Cluster', fontsize=10)	459	0	459	38	7960860039789173027
10	460	46	460	48	6415020652680921737	ax3.set_ylabel('Avg Taxi Out Delay', fontsize=10)	460	0	460	49	7007755901566485744
10	462	35	462	37	-5897923699117168456	ax1.set_xlabel('Cluster', fontsize=10)	462	0	462	38	2748897426586811664
10	463	55	463	57	-6190911804386369563	ax1.set_ylabel('Avg Airport Departure Delay', fontsize=10)	463	0	463	58	4926722220488433761
10	467	35	467	37	-5173967098577080117	ax2.set_xlabel('Cluster', fontsize=10)	467	0	467	38	5550918129572373297
10	468	45	468	47	2331280967133990108	ax2.set_ylabel('Avg Taxi Out Time', fontsize=10)	468	0	468	48	4999803232005558578
10	469	35	469	37	-3997126504146844420	ax1.set_xlabel('Cluster', fontsize=10)	469	0	469	38	-8955318232002603381
10	470	47	470	49	-4374472602189541925	ax1.set_ylabel('Total Cancellations', fontsize=10)	470	0	470	50	4190327645470008687
10	472	35	472	37	-7608641525007450860	ax3.set_xlabel('Cluster', fontsize=10)	472	0	472	38	-3867300936465630621
10	473	46	473	48	8382125316967147889	ax3.set_ylabel('Avg Taxi Out Delay', fontsize=10)	473	0	473	49	6586799547375230298
10	474	35	474	37	-1714877954937241603	ax2.set_xlabel('Cluster', fontsize=10)	474	0	474	38	169470823217585360
10	475	44	475	46	4359947448743350689	ax2.set_ylabel('Total Diversions', fontsize=10)	475	0	475	47	3533534520942404908
10	479	33	479	35	3926335498921287844	cbar.set_label(var, size=10)	479	8	479	36	-8867605737135621232
10	482	35	482	37	-3078908818699187421	ax1.set_xlabel('Cluster', fontsize=10)	482	0	482	38	-581547780834066900
10	482	77	482	79	4049347923974048035	anim.save('vae_all_{}to{}.gif'.format(start, end), writer='imagemagick', fps=10, dpi=64)	482	0	482	88	-1497845107189350081
10	483	47	483	49	46224896947748756	ax1.set_ylabel('Total Cancellations', fontsize=10)	483	0	483	50	1702413012732462816
10	487	35	487	37	-8170959119741779014	ax2.set_xlabel('Cluster', fontsize=10)	487	0	487	38	5174010570277362693
10	488	44	488	46	-3233532265656250563	ax2.set_ylabel('Total Diversions', fontsize=10)	488	0	488	47	-3044725199345116316
10	645	52	645	54	-4656137843552511815	filter_bbox(image, bboxes_list,threshold=10)	645	11	645	55	1744537446093197846
10	666	33	666	35	9187478279223833297	LogisticRegression(C=10)	666	12	666	36	4107878680221579885
10	687	30	687	32	-571523393265659490	plt.rc('ytick', labelsize=10)	687	4	687	33	-5681739198705521952
10	722	36	722	38	-4736167490615257359	DBSCAN(eps = 5, min_samples = 10)	722	6	722	39	1792822462505832833
10	731	30	731	32	5786157789331010104	plt.rc('ytick', labelsize=10)	731	4	731	33	-4985609242862046172
10	742	64	742	66	-2033032880381560083	plot_features(coef_model2[:,i], feature_names_model2, top_n=10, ax=ax)	742	4	742	74	3794157781127659396
10	776	30	776	32	260424675507177628	plt.rc('ytick', labelsize=10)	776	4	776	33	6441343223148845195
10	812	42	812	44	-445407047139278486	plt.bar(bin_edges[:-1], hist, width = 10)	812	4	812	45	-1268595460565097417
10	853	50	853	52	6677677864708758829	axarr[0, 0].bar(bin_edges[:-1], hist, width = 10)	853	4	853	53	6912934797787031499
10	857	50	857	52	6651936229297422303	axarr[0, 1].bar(bin_edges[:-1], hist, width = 10)	857	4	857	53	-3503047784907461844
10	940	55	940	57	-4408482289467219538	sns.kdeplot(win['team1_adjde'], win['Adjusted RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False, size = 10, aspect = 'equal',kind = 'kde',n_levels=25)	939	4	940	101	-1935959028215653032
10	944	92	944	94	-1068716312056171716	LogisticRegression(C = 10)	944	69	944	95	7014845580528383072
10	955	55	955	57	5706734948981271296	sns.kdeplot(win['team1_adjde'], win['RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False, size = 10, aspect = 'equal',kind = 'kde',n_levels=25)	954	4	955	101	6355256911657107609
10	965	54	965	56	6921776230176519287	sns.kdeplot(loss['team1_adjde'], loss['Adjusted RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False,size = 10, aspect = 'equal',n_levels=25)	964	4	965	87	-2402006676199883176
10	974	54	974	56	-6422361967840400908	sns.kdeplot(loss['team1_adjde'], loss['RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False,size = 10, aspect = 'equal',n_levels=25)	973	4	974	87	8140729054097177418
10	988	63	988	65	-7611477477283349661	sns.kdeplot(win['team1_adjtempo'], win['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False, size = 5, aspect = 10,n_levels=50)	987	0	988	78	-1208705493962606294
10	992	61	992	63	-4664217586192382628	sns.kdeplot(loss['team1_adjtempo'], loss['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False,size = 5,aspect = 10,n_levels=50)	991	0	992	76	2187852039882625447
10	1038	55	1038	57	6299058551998208674	LogisticRegression(C=10)	1038	34	1038	58	6552045986735796510
10	1041	55	1041	57	7420817493428601253	LogisticRegression(C=10)	1041	34	1041	58	5528715717253531700
10	1044	55	1044	57	-6374496852394796318	LogisticRegression(C=10)	1044	34	1044	58	-4593706766677293579
10	1067	38	1067	40	385957497676178081	LogisticRegression(C=10)	1067	17	1067	41	6903643808808145234
10	1114	68	1114	70	-4561065222968199162	plt.xlabel('Normalized video index(ranked by popularity)', fontsize=10)	1114	0	1114	71	-358330678167959527
10	1115	45	1115	47	3841305937992200000	plt.ylabel('Total Number of views', fontsize=10)	1115	0	1115	48	-583763965373168891
10	1202	37	1202	39	8204273154585538640	LogisticRegression(maxIter=10, regParam=0.01, labelCol="label_binary", featuresCol="features",\n                            predictionCol="prediction_binary")	1202	10	1203	62	7712826776488672714
10	1203	26	1203	28	-1401634136803783578	LogisticRegression(C=10)	1203	5	1203	29	1892776692774643651
10	1473	12	1473	14	-5915304352419124427	PCA(k=10, inputCol="features", outputCol="pca_features")	1473	6	1473	62	-1663749943752011269
10	1855	102	1855	104	8845357818902883497	plt.errorbar(linmean,linresolution,linresolutionerr,linmeanerr, marker='o', color='indigo',markersize=10, linestyle="",\n             label='Linear CES energy resolution', alpha=1)	1855	0	1856	59	-2838111590889231101
10	1858	102	1858	104	-6995299015037861911	plt.errorbar(linmean,csresolution,csresolutionerr,csmeanerr, marker='o', color='royalblue',markersize=10, linestyle="",\n             label='Single line CES energy resolution', alpha=1)	1858	0	1859	64	-616559936193388232
10	1861	104	1861	106	5049127024419251033	plt.errorbar(linmean,parresolution,parresolutionerr,parmeanerr, marker='o', color='seagreen',markersize=10, linestyle="",\n             label='Parametrized CES energy resolution', alpha=1)	1861	0	1862	65	-5334230830350459560
10	1909	104	1909	106	-160909005289134555	plt.errorbar(linmean,lindeltaenergy,lindeltaenergyerr,linmeanerr, marker='o', color='indigo',markersize=10, linestyle="",\n             label='Linear CES accuracy', alpha=1)	1909	0	1910	50	-1649682475758859383
10	1912	103	1912	105	-6981360073266606731	plt.errorbar(csmean,csdeltaenergy,csdeltaenergyerr,csmeanerr, marker='o', color='royalblue',markersize=10, linestyle="",\n             label='Single line CES accuracy', alpha=1)	1912	0	1913	55	-1350440438197371095
10	1915	106	1915	108	7913651703735026469	plt.errorbar(parmean,pardeltaenergy,pardeltaenergyerr,parmeanerr, marker='o', color='seagreen',markersize=10, linestyle="",\n             label='Parametrized CES accuracy', alpha=1)	1915	0	1916	56	-5885878675569113869
2	11	19	11	20	-2771965300482551993	sns.set(font_scale=2)	11	0	11	21	-3882990168435502637
2	15	25	15	26	-5067978303826754733	gdelt.gdelt(version=2)	15	5	15	27	-6885777002980141133
2	15	30	15	31	-5455212923390759906	np.set_printoptions(precision=2)	15	0	15	32	4839561335820453820
2	20	49	20	50	-826860743277586780	PlotlyPlot(plot_mode='static', x_title='GDP per capita', y_title='Life expectancy', plot_title='Example XY plot',\n          filename='plots/example_xy.png', scale=2)	19	0	20	51	-6332837754808124338
2	23	23	23	24	-8578381444373701548	plt.plot(x,y,linewidth=2)	23	0	23	25	3304458551226865527
2	24	24	24	25	-7436330537960104681	plt.plot(x,y2,linewidth=2)	24	0	24	26	8425632166093968082
2	27	18	27	19	-6388021284922230575	plt.plot(x, y, lw=2)	27	0	27	20	-3481600698524121823
2	29	36	29	37	-1669756805945828657	np.mean(frame, axis=2)	29	16	29	38	-3370386914126165730
2	31	20	31	21	-9168387121716461394	ax.plot(x,y, lw=2)	31	4	31	22	6952158940011644582
2	31	53	31	54	7437089088092400086	itertools.combinations(l, r=2)	31	25	31	55	6137102032270909473
2	31	75	31	76	-5530670944863208343	scene.TurntableCamera(elevation=30, azimuth=30, up='z', distance=2)	31	10	31	77	7580740277387095602
2	32	17	32	18	1170566388332895332	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	30	16	35	1	660775984864435510
2	32	108	32	109	-3292227577409331010	PlotlyPlot(plot_mode='static', plot_title='Example heatmap 1', filename='plots/example_heatmap1.png', scale=2)	32	0	32	110	-143798260124767452
2	33	39	33	40	-5327148548641874983	PCA(n_components=2)	33	22	33	41	792874789503178066
2	39	73	39	74	-5599767275886050005	generate_adjacency_map(corpus = inaugural, order = 2, struct=list)	39	22	39	88	2127535486672378923
2	40	72	40	73	-9136200337149925586	generate_adjacency_map(corpus = inaugural, order = 2, struct=set)	40	21	40	86	4039981884048099978
2	40	74	40	75	6108103961423115593	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	40	0	40	76	1329426235706070048
2	41	47	41	48	6244931043255258554	pd.read_csv('lec25.csv', header = None, nrows =2)	41	0	41	49	-3311391533077538797
2	43	22	43	23	2808339943820049876	wcs.WCS(naxis=2)	43	8	43	24	837115250180770315
2	43	59	43	60	-5002185420677456651	plt.axvline(this.C_intersurface, 0, 40, c='k', ls='--', lw=2, zorder=-2)	43	0	43	72	5715439100093660952
2	45	71	45	72	4185561508243001899	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	45	52	45	112	-403443544484575185
2	46	71	46	72	3932557825131477938	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	46	52	46	112	-3747151126198113622
2	48	57	48	58	-9073764439749362673	LaplaceProbDist(FreqDist(lines),bins=2)	48	20	48	59	-78589899175229863
2	49	36	49	37	-6659454620036490000	plt.legend(loc='upper center', ncol=2)	49	0	49	38	-2720473822611329640
2	49	37	49	38	4223832817185537879	M.sample(iter=10000, burn=5000, thin=2)	49	0	49	39	7307386832071018896
2	50	26	50	27	3446122543657057681	plt.plot(x, y,'k.',ms=2)	50	4	50	28	-168496664452868943
2	50	74	50	75	813468062305430364	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	50	0	50	76	5898441759789635742
2	50	108	50	109	-3284299701508042822	PlotlyPlot(plot_mode='static', plot_title='Example heatmap 2', filename='plots/example_heatmap2.png', scale=2)	50	0	50	110	-9119168506062126691
2	53	68	53	69	3043448059503939726	tf.make_template("fc_test_template", fc, in_size=2, out_size=2)	53	19	53	82	5194092426408639185
2	53	80	53	81	-3171192294361132689	tf.make_template("fc_test_template", fc, in_size=2, out_size=2)	53	19	53	82	5194092426408639185
2	54	74	54	75	3108065508267605122	datasets.make_classification(n_features = 2, n_informative = 1,\n                                                            n_redundant = 1, n_clusters_per_class = 1,\n                                                            random_state = 1 )	54	32	56	78	1581585273349022126
2	56	66	56	67	5053862092693343066	decomposition.PCA(copy=True, iterated_power=3, n_components=2,\n                        whiten=False, svd_solver='randomized')	56	6	57	62	4972156510544883061
2	59	72	59	73	-4656995828028321041	cv2.morphologyEx(bw,cv2.MORPH_OPEN, kernel,iterations = 2)	59	16	59	74	-4506319200148383314
2	60	71	60	72	-3648877915677226837	pd.read_csv(file_names['train'][file_name], nrows=2)	60	21	60	73	-4006334834657629071
2	60	74	60	75	-5804723354002967799	cv2.morphologyEx(bw,cv2.MORPH_CLOSE, kernel,iterations = 2)	60	17	60	76	-1665991640397737644
2	61	106	61	107	3552877143413129621	PlotlyPlot(plot_mode='static', y_title='Life expectancy', filename='plots/example_violinplot1.png', scale=2)	61	0	61	108	6534695927547312497
2	62	61	62	62	3365552496173696163	widgets.IntSlider(min = -10, max = 20,step = 2, value = 5)	62	16	62	74	-3704810155526715517
2	62	101	62	102	7612099517338185787	plt.scatter(train[:,0], train[:,1], color='blue', marker='o',s=40,lw=2,label='train',zorder=1)	62	32	62	126	6840088343666820681
2	64	53	64	54	-909932809518290422	build_sentence(word_adjacency_list, order=2)	64	11	64	55	6972539163512884126
2	65	14	65	15	-1872662941135631084	SVC(gamma=2, C=1)	65	4	65	21	-3939150612301952104
2	65	101	65	102	-4330339728866144434	plt.plot(target[:,0], target[:,1], color='black',label='true',zorder=2)	65	32	65	103	8973259464934565834
2	66	67	66	68	-5032353958652868807	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
2	66	86	66	87	3701980478033888503	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
2	66	125	66	126	-6835187751536755277	plt.plot(target[:,0], linear.predict(target[:,0:1]), color='blue',lw=3,label='linear',zorder=2)	66	32	66	127	1528334268609395672
2	70	29	70	30	-760108306025595737	TSNE(n_components=2, perplexity=40, verbose=2)	70	11	70	57	-2086914756320751285
2	70	34	70	35	1953295309241695461	np.set_printoptions(precision=2)	70	4	70	36	5670336703712232559
2	70	40	70	41	5044592045277543812	plt.subplots(nrows=2, ncols=2,figsize=(20,15))	70	21	70	67	-1473953046908174741
2	70	49	70	50	72645791627896720	plt.subplots(nrows=2, ncols=2,figsize=(20,15))	70	21	70	67	-1473953046908174741
2	70	55	70	56	-7186297884907900920	TSNE(n_components=2, perplexity=40, verbose=2)	70	11	70	57	-2086914756320751285
2	71	44	71	45	-3296183372632394441	plt.vlines(np.median(lifetime), 0, 1000, lw=2, linestyles="--")	71	0	71	63	2485939240120179323
2	72	58	72	59	1283460255658715910	plt.axvline(this.offset_factor, 0, 40, c='k', ls='--', lw=2, zorder=-2)	72	0	72	71	-4531570644328258589
2	72	106	72	107	-3224887371707052435	PlotlyPlot(plot_mode='static', y_title='Life expectancy', filename='plots/example_violinplot2.png', scale=2)	72	0	72	108	5761105463117550744
2	76	28	76	29	-5259306425402540262	geoplotlib.kde(geo_data, bw=2, cmap='hot_r', cut_below=1e-4)	76	0	76	60	-3952687040993442369
2	80	73	80	74	3772072076228840275	anova_lm(sm.ols('price ~ ' + var, data = dataset).fit(), typ = 2)	80	10	80	75	1180945922044819983
2	81	11	81	12	5243801195959044272	legend(loc=2, bbox_to_anchor=(1, 1))	81	0	81	36	-3687910346131085783
2	82	29	82	30	43013148237260788	gridspec.GridSpec(nrows=2, ncols=6)	82	5	82	40	3299930594276570894
2	83	25	83	26	7482111013546156176	plt.vlines(2, 0, 1.2, lw=2, linestyles="--")	83	0	83	44	6954955432461373292
2	84	25	84	26	1724733443804721391	plt.vlines(5, 0, 1.2, lw=2, linestyles="--")	84	0	84	44	-1687705181466751535
2	84	72	84	73	6809807702176598004	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	84	53	84	113	8553067472601386944
2	84	99	84	100	4291775417708798563	KNeighborsClassifier(n_neighbors=30, weights='uniform', algorithm='kd_tree', leaf_size=30, p=2, metric='minkowski', metric_params=None)	84	6	84	141	3553224379823485797
2	85	72	85	73	6019618092475096143	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	85	53	85	113	1242869415776402056
2	86	61	86	62	-3758206709478451709	pl.Circle((x,y ), radii[i], color = 'red', linewidth=2, fill=False)	86	8	86	75	6799404356666767067
2	86	168	86	169	1145198789450806110	anova_lm(sm.ols('price ~ condition + bedrooms + bathrooms + floors + waterfront + view + grade + yr_built + yr_renovated + zipcode', data = dataset).fit(), typ = 2)	86	6	86	170	-6023542904793507175
2	88	39	88	40	-2117501437153880553	plt.plot(x, beta(a,b).pdf(x), 'k-', lw=2, label='frozen pdf')	88	0	88	61	8176602447693315387
2	89	46	89	47	6243749689167806286	LinearDiscriminantAnalysis(n_components=2)	89	6	89	48	-604774760279897918
2	93	59	93	60	4090002078298059759	random_projection.SparseRandomProjection(n_components=2, random_state=42)	93	5	93	78	-7488334484764784218
2	93	74	93	75	-8378011293752069889	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	93	0	93	76	-1333355434018928366
2	94	17	94	18	-8573347257325207026	plt.legend(loc = 2)	94	0	94	19	8935566859281758348
2	94	72	94	73	-40720372946765873	plt.scatter(dat['Teff'], dat['log(g)'], c=dat['R_H'], vmin=0, vmax=2, s=35, cmap=cmap, alpha=0.5)	94	5	94	102	3057921789789673490
2	95	40	95	41	-5160492629622297686	plt.subplots(nrows=1, ncols=2)	95	12	95	42	2040251658156822377
2	95	80	95	81	1041404058510405695	PlotlyPlot(plot_mode='static', filename='plots/example_scatterplot1.png', scale=2)	95	0	95	82	-5394541833369050976
2	96	46	96	47	7842700232637710125	plt.axvline(this.D, 0, 40, c='k', ls='--', lw=2, zorder=-2)	96	0	96	59	-6828665469403682810
2	97	14	97	15	-147931523969707424	Text(x=2, y=35, text='year', text_font_size='150pt', text_color='#EEEEEE')	97	7	97	81	6910983217275782025
2	98	11	98	12	2203834474380724828	legend(loc=2, bbox_to_anchor=(1, 1))	98	0	98	36	7921324046655093162
2	99	44	99	45	4193612901970873289	FunctionApproximator(n_out=1, n_hidden=2)	99	5	99	46	8182645017762211205
2	100	41	100	42	-7606971437584029660	LRU(max_size=2)	100	28	100	43	6730849856103529268
2	101	89	101	90	-2526330009106926718	generate_tag_adjacencies(corpus = inaugural, order = 2, struct=list)	101	36	101	104	-6584232061251059819
2	102	87	102	88	-1878621108101381527	generate_tag_adjacencies(corpus = inaugural, order = 2, struct=set)	102	34	102	101	-3677944042975234621
2	103	74	103	75	-7997094749338353301	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	103	0	103	76	566823260244223524
2	104	61	104	62	-3582912612417842807	pl.Circle((x,y ), radii[i], color = 'red', linewidth=2, fill=False)	104	8	104	75	-8364955655599243307
2	105	18	105	19	5132498247130299142	wcs.WCS(naxis=2)	105	4	105	20	8860710771245117230
2	105	50	105	51	8315392183219111830	plt.subplots(nrows=1, ncols=2, figsize=(6, 3))	105	22	105	68	-1805348241094352061
2	106	80	106	81	-5207103377866315240	PlotlyPlot(plot_mode='static', filename='plots/example_scatterplot2.png', scale=2)	106	0	106	82	6440082960152005790
2	107	48	107	49	-4625657304971658177	decomposition.TruncatedSVD(n_components=2)	107	8	107	50	-7541189973245824285
2	108	42	108	43	5159313799006627315	make_blobs(n_samples=1000, n_features=2, centers=4)	108	4	108	55	-5635320266443073427
2	111	25	111	26	-8401735165345556670	PCA(n_components=2)	111	8	111	27	-392275295765704012
2	111	40	111	41	2065196353149636977	plt.subplots(nrows=1, ncols=2)	111	12	111	42	4475117986850477918
2	113	18	113	19	-4558257700411952822	model.fit(X_train, y_train, batch_size=128, epochs=10,\n          validation_split=0.2, callbacks=[checkpointer],\n          verbose=2, shuffle=True)	111	7	113	34	-1052891680331590484
2	113	50	113	51	532764830190109074	make_moons(50, noise=0.1, random_state=2)	113	11	113	52	-1106712633500249412
2	114	44	114	45	-7519292899066727587	np.around(conf_mat_norm,decimals=2)	114	11	114	46	6089200231225559708
2	114	74	114	75	-744689354091172508	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	114	0	114	76	8926544652171672108
2	118	60	118	61	3402525445509720967	skimage.morphology.label(closed, background=0,\n                                               connectivity=2,\n                                               return_num=True)	117	22	119	63	1190605743947185684
2	122	69	122	70	3918335705786667011	pd.read_csv(file_names['test'][file_name], nrows=2)	122	20	122	71	4022493458529465922
2	123	72	123	73	-5597951256587412698	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	123	53	123	113	2358917832902972433
2	124	35	124	36	6391816045817652712	svm.SVC(gamma=2, C=1)	124	21	124	42	-6035466067243746494
2	124	70	124	71	1066918821636038414	discriminant_analysis.LinearDiscriminantAnalysis(n_components=2)	124	8	124	72	-9063698035779140501
2	124	72	124	73	-1349795147023743982	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	124	53	124	113	-3955764760833604143
2	124	74	124	75	2729598594260612236	plt.hlines(0, plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], linewidth=2)	124	0	124	76	-7894563793518039088
2	125	60	125	61	-5964982336580686297	manifold.Isomap(n_neighbors=i+2, n_components=2)	125	14	125	62	6235791826484460673
2	127	29	127	30	-3213963075003905573	svm.SVC(kernel='rbf',C=2)	127	6	127	31	-3875451822593291235
2	127	73	127	74	7618222140000253714	build_tag_sentence(tag_adjacency_list, tag_bags_list, order = 2)	127	11	127	75	-8718143476897954253
2	129	19	129	20	-3958397477134562878	nc1.train(learning_rate=0.1, n_epochs=40000,\n              X_train=X3, Y_train=Y3, batch_size=len(Y), print_frequency=2000,\n              n_in=2, n_out=2, n_hidden=i, n_layers=2)	127	4	129	54	-3621392733447045574
2	129	28	129	29	-7021006292967071018	nc1.train(learning_rate=0.1, n_epochs=40000,\n              X_train=X3, Y_train=Y3, batch_size=len(Y), print_frequency=2000,\n              n_in=2, n_out=2, n_hidden=i, n_layers=2)	127	4	129	54	-3621392733447045574
2	129	52	129	53	-5878721968739354271	nc1.train(learning_rate=0.1, n_epochs=40000,\n              X_train=X3, Y_train=Y3, batch_size=len(Y), print_frequency=2000,\n              n_in=2, n_out=2, n_hidden=i, n_layers=2)	127	4	129	54	-3621392733447045574
2	132	77	132	78	2466526626935203450	GradientBoostingRegressor(min_samples_split=2, max_depth=3, learning_rate=0.1)	132	33	132	111	-1667282952749129373
2	135	16	135	17	3547977962966305422	plt.legend(ncol=2, loc='lower right')	135	0	135	37	-2639848523949059285
2	135	46	135	47	9008493437017031210	KernelPCA(n_components=4, degree=2, gamma=.000001, coef0=120)	135	13	135	74	-2535834234939777556
2	136	34	136	35	-7446123093738234814	np.set_printoptions(precision=2)	136	4	136	36	2932168577332596489
2	137	50	137	51	6858632444944429881	manifold.Isomap(n_neighbors, n_components=2)	137	8	137	52	-6688820583886931916
2	139	50	139	51	-1706995642010755632	build_sentence(word_adjacency_list, order=2)	139	8	139	52	5034442503486185983
2	142	40	142	41	3289910368971863369	plt.subplots(nrows=2, ncols=2,figsize=(20,15))	142	21	142	67	-2096245548505487828
2	142	49	142	50	-699535695793312758	plt.subplots(nrows=2, ncols=2,figsize=(20,15))	142	21	142	67	-2096245548505487828
2	143	16	143	17	-5365502900651070286	plt.legend(ncol=2, loc='lower right')	143	0	143	37	-3627815258315016943
2	144	70	144	71	-3611471191740627166	build_tag_sentence(tag_adjacency_list, tag_bags_list, order = 2)	144	8	144	72	5064334705724788053
2	145	36	145	37	-1816949851381088213	np.sum(images[0]/3, axis=2, keepdims=True)	145	11	145	53	6199002321976324407
2	148	14	148	15	-1830827419911437686	ax.legend(loc=2)	148	0	148	16	-3738678067866985589
2	148	17	148	18	729111083148915046	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	146	16	151	1	-3537157781248254314
2	150	47	150	48	5538107041886698814	numpy.around(conf_mat_norm,decimals=2)	150	11	150	49	-7896342705114730838
2	150	64	150	65	-5219240086690612233	manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n                                      method='standard')	150	6	151	56	3828538358515508782
2	152	60	152	61	-7586255202988789656	pl.Circle(point, radii[i], color = 'red', linewidth=2, fill=False)	152	8	152	74	-7284146840416867731
2	155	45	155	46	7179810874028241382	mc.Uniform( "stds", 0, 100, size= 2)	155	11	155	47	3413722141658293381
2	156	24	156	25	-4401677794462499938	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
2	156	48	156	49	4856647637422315453	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
2	156	64	156	65	3334235611632488894	mc.Normal( "centers", [120, 190], [0.01, 0.01], size =2 )	156	10	156	67	6784104915695701404
2	160	26	160	27	-6484763499675467266	ax.legend(loc=2, bbox_to_anchor=(1, 1))	160	12	160	51	-2239034751233711916
2	162	14	162	15	5559608038482294969	ax.legend(loc=2)	162	0	162	16	-3201668031338544471
2	162	72	162	73	-8908280997109226781	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	162	53	162	113	-8908195277355693520
2	163	68	163	69	4741265448480938463	processor(vt, targetimage, timeslice='auto', padding=2, oversampling=4,\n                         facets=4, wstack=advice['w_sampling_primary_beam'], vis_slices=31,\n                         wstep=advice['w_sampling_primary_beam'])	163	15	165	65	618035739375703242
2	163	72	163	73	7794880138691602376	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	163	53	163	113	4686635607745070422
2	165	24	165	25	-8727107802838692652	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
2	165	48	165	49	-6513154788972176579	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
2	165	56	165	57	-3390303719159168302	kernel_mean_matching(test, train, kern='rbf', B=2)	165	8	165	58	-6409464812230035963
2	166	18	166	19	8814407642487215295	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(5)], batch_size= 32, nb_epoch= 10,\\n          verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(5)]))	165	0	166	97	-2486106478044164558
2	166	32	166	33	4817295656680150350	Uniform('x',0,10, shape=2)	166	8	166	34	-281188167353778005
2	166	64	166	65	-2500638405999932390	manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n                                      method='modified')	166	6	167	56	-3591319783741407548
2	170	92	170	93	-4908948272122371856	P.rc('legend', numpoints=1, frameon=False, handletextpad=0.3, scatterpoints=1, handlelength=2, handleheight=0.1)	170	0	170	112	6412631352673677337
2	171	23	171	24	5009699351230069709	PCA(n_components=2)	171	6	171	25	7534151355044711740
2	171	88	171	89	-8595995378361048836	plt.loglog(bblnrgdata_cut['EnergyTOTAL'], bblnrgdata_cut['UnitsTotal'], 'o', markersize=2)	171	0	171	90	-1489390850263149294
2	172	35	172	36	-1772178678968060018	plt.plot(r,orbElems[0,:],linewidth=2)	172	0	172	37	1095826441851414442
2	172	79	172	80	-8547469626557730586	DensityDist('z',lambda x: -(x[0]-4)**2 - 2*(x[1]-9)**4, shape=2, testval=[1,1])	172	17	172	96	4201929695302508574
2	174	39	174	40	-9129561419104602053	decomposition.PCA(n_components=2)	174	8	174	41	-6825909486692249191
2	176	14	176	15	4763982579324040331	ax.legend(loc=2)	176	0	176	16	-4381713594602517302
2	179	34	179	35	-4442592621978660641	np.set_printoptions(precision=2)	179	4	179	36	-7965700041520046915
2	179	48	179	49	-9078126414223851216	plt.axvline(x=loc, ymin=-1, ymax = 1, linewidth=2, color='black',label="1:3 EOLR")	179	0	179	82	7709365567739490862
2	180	41	180	42	-792699448626540698	plt.plot(r,ecc_f,color='green',linewidth=2,label="$e_{forced}$ [Moriwaki 2004]")	180	0	180	80	563697949590966992
2	181	56	181	57	-8086931978546763659	kernel_mean_matching(test, train, kern='rbf', B=2)	181	8	181	58	8317496914298098219
2	183	64	183	65	4164097834549479250	manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n                                      method='hessian')	183	6	184	55	-4678073921709539982
2	183	88	183	89	5213155921874298634	plt.loglog(bblnrgdata_cut['UnitsTotal'], bblnrgdata_cut['EnergyTOTAL'], 'o', markersize=2)	183	0	183	90	3966367339072659278
2	185	16	185	17	7661339691044623725	ax.legend(loc = 2)	185	0	185	18	-1472385049146352398
2	186	49	186	50	-1589099963611559830	plt.plot(sa, ct, color='#999999', zorder=2)	186	8	186	51	5009150152581523851
2	187	51	187	52	-5235376876884470649	manifold.Isomap(n_neighbors=25, n_components=2)	187	6	187	53	1626133110710677441
2	190	14	190	15	2171200754128758976	ax.legend(loc=2)	190	0	190	16	-6237082460874491462
2	190	17	190	18	6026602104937511578	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	188	16	193	1	-6595224594010388118
2	192	14	192	15	-989470685901263238	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='G/60 during slump')	192	0	192	66	8491989641045042866
2	196	23	196	24	-5168729765185460134	PCA(n_components=2)	196	6	196	25	8818776779286793458
2	198	67	198	68	7697803700841444830	manifold.LocallyLinearEmbedding(n_neighbors=15, n_components=2, method='modified')	198	6	198	88	5226607276166827305
2	200	64	200	65	8100975348076800833	manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n                                      method='ltsa')	200	6	201	52	-3360917814952101489
2	202	14	202	15	1726614930627713741	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='G/60 during slump')	202	0	202	66	3939191764731161747
2	204	14	204	15	-1122091987833036544	ax.legend(loc=2)	204	0	204	16	-2910531469726519206
2	206	46	206	47	-5313900949524910773	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=2)	206	0	206	48	-1282925691893218194
2	208	16	208	17	8622259421352303865	ax.legend(loc = 2)	208	0	208	18	8008047158507742940
2	211	34	211	35	6307455231040650197	manifold.TSNE(n_components=2, n_iter=500)	211	7	211	48	-32563930144533522
2	215	32	215	33	-530236994690654294	manifold.MDS(n_components=2, n_init=1, max_iter=100)	215	6	215	58	-466724360669131111
2	215	84	215	85	-7249080579929072282	plt.scatter(all_centroid["x"],         all_centroid["y"],         c="g", zorder=2, s=100)	215	4	215	93	7377727079367765918
2	216	84	216	85	2637277240966601569	plt.scatter(all_centroidweighted["x"], all_centroidweighted["y"], c="r", zorder=2, s=100)	216	4	216	93	8428329796300536488
2	218	42	218	43	-5604223203509623804	CountVectorizer(min_df=2, stop_words='english')	218	19	218	66	2578034628689521108
2	219	48	219	49	5055073944490024206	plt.plot(ct, d, color='#999999', zorder=2)	219	8	219	50	-7404061397319076779
2	219	57	219	58	-8268926337980907624	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=2, row_step=2,\n                                                col_end=shapes[k]['w'],\n                                                row_end=shapes[k]['h'])	215	23	221	71	5749420223800921298
2	219	69	219	70	5419864239030862074	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=2, row_step=2,\n                                                col_end=shapes[k]['w'],\n                                                row_end=shapes[k]['h'])	215	23	221	71	5749420223800921298
2	220	23	220	24	-6842601975299204048	PCA(n_components=2)	220	6	220	25	4489271499759123509
2	220	86	220	87	1252915998463130698	plt.scatter(topN_centroidweighted["x"], topN_centroidweighted["y"], c="m", zorder=2, s=100)	220	4	220	95	-1631311168509988455
2	221	50	221	51	-6604824768493161841	plt.axvline(x=wiki['length'][wiki['name'] == 'Barack Obama'][0], color='k', linestyle='--', linewidth=4,\n           label='Length of Barack Obama', zorder=2)	220	0	221	52	-3909111957945218711
2	221	86	221	87	-4074414773226316462	plt.scatter(topN_centroid["x"],         topN_centroid["y"],         c="y", zorder=2, s=100)	221	4	221	95	6538590467234555823
2	223	71	223	72	-1873114605505653792	plt.plot(pg['rbins'], pg['density'].in_units("g cm**-2"),'k',linewidth=2)	223	0	223	73	-7419956743045825370
2	223	94	223	95	-4712963178366085242	plt.scatter(topNtile_centroidweighted["x"], topNtile_centroidweighted["y"], c="c", zorder=2, s=100)	223	4	223	103	-1752530546439175677
2	224	94	224	95	-4712790185778893319	plt.scatter(topNtile_centroid["x"],         topNtile_centroid["y"],         c="k", zorder=2, s=100)	224	4	224	103	-4832562188758651614
2	228	23	228	24	6156184935259423656	PCA(n_components=2)	228	6	228	25	7396476035044748284
2	230	54	230	55	8948786853064758902	plt.arrow(0, 0, x_arrow, y_arrow, color='red', zorder=2, head_width=10, width=2)	230	0	230	80	1747813031023141340
2	230	78	230	79	-6686232767746713191	plt.arrow(0, 0, x_arrow, y_arrow, color='red', zorder=2, head_width=10, width=2)	230	0	230	80	1747813031023141340
2	232	11	232	12	-120372153881632770	legend(loc=2, bbox_to_anchor=(1, 1), title='Period')	232	0	232	52	-8359156198046740550
2	233	43	233	44	1022196028925037951	ax1.plot(Mrs, C_dash, color='k', linewidth=2)	233	0	233	45	-4348982113230964836
2	233	46	233	47	-9123300712482475600	decomposition.TruncatedSVD(n_components=2)	233	6	233	48	-7534332260789508718
2	233	106	233	107	-1958732653621903467	plt.plot(np.log10(bblnrgdata_cut['UnitsTotal']), np.log10(bblnrgdata_cut['EnergyTOTAL']), 'o', markersize=2, label='Data Points')	233	0	233	129	5480674682772203475
2	234	19	234	20	-4024860641937978189	plt.legend(["line",\n                "detections",\n                "centroid",\n                "centroid weighted",\n                "top N_centroid weighted",\n                "top N_centroid",\n                "top Ntile centroid weighted",\n                "top Ntile centroid"],\n               loc=2, #legend loc='upper left'\n               scatterpoints=1,\n               frameon=False\n               )	226	4	237	16	7115522464313205573
2	234	62	234	63	-2454517901466374133	ax1.plot(Mrs, upper, color='k', linestyle='dashed', linewidth=2)	234	0	234	64	1240252117170648013
2	235	49	235	50	-9203400149273885930	plt.axvline(this.cATP, 0, 40, c='k', ls='--', lw=2, zorder=-2)	235	0	235	62	6001528957034082448
2	235	62	235	63	4302146084702457088	ax1.plot(Mrs, lower, color='k', linestyle='dashed', linewidth=2)	235	0	235	64	-1472888750424299597
2	236	59	236	60	-4566594310856330550	plt.errorbar(x, y, xerr=0.2, yerr=yerr, fmt='+', linewidth=2)	236	0	236	61	-5108683098238902043
2	237	48	237	49	-1440703834397264681	plt.axvline(x=loc, ymin=-1, ymax = 1, linewidth=2, color='red',label="3:1")	237	0	237	75	-6654553551286560328
2	238	49	238	50	-4409446252534079961	plt.axvline(x=loc2, ymin=-1, ymax = 1, linewidth=2, color='green',label="2:1")	238	0	238	78	-1157387928474582139
2	246	28	246	29	-6674961036168504824	sm.TSNE(n_components=2, verbose=1, n_iter=1000)	246	7	246	54	-286395297359099334
2	246	51	246	52	7759136923186750204	manifold.SpectralEmbedding(n_components=2, random_state=0,\n                                      eigen_solver="arpack")	246	11	247	60	-1502557477349364256
2	247	43	247	44	-5036593524349931249	loglog(2**bins, noise_var/2**bins, "c", lw=2, label=r"Noise $\propto\ N^{-1}$")	247	0	247	79	4932204191680475475
2	247	106	247	107	-8550347758318163903	plt.plot(np.log10(bblnrgdata_cut['EnergyTOTAL']), np.log10(bblnrgdata_cut['UnitsTotal']), 'o', markersize=2, label='Data Points')	247	0	247	129	-1231897868492369292
2	249	33	249	34	-1827965791116255384	ax.plot([], [], 'o-', lw=2)	249	8	249	35	8278770579672858107
2	249	59	249	60	540034275229537164	loglog(2**bins, noise_var*(a + (1 - a)/2**bins), "c--", lw=2, label=r"Noise $+\ C$")	249	0	249	84	4736270810260220488
2	251	23	251	24	-6757196338131809577	PCA(n_components=2)	251	6	251	25	-7714389911149207242
2	251	48	251	49	6643069156821699708	plt.plot(sa, d, color='#999999', zorder=2)	251	8	251	50	-4843840544183177146
2	252	71	252	72	2953043477387547595	ax1.plot(N.log10(ms), sfr_138, linestyle='solid', color='k', linewidth=2)	252	0	252	73	4510646358581457850
2	253	55	253	56	-8165338324985156560	newyear.rolling(10, center=True).mean().plot(linewidth=2)	253	0	253	57	5163017210663204365
2	253	76	253	77	2692971168522071668	ax1.plot(N.log10(ms), sfr_138-0.3, linestyle='dashed', color='k', linewidth=2)	253	0	253	78	5186341927089163187
2	254	76	254	77	-3664424949958232724	ax1.plot(N.log10(ms), sfr_138+0.3, linestyle='dashed', color='k', linewidth=2)	254	0	254	78	-2113001321082411896
2	257	16	257	17	-3871321117066654479	plt.axhline(y=2, color='r', ls='dashed')	257	2	257	42	2876171804118805036
2	261	55	261	56	-4633329965144401150	newyear.rolling(10, center=True).mean().plot(linewidth=2, ax=ax, color=['DarkGreen', 'DarkBlue'], rot=0)	261	0	261	104	4079559634740617041
2	261	101	261	102	4451724178230730896	pl.Circle((y[point[0], point[1]], x[point[0], point[1]]), radii[i], color = 'red', linewidth=2, fill=False)	261	8	261	115	8164031447783109600
2	262	34	262	35	-4438723963346723490	manifold.TSNE(n_components=2, init='pca', random_state=0,  method='exact')	262	7	262	81	-1265851058584896373
2	262	37	262	38	-6726883589252878190	decomposition.PCA(n_components=2)	262	6	262	39	-9132194850717302245
2	262	50	262	51	-2935757592882771205	plt.axvline(x=wiki['length'][wiki['name'] == 'Barack Obama'][0], color='k', linestyle='--', linewidth=4,\n           label='Length of Barack Obama', zorder=2)	261	0	262	52	-1815223556735027941
2	262	70	262	71	-1568007432612518485	L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n                             transform_param=dict(scale=1./255), ntop=2)	261	22	262	72	-2497730615391229196
2	265	45	265	46	7366092959016368646	L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)	265	14	265	77	5956721079524714752
2	265	55	265	56	1256588004490357043	L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)	265	14	265	77	5956721079524714752
2	267	45	267	46	2396204336312933076	L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)	267	14	267	77	-4777708325594045712
2	267	55	267	56	-1324410783914350800	L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)	267	14	267	77	-4777708325594045712
2	268	59	268	60	-970972498355078106	hist(top_offenses.G60, normed=True, label='Actual', zorder=2)	268	0	268	61	8435781455259574326
2	269	59	269	60	-5919913658339252636	plt.axvline(this.catalytic_rate, 0, 40, c='k', ls='--', lw=2, zorder=-2)	269	0	269	72	-4103403130355902821
2	275	62	275	63	2734326592886066081	patches.PathPatch(_path, fill=False, linewidth = 2)	275	13	275	64	5626947596252436483
2	275	78	275	79	3401251284373306691	plot(xs_g60, gamma.pdf(xs_g60, k_g60_top, loc_g60_top, theta_g60_top), zorder=2,\n     label=r"Gamma ($k$ = {0:.1f}, $\theta$ = {1:.2f})".format(k_g60_top, theta_g60_top))	275	0	276	89	2559021680133819387
2	278	23	278	24	3407554404352563878	MDS(n_components=2, dissimilarity="euclidean")	278	6	278	52	-4598935384329682608
2	279	52	279	53	2160141017008531203	plt.scatter(points[:,0], points[:,1], linewidth=2, s=50, color='white', edgecolor='black', zorder=10)	279	4	279	105	-5637123221761941515
2	280	32	280	33	4851374152762557089	ax.plot(x, x+5, color="red", lw=2, linestyle='-')	280	0	280	49	8723707343617949783
2	280	47	280	48	4318662900133947864	plt.plot(o, d, color='#999999', zorder=2)	280	8	280	49	8040165017668986314
2	281	32	281	33	-1316939023355741411	ax.plot(x, x+6, color="red", lw=2, ls='-.')	281	0	281	43	2640387612747130847
2	281	41	281	42	-3380566074493258624	decomposition.PCA(n_components=2)	281	10	281	43	1764099658822012279
2	282	11	282	12	8761184013536386879	legend(loc=2, bbox_to_anchor=(1, 1))	282	0	282	36	-1248216828603899889
2	282	32	282	33	3010910923264593049	ax.plot(x, x+7, color="red", lw=2, ls=':')	282	0	282	42	-5051173672304861734
2	283	34	283	35	-3907510980646720629	ax.plot(x, x+7.5, color="red", lw=2, ls='steps')	283	0	283	48	6352363842670268516
2	283	46	283	47	-3306184898069746410	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	283	18	283	65	-1752398385346999394
2	283	91	283	92	4636074928334563133	decision_tree_create(train_data, features, 'safe_loans', max_depth = 2,\n                                        min_node_size = 10, min_error_reduction=0.0)	283	22	284	84	4966024280047886206
2	290	35	290	36	-2196273828360079497	ax.plot(x, x+ 9, color="green", lw=2, ls='*', marker='+')	290	0	290	57	729166860005086732
2	290	46	290	47	-6464422207576334726	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	290	18	290	65	6759630139307608876
2	291	35	291	36	-7831585071266940120	ax.plot(x, x+10, color="green", lw=2, ls='*', marker='o')	291	0	291	57	-2785315385950271436
2	292	29	292	30	-3925700612686734237	GMM(n_components=2)	292	12	292	31	-8704682695164813843
2	292	35	292	36	-4237636131436623638	ax.plot(x, x+11, color="green", lw=2, ls='*', marker='s')	292	0	292	57	-4520000005471143847
2	293	35	293	36	4701226648323361261	ax.plot(x, x+12, color="green", lw=2, ls='*', marker='1')	293	0	293	57	7823518750030976369
2	296	70	296	71	1210378911775726704	ax.plot(x, x+13, color="purple", lw=1, ls='-', marker='o', markersize=2)	296	0	296	72	2740781268762736408
2	297	48	297	49	-2213143446296015735	CountVectorizer(min_df=2, stop_words='english')	297	25	297	72	-7442715785519486630
2	300	50	300	51	59110386503560271	ax.plot(x, x+16, color="purple", lw=1, ls='-', marker='s', markersize=8,\n        markerfacecolor="yellow", markeredgewidth=2, markeredgecolor="blue")	299	0	300	76	3735684027595230213
2	303	30	303	31	-6323781080368465692	plt.plot(x, y, 'b', linewidth=2)	303	0	303	32	-8318519682478510591
2	303	46	303	47	-9176305062153370015	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	303	18	303	65	8817492634719737204
2	303	59	303	60	9007675953119465529	plt.axvline(this.catalytic_rate, 0, 40, c='k', ls='--', lw=2, zorder=-2)	303	0	303	72	-3615936807862226184
2	307	106	307	107	6939631965149543130	plt.plot(np.log10(bblnrgdata_cut['UnitsTotal']), np.log10(bblnrgdata_cut['EnergyTOTAL']), 'o', markersize=2, label='Data Points')	307	0	307	129	1750880213817029952
2	309	9	309	10	518771818736074509	hist( data, bins = 20, histtype="step", normed = True, color = "k",\n    lw = 2, label = "histogram of data" )	308	0	309	41	5833219851132992370
2	314	26	314	27	-5199515748609581817	ax.legend(loc=2, bbox_to_anchor=(1, 1))	314	12	314	51	-6956522702780673779
2	320	41	320	42	-172584331882886516	GaussianMixture(n_components=2, random_state = RAN_STATE)	320	12	320	69	-9159843316210616800
2	328	29	328	30	-1970042152852979706	ax.plot(x, x**2, x, x**3, lw=2)	328	0	328	31	-7023367956140714297
2	329	39	329	40	8083569767760966852	sns.set_context("notebook", font_scale=2, rc={"lines.linewidth": 2.5})	329	0	329	70	-8265944744083939266
2	330	29	330	30	1865205658488053612	Tk.Radiobutton(kernel_group, text="Poly", variable=controller.kernel,\n                       value=2, command=controller.refit)	329	8	330	57	1209351903957148346
2	338	14	338	15	-6777606865559770202	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='G/60 during slump')	338	0	338	66	2627359435719647337
2	341	39	341	40	-6611986631054158800	plt.subplots(ncols=2, nrows=2)	341	20	341	50	1515056493569520833
2	341	48	341	49	-7988279650560050923	plt.subplots(ncols=2, nrows=2)	341	20	341	50	1515056493569520833
2	347	34	347	35	6081382077885202773	axes[0].plot(x, x**2, x, x**3, lw=2)	347	0	347	36	7403603415031794957
2	348	14	348	15	-399372786801579937	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='G/60 during slump')	348	0	348	66	-2038031200516742655
2	351	34	351	35	-7181974688181013028	axes[1].plot(x, x**2, x, x**3, lw=2)	351	0	351	36	5425923535969471431
2	353	12	353	13	5601273305065414821	legend(ncol=2)	353	0	353	14	-9197774241934447247
2	360	30	360	31	-9134503523012625270	plt.Circle((0,0), radius=2, fill=False)	360	5	360	44	-7030150409901234335
2	365	11	365	12	-926162382280863567	legend(loc=2, bbox_to_anchor=(1, 1), title='Period')	365	0	365	52	77120493468113718
2	365	39	365	40	-3522053322086764872	plt.plot(x, beta(a,b).pdf(x), 'k-', lw=2, label='frozen pdf')	365	0	365	61	8491132702915595583
2	366	55	366	56	1667165447637669637	manifold.Isomap(n_neighbors, n_components=2)	366	13	366	57	-8663306144567983063
2	367	39	367	40	-5293536119999137341	plt.plot(x, beta(a,b).pdf(x), 'k-', lw=2, label='frozen pdf')	367	0	367	61	-3736191352220941444
2	370	34	370	35	2126167667631111513	prng.normal(size=2)	370	17	370	36	-4058911517725295222
2	371	43	371	44	-5653722934757036739	loglog(2**bins, noise_var/2**bins, "c", lw=2, label=r"Noise $\propto\ N^{-1}$")	371	0	371	79	-8075568572065896662
2	372	79	372	80	-2019123782147752313	decision_tree_create(train_data, features, 'safe_loans', max_depth = 2,\n                                min_node_size = 0, min_error_reduction=-1)	372	10	373	74	-1270068233323247426
2	373	59	373	60	-6959594052305269936	loglog(2**bins, noise_var*(a + (1 - a)/2**bins), "c--", lw=2, label=r"Noise $+\ C$")	373	0	373	84	308383695997022203
2	374	39	374	40	-591963596645940476	plt.plot(x, beta(a,b).pdf(x), 'k-', lw=2, label='frozen pdf')	374	0	374	61	-6167940059969502659
2	376	21	376	22	9021761450580994849	ax1.plot(x, x**2, lw=2, color = 'blue')	376	0	376	39	-2153648409739404302
2	376	31	376	32	6840049769732527669	legend(loc="upper right", ncol=2)	376	0	376	33	1837946985216715988
2	379	23	379	24	-7521949248427068210	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(6)], batch_size= 64, nb_epoch= 40,\\n               verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(6)]))	378	0	379	102	6194392437158701180
2	379	25	379	26	5759174404855773693	PCA(n_components=2)	379	8	379	27	-7280974346103731958
2	379	25	379	26	7119975967850802579	plt.plot(x, y, linewidth=2)	379	0	379	27	259049430629386001
2	382	21	382	22	-5759244425144282683	ax2.plot(x, x**3, lw=2, color='red')	382	0	382	36	-5464668398768488958
2	382	38	382	39	-6425739782341590921	plot_flux_total(pert_100,varlist ,row=2,col=3)	382	0	382	46	-3491051915224671264
2	385	39	385	40	-2045619066083660646	plt.plot(x, beta(a,b).pdf(x), 'k-', lw=2, label='frozen pdf')	385	0	385	61	-1400357059387215233
2	399	26	399	27	2499499745789065858	ax.legend(loc=2, bbox_to_anchor=(1, 1))	399	12	399	51	-4603807215249702801
2	400	45	400	46	-8276360642511301769	manifold.SpectralEmbedding(n_components=2,\n                                n_neighbors=n_neighbors)	400	5	401	56	3488114446571757748
2	409	39	409	40	-7010607413598836652	sns.set_context("notebook", font_scale=2, rc={"lines.linewidth": 5})	409	0	409	68	-7169016623435906955
2	411	46	411	47	-8873933108054060942	CountVectorizer(min_df=2, ngram_range=(2,2), stop_words='english')	411	23	411	89	-7374264076951909465
2	414	60	414	61	1559416680908456810	plt.subplot2grid((20,20), (18,0), colspan=19, rowspan=2)	414	6	414	62	-7551571044590947242
2	415	25	415	26	5745100966456657323	axes[1].step(n, n**2, lw=2)	415	0	415	27	2368338002637690499
2	417	53	417	54	5178038008959352355	RandomForestClassifier(max_depth = None,\n                                 class_weight = 'balanced',\n                                 min_samples_split = 2,\n                                 n_estimators = 1000,\n                                 max_features = int(np.sqrt(X_train.shape[1])),\n                                 random_state = 0,\n                                 n_jobs = -1, # to parallelize jobs across all processors\n                                 oob_score = True)	415	11	422	50	3624182513612562906
2	417	56	417	57	-7591916513086939019	plot_flux_total_diff(pert_const,pert_bench,varlist ,row=2,col=3)	417	0	417	64	4581447171010729293
2	417	89	417	90	3553725954356817950	ax.plot(mergedData.x,mergedData.y,alpha=0.7, linewidth=3, solid_capstyle='round', zorder=2)	417	0	417	91	4953089933564221597
2	419	34	419	35	4047846990731017063	manifold.TSNE(n_components=2, init='pca', random_state=0, method = 'exact')	419	7	419	82	102417139704355305
2	423	14	423	15	-3852071279423209617	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='Sh% during slump')	423	0	423	65	8224517592010494447
2	425	30	425	31	-5733533646624024019	anova_lm(kidney_lm, typ=2)	425	6	425	32	-3373625754681166264
2	425	48	425	49	-7532408920144807784	ax.plot_surface(strike, ttm, iv, rstride=2, cstride=2,\n                       cmap=plt.cm.coolwarm, linewidth=0.5,\n                       antialiased=True)	425	7	427	40	2556864801644817235
2	425	59	425	60	-3199533045451890730	ax.plot_surface(strike, ttm, iv, rstride=2, cstride=2,\n                       cmap=plt.cm.coolwarm, linewidth=0.5,\n                       antialiased=True)	425	7	427	40	2556864801644817235
2	429	28	429	29	8115808165905354161	plt.contour(Z, levels,\n                 origin='lower',\n                 linewidths=2,\n                 extent=(-3,3,-2,2))	427	5	430	36	-6492409649985639412
2	429	54	429	55	3735654762712685095	CountVectorizer(min_df=2, ngram_range=(3,3), stop_words='english')	429	31	429	97	-6812019238463884605
2	432	27	432	28	5956905922771620166	KMeans(n_clusters=2)	432	9	432	29	1342558117449333177
2	432	70	432	71	-5690991058660043905	L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n                             transform_param=dict(scale=1./255), ntop=2)	431	22	432	72	-8321588255149795322
2	433	14	433	15	-2615730755414243784	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='Sh% during slump')	433	0	433	65	-9132044537979675914
2	436	12	436	13	-7668561136963760962	legend(ncol=2)	436	0	436	14	-7859112898596499741
2	437	45	437	46	-5620564465898539025	L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)	437	14	437	77	8139769385218215788
2	437	55	437	56	3855472940055022248	L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)	437	14	437	77	8139769385218215788
2	443	45	443	46	-2797831035925272668	L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)	443	14	443	77	1689325366866754470
2	443	55	443	56	-7221485510588974609	L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)	443	14	443	77	1689325366866754470
2	445	27	445	28	7444071754075284703	KMeans(n_clusters=2)	445	9	445	29	2615408470217860814
2	445	45	445	46	1333306863353215472	sns.lmplot(data = mapped_lfmm, x = 'cM', y = 'mlog10val', fit_reg=False, row = 'plinkLG', hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 2,\n           palette="Set2")	444	4	446	26	2752353563991065084
2	447	45	447	46	2241488881497030616	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	447	4	447	65	-6396835444559068657
2	451	11	451	12	-4559761794351426225	legend(loc=2, bbox_to_anchor=(1, 1), title='Period')	451	0	451	52	6052294356478175707
2	455	45	455	46	825385244505345432	sns.lmplot(data = mapped_lfmm, x = 'cM', y = 'FST', fit_reg=False, row = 'plinkLG', hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 2,\n           palette="Set2")	454	4	456	26	4356968802999137230
2	458	45	458	46	-3204021504680424355	plt.subplot2grid((3,3), (1,0), colspan=2)	458	6	458	47	8125705614273093058
2	459	45	459	46	-5417395150419552739	plt.subplot2grid((3,3), (1,2), rowspan=2)	459	6	459	47	6584895691221214426
2	465	37	465	38	-3877857001459139225	plt.subplots(ncols=2, sharey=False, figsize=(16, 8))	465	18	465	70	-672487933585656496
2	472	52	472	53	8362664110237987497	CountVectorizer(min_df=2,ngram_range=(ngram,ngram),stop_words='english')	472	29	472	101	-50843732726516953
2	478	37	478	38	-3584583051745358251	plt.subplots(ncols=2, sharey=False, figsize=(16, 8))	478	18	478	70	7190389242209390152
2	479	59	479	60	-1282043183587816810	hist(top_offenses.ShP, normed=True, label='Actual', zorder=2)	479	0	479	61	7222107967666747750
2	480	57	480	58	-9163627613333121904	plt.plot([x11,x12],[y11,y12], color='crimson', linewidth=2)	480	0	480	59	484316790663815357
2	483	27	483	28	362024042684907169	MDS(n_components=2, dissimilarity="precomputed", random_state=1, n_jobs=num_jobs)	483	10	483	91	5988568686961172068
2	485	88	485	89	-3513842968895645847	plot(xs_shp, beta.pdf(xs_shp, a_shp_top, b_shp_top, loc_shp_top, scale_shp_top), zorder=2,\n     label=r"Beta ($\alpha$ = {0:.1f}, $\beta$ = {1:.1f})".format(a_shp_top, b_shp_top))	485	0	486	88	8350162401028202733
2	491	111	491	112	5051111456445036497	ax3.hist(Ys, weights = yshastau/N.sum(yshastau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 2)	491	0	491	113	-741205510252227087
2	492	11	492	12	4925041673659339857	legend(loc=2, bbox_to_anchor=(1, 1))	492	0	492	36	-6433536194300297532
2	496	61	496	62	3126280187290522195	plt.plot([x11,x12],[y11,y12], color='greenyellow', linewidth=2)	496	0	496	63	1539564609393797537
2	497	61	497	62	-5623045123874110926	plt.plot([x21,x22],[y21,y22], color='greenyellow', linewidth=2)	497	0	497	63	2876140095415161649
2	500	50	500	51	7836330729333119884	plt.subplots(nrows=1, ncols=2, figsize=(18, 8), tight_layout=True)	500	22	500	88	-45604085668237932
2	519	89	519	90	-2896842896950927658	ax.plot(mergedData.x,mergedData.y,alpha=0.7, linewidth=3, solid_capstyle='round', zorder=2)	519	0	519	91	-503506319487502600
2	524	26	524	27	5285059341185178499	ax.legend(loc=2, bbox_to_anchor=(1, 1))	524	12	524	51	6756614097500950774
2	536	108	536	109	-6750255944149794442	get_mds(bike_df_Nouns_Adj,sample_size=Nouns_Adj_sample_size, nouns_only=False, ngram=2)	536	23	536	110	445020821902524101
2	541	52	541	53	-88398219048488580	MDS(dissimilarity="precomputed", n_components=2, metric=True, max_iter=1000)	541	6	541	82	-2542147882667638429
2	547	14	547	15	-1118616379757115710	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='Sh% during slump')	547	0	547	65	-6487735178260272710
2	557	14	557	15	1870432032525443172	ax.legend(loc=2, bbox_to_anchor=(1, 1), title='Sh% during slump')	557	0	557	65	5219519035831697410
2	558	69	558	70	-7146717711569451180	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	558	21	558	71	136146890254078205
2	571	49	571	50	-1495808070090681155	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	571	8	571	69	-879767368560633955
2	574	11	574	12	1452331968417317832	legend(loc=2, bbox_to_anchor=(1, 1), title='Period')	574	0	574	52	-3264853314292890096
2	580	58	580	59	4131067838503634134	plt.plot([x11,x12],[y11,y12], color='seagreen', linewidth=2)	580	0	580	60	-8282928624559514916
2	581	58	581	59	8950146316484772320	plt.plot([x21,x22],[y21,y22], color='seagreen', linewidth=2)	581	0	581	60	-8032574303382533542
2	586	110	586	111	7299014768155666543	bbmodel.fit(X_train_sample, [bbox_train_sample[:,i] for i in range(4)], batch_size= 32, nb_epoch= 50, verbose=2)	586	0	586	112	-7866280002810193536
2	589	71	589	72	938522408183357208	interpolate.approximate_taylor_polynomial(f, x=1, degree=2, scale=0.01)	589	14	589	85	7997301780110804467
2	594	65	594	66	1060860430691864940	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	594	17	594	67	-2313033117735671598
2	607	49	607	50	1600478968429347652	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	607	8	607	69	-7940595730713963197
2	611	34	611	35	2665854184411783636	manifold.TSNE(n_components=2, init='pca', random_state=5)	611	7	611	64	1086470632391818103
2	624	58	624	59	-2778375026955369409	plt.plot([x11,x12],[y11,y12], color='darkcyan', linewidth=2)	624	0	624	60	300993798965699097
2	625	58	625	59	-4454978349401882540	plt.plot([x21,x22],[y21,y22], color='darkcyan', linewidth=2)	625	0	625	60	1468859757005290741
2	648	69	648	70	285832861078589639	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	648	21	648	71	-6129448094641795450
2	655	59	655	60	4559824203787491573	plt.plot([x11,x12],[y11,y12], color='orangered', linewidth=2)	655	0	655	61	8445611536836787183
2	656	59	656	60	7948077174130991965	plt.plot([x21,x22],[y21,y22], color='orangered', linewidth=2)	656	0	656	61	8752365498115329764
2	669	24	669	25	7868641395990934172	PCA( n_components=2, svd_solver='randomized',whiten=True)	669	6	669	63	-3667145780244457643
2	671	50	671	51	7934980318536030388	manifold.Isomap(n_neighbors, n_components=2)	671	8	671	52	-8942874618604939282
2	684	37	684	38	4252173016298863402	ax.plot(numpy.arange(1000), test, lw=2, label = 'test')	684	0	684	55	2818934585518454179
2	685	38	685	39	-5895634894962617621	ax.plot(numpy.arange(1000), train, lw=2, label = 'train')	685	0	685	57	-3172475454525287535
2	686	65	686	66	-2785186494843935776	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	686	17	686	67	-3945529989796259388
2	699	49	699	50	-9111690098835873007	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	699	8	699	69	-8198305970427949715
2	709	19	709	20	-7242821078883869035	DBSCAN(eps = 2, min_samples = 5)	709	6	709	38	3025703673947804797
2	723	75	723	76	-1089422281564669068	np.nansum(np.nansum((1-data/34.8)*maskcalc ,axis=3),axis=2)	723	18	723	77	5698630063108707424
2	724	65	724	66	3858701388031642891	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	724	17	724	67	-7022082836842722392
2	746	87	746	88	99402995915155770	plt.hist(df_ambe['linCES'], bins=erange[1], histtype='step', color='indigo', linewidth=2, range=erange, label="Linear CES on AmBe data in 34 kg fiducial volume")	746	0	746	161	3900187054221159842
2	747	89	747	90	-47579457859205314	plt.hist(df_ambe['CsCES'], bins=erange[1], histtype='step', color='royalblue', linewidth=2, range=erange, label="$^{137}$Cs CES on AmBe data in 34 kg fiducial volume")	747	0	747	167	3887370106868034510
2	748	89	748	90	1919665523921209341	plt.hist(df_ambe['parCES'], bins=erange[1], histtype='step', color='seagreen', linewidth=2, range=erange, label="Parametrized CES on AmBe data in 34 kg fiducial volume")	748	0	748	169	9061048245698901766
2	756	47	756	48	-9109284131870905624	plt.axvline(linevalue,0,450, linewidth=2, linestyle='--', color="crimson", alpha=0.8)	756	8	756	93	-500900436344501524
2	774	86	774	87	4020311079636272526	plt.hist(df_mxe['linCES'], bins=erange[1], histtype='step', color='indigo', linewidth=2, range=erange, label="Linear CES on BG and $^{137}$Cs data in 34 kg fiducial volume")	774	0	774	173	-5620499474950768485
2	775	88	775	89	1321361076873276196	plt.hist(df_mxe['CsCES'], bins=erange[1], histtype='step', color='royalblue', linewidth=2, range=erange, label="$^{137}$Cs CES on BG and $^{137}$Cs data in 34 kg fiducial volume")	775	0	775	179	4743675190875349598
2	776	88	776	89	6087415591844748708	plt.hist(df_mxe['parCES'], bins=erange[1], histtype='step', color='seagreen', linewidth=2, range=erange, label="Parametrized CES on BG and $^{137}$Cs data in 34 kg fiducial volume")	776	0	776	181	-3896685568587284316
2	778	43	778	44	929890951839514209	CountVectorizer(min_df=2,stop_words='english')	778	20	778	66	6948516833950009483
2	778	85	778	86	1302184131250684262	plt.hist(df_cs['linCES'], bins=erange[1], histtype='step', color='indigo', linewidth=2, range=erange)	778	0	778	101	-7607582504984923978
2	779	87	779	88	698643346685794193	plt.hist(df_cs['CsCES'], bins=erange[1], histtype='step', color='royalblue', linewidth=2, range=erange)	779	0	779	103	-3484558962940062526
2	780	87	780	88	2754601100708106933	plt.hist(df_cs['parCES'], bins=erange[1], histtype='step', color='seagreen', linewidth=2, range=erange)	780	0	780	103	-4276272992596949454
2	786	47	786	48	-9042830088285207556	plt.axvline(linevalue,0,450, linewidth=2, linestyle='--', color="crimson", alpha=0.8)	786	8	786	93	7771442096837858607
2	818	41	818	42	-3907233016445788967	CountVectorizer(min_df=2,ngram_range=(3,3),stop_words='english')	818	18	818	82	7169445087238583346
2	855	15	855	16	-4429204392673093069	plt.legend(loc=2, frameon=False, prop={'family':'serif'})	855	0	855	57	1302526881105933421
2	1086	65	1086	66	290581694709573910	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	1086	17	1086	67	-208394453148459502
2	1099	49	1099	50	4010178901102039301	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	1099	8	1099	69	3055510635127195818
2	1121	57	1121	58	5815939143460813373	gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)	1121	8	1121	68	-5755679163829373569
2	1122	65	1122	66	-7538664106637628134	np.nansum(np.nansum(datam[:,:,:,:],axis=3),axis=2)	1122	17	1122	67	3446541547539086049
2	1135	49	1135	50	-7853851785721818700	plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)	1135	8	1135	69	5700908834938180443
2	1229	44	1229	45	6689105457699865422	plot_flux_in_out(pert,varlist,'FluxSum',row=2,col=3)	1229	0	1229	52	2057609927927599845
2	1266	33	1266	34	-971387310040924079	plot_flux_total(pert,varlist,row=2,col=3)	1266	0	1266	41	6804114166335491736
2	1319	42	1319	43	-2407269466835328666	fig.subplots_adjust(right=2.4,top=2)	1319	8	1319	44	-1321493694758122187
2	1353	83	1353	84	6422702686197679788	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=2)	1353	35	1353	85	4022973475185842890
2	1354	97	1354	98	6027109901849959832	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=2)	1354	49	1354	99	6277834113552346642
2	1443	65	1443	66	-9134096133403513122	np.nanmean(diff[t,:,:,:],axis=2)	1443	35	1443	67	8361042359298025414
2	1444	97	1444	98	39023293399636252	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=2)	1444	49	1444	99	-8601077487609853523
2	1741	143	1741	144	-2672274194135286705	plt.hist(np.divide(np.subtract(df_ambe['linCES'],linCESerr(df_ambe)),df_ambe['linCES']), bins=1000, histtype='step', color='indigo', linewidth=2, range=erange, label="Linear CES")	1741	0	1741	179	-5501242117181297128
2	1742	143	1742	144	-344852431335966536	plt.hist(np.divide(np.subtract(df_ambe['CsCES'],CsCESerr(df_ambe)),df_ambe['CsCES']), bins=1000, histtype='step', color='royalblue', linewidth=2, range=erange, label="Single line CES")	1742	0	1742	184	2843532451055559970
2	1812	45	1812	46	-5591112843026657886	plt.legend(bbox_to_anchor=(1.05, 8), loc=2, borderaxespad=0.)	1812	4	1812	65	2857307185131603525
2	1823	35	1823	36	2272197939361867871	plt.subplots(ncols=2,nrows=2,sharex=True)	1823	16	1823	57	8309663813104248934
2	1823	43	1823	44	7998062505225718804	plt.subplots(ncols=2,nrows=2,sharex=True)	1823	16	1823	57	8309663813104248934
2	1907	27	1907	28	8841220081921941844	plot_dynStLayers({0:pert_const, 1 :pert_bench},['LaUH1TH_ave','LaVH1TH_ave','LaUH2RHO_ave','LaVH2RHO_ave'],\\n                 reg=1,row=2,col=2)	1906	0	1907	35	-5132290542186514365
2	1907	33	1907	34	607667251053735313	plot_dynStLayers({0:pert_const, 1 :pert_bench},['LaUH1TH_ave','LaVH1TH_ave','LaUH2RHO_ave','LaVH2RHO_ave'],\\n                 reg=1,row=2,col=2)	1906	0	1907	35	-5132290542186514365
2	1921	57	1921	58	-6612586045753581623	plt.axhline(0,color='crimson', linestyle='--', linewidth=2)	1921	0	1921	59	4732013084329166970
1	14	24	14	25	-370558012479072584	g.add_edge(1, 1, weight=1)	14	0	14	26	-7768502096008592835
1	15	78	15	79	-3551353710051389623	f.drop(['Full count Pupae', 'Household_ID', 'Full count Larvae'], axis=1)	15	7	15	80	-8650575976673278689
1	15	80	15	81	-7329673531207635898	pd.read_excel(file_i, u'Sheet1', header=0, parse_cols="A:K", skip_footer=1)	15	7	15	82	371090447531890935
1	16	44	16	45	8887653299258429185	data.drop(['Region', 'Channel'], axis = 1, inplace = True)	16	4	16	62	4231367469732980082
1	17	44	17	45	-2609412096801956766	temp.drop(['Region', 'Channel'], axis = 1, inplace = True)	17	4	17	62	-1401559134938740107
1	17	44	17	45	-2128271509729496188	data.drop(['Region', 'Channel'], axis = 1, inplace = True)	17	4	17	62	-6719337437592653012
1	17	44	17	45	4629086518267580504	data.drop(['Region', 'Channel'], axis = 1, inplace = True)	17	4	17	62	-3117776538202309472
1	18	44	18	45	-5858681096043763478	data.drop(['Region', 'Channel'], axis = 1, inplace = True)	18	4	18	62	2058597960675378199
1	18	44	18	45	7601368645566152335	data.drop(['Region', 'Channel'], axis = 1, inplace = True)	18	4	18	62	5430183413544763868
1	18	51	18	52	5251262606900594335	np.loadtxt("lowp_finalresults.csv",skiprows=1,delimiter= ",")	18	7	18	68	-4633651208326146581
1	19	32	19	33	-4610881880034306909	np.sum(diff**2, axis=1)	19	11	19	34	-5523739458479463192
1	19	34	19	35	-1389370961587505363	plt.imshow(M, interpolation='none', origin='lower',\n                cmap=cm.jet, vmax=1, vmin = -.15, extent=(0,5,0,5))	18	5	19	67	-9046888039748304835
1	20	34	20	35	-6777257456221908991	recipes.drop(['Unnamed: 0'], axis=1, inplace=True)	20	0	20	50	6270750415696184358
1	20	67	20	68	-4125001413499276771	df.drop(['discharge_disposition_id','admission_type_id'], axis=1)	20	4	20	69	1136822881025204752
1	21	35	21	36	-5016571238098863267	fitsio.read_header(f1, ext=1)	21	8	21	37	195181680336027396
1	21	77	21	78	-6748534678759929904	tf.reduce_sum(tf.abs(tf.add(xtr, tf.neg(xte))), reduction_indices=1)	21	11	21	79	-6428793498088085467
1	22	35	22	36	5424371498432716991	fitsio.read_header(f2, ext=1)	22	8	22	37	5840205015924306401
1	22	42	22	43	6667092221509703372	AdaBoostClassifier(random_state=1,n_estimators=800,learning_rate=0.9,algorithm='SAMME',\n                             base_estimator=DecisionTreeClassifier(max_depth=3))	22	10	23	80	1100203830827759889
1	22	54	22	55	-9107461382463327521	redis.StrictRedis(host='localhost', port=6379, db=1)	22	4	22	56	7569286207406513812
1	22	87	22	88	-62365824054733014	train_test_split(X, y, test_size=0.20, random_state=1)	22	35	22	89	6899462015439271802
1	25	32	25	33	6284106504600422742	df.drop('experience', axis=1)	25	5	25	34	2976491867517744904
1	25	36	25	37	-5772856011045074784	FunctionApproximator(n_out=1, n_hidden=f)	25	9	25	50	-3692493773598903109
1	25	60	25	61	-5526570997373040720	regions.apply(get_color, axis=1)	25	30	25	62	8491437656659003668
1	26	43	26	44	5567638612851149346	ax.plot_surface(X, Y, M, cmap=cm.jet, vmax=1, vmin = -.15 )	26	0	26	59	-2511432488447796266
1	27	30	27	31	-2741205269631717910	np.insert(X, 0, 1, axis = 1)	27	4	27	32	-361242094545205003
1	27	62	27	63	5566450096019568069	Te.data2array('../../Connectomes/Jonathan/AAL.npy', dic=1)	27	6	27	64	1029981653979781957
1	27	120	27	121	-6001568670601757549	df[['id','co_w','co_a']].apply(lambda x: conv.convert_co_ID(x.values[0], x.values[1], x.values[2]), axis=1)	27	15	27	122	6145973696361724977
1	28	129	28	130	3436710075882917930	df[['id','co_a','co_w']].apply(lambda x: conv.convert_co_ID(x.values[0], x.values[1], x.values[2]), axis=1)	28	24	28	131	-7256208746542743402
1	29	64	29	65	-3362689020893534822	tf.reduce_sum(Y*tf.log(hypothesis), axis=1)	29	23	29	66	-5045470350883017239
1	29	139	29	140	-1573703386299853470	df[['id','co_w','co_a']].apply(lambda x: conv.convert_co_ID_correcting(x.values[0], x.values[1], x.values[2]), axis=1)	29	23	29	141	2379673949398135214
1	32	39	32	40	1762749205441977082	d[...,b0].std(axis=3, ddof=1)	32	12	32	41	6842214693927361060
1	32	63	32	64	8018409629580347514	np.sum(np.dot(Z, X.T)*float(nz)/float(nx),axis=1)	32	16	32	65	4055829661056653046
1	32	113	32	114	6625371663474708281	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=c, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	32	13	32	241	-6282894579066499134
1	32	239	32	240	-3088551551562441322	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=c, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	32	13	32	241	-6282894579066499134
1	33	21	33	22	4673212121104975665	sns.heatmap(cor,vmax=1,square=True)	33	0	33	35	-7274884903674880234
1	33	52	33	53	384518760721615164	kobe.drop(['team_id', 'team_name', 'matchup'], axis=1, inplace=True)	33	0	33	68	-3594080594744589864
1	34	40	34	41	5949779791731498573	datagen.flow(x, batch_size=1,\n                          save_to_dir='dogs-cats/preview', save_prefix='cat', save_format='jpeg')	34	13	35	97	4302223503363760704
1	34	53	34	54	-7061729593255531547	LogisticRegression(random_state=1)	34	21	34	55	1446283581966820393
1	35	29	35	30	6615571684608870263	army.drop([2009, 2010], axis=1, inplace=True)	35	0	35	45	-355336200225207185
1	35	45	35	46	-2299769126636529636	np.sum(compute_rbf(Z,X),axis=1)	35	16	35	47	2261835941553116767
1	35	124	35	125	-4237817146961553500	df[['id','no2_w','no2_a']].apply(lambda x: conv.convert_no2_ID(x.values[0], x.values[1], x.values[2]), axis=1)	35	16	35	126	6695698559193301619
1	36	54	36	55	-2648189507797797229	safe_loans_raw.sample(percentage, seed = 1)	36	13	36	56	3352782534549169229
1	36	69	36	70	9127388814947473179	post_street.drop(post_street.columns[[0,2,3,5,6]],axis = 1)	36	12	36	71	-7722379957170636023
1	36	133	36	134	4287653346280466009	df[['id','no2_a','no2_w']].apply(lambda x: conv.convert_no2_ID(x.values[0], x.values[1], x.values[2]), axis=1)	36	25	36	135	6512478554028703913
1	37	76	37	77	-5660127628893955367	GradientBoostingClassifier(n_estimators=100, verbose=1)	37	23	37	78	-5667541124086464248
1	37	143	37	144	-1582301133429810289	df[['id','no2_w','no2_a']].apply(lambda x: conv.convert_no2_ID_correcting(x.values[0], x.values[1], x.values[2]), axis=1)	37	24	37	145	-4157484926101638107
1	38	78	38	79	2319022072280783802	GradientBoostingClassifier(n_estimators=100, verbose=1)	38	25	38	80	-653183788370041305
1	39	30	39	31	-6322085236312862911	temp.sum(axis=1)	39	16	39	32	-8711875303744084351
1	39	30	39	31	2210341636049448379	dict(algorithm=1, trees=5)	39	15	39	41	6497931345568479978
1	39	40	39	41	-7934698237711414868	ps_id_fee.drop('cpt',axis = 1)	39	12	39	42	6877868323959042908
1	39	113	39	114	1490702409944128967	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.005, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	39	9	39	241	3476444751173404693
1	39	239	39	240	8306679742016097793	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.005, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	39	9	39	241	3476444751173404693
1	40	55	40	56	-8494202016784232772	products.random_split(.8, seed=1)	40	24	40	57	3077438179693839621
1	40	55	40	56	-7503663396121383055	products.random_split(.8, seed=1)	40	24	40	57	4620031767723599085
1	40	55	40	56	1365581925645148223	products.random_split(.8, seed=1)	40	24	40	57	-8585181202762813588
1	41	40	41	41	-3676099555231345867	B_crop.sum(axis=1)	41	24	41	42	5386508020064342999
1	41	46	41	47	8838083279852830906	fileinput.input(path, inplace=1)	41	16	41	48	-2520821802399031479
1	41	55	41	56	-24770606703955159	products.random_split(.8, seed=1)	41	24	41	57	6739806165897971473
1	41	66	41	67	-56227439289399322	dt.datetime(year = int(row[1]), month = int(row[2]), day=1)	41	9	41	68	-8393723415194769969
1	42	46	42	47	6174534593120701628	samples.apply(np.sum, axis=1)	42	19	42	48	-7007915873150714400
1	42	47	42	48	6339646860958823085	VideoClip(make_frame, duration=1)	42	16	42	49	-7510466507719808512
1	43	96	43	97	7028277871116509875	mx.model.FeedForward.load('model/inception-bn', 126, ctx=mx.cpu(), numpy_batch_size=1)	43	12	43	98	-8510594930139542073
1	45	50	45	51	-1350065332625795025	df.xs(structure, level='Structure', axis=1)	45	9	45	52	-1641202450005878175
1	45	60	45	61	6684122066731689189	np.concatenate((X_img, X[img_id]), axis=1)	45	20	45	62	-5144956128537293628
1	45	84	45	85	6717027740371602477	df.xs(structure, level='Structure', axis=1).xs('AAA', level='planID', axis=1)	45	9	45	86	6684867388733151312
1	46	50	46	51	-4332249585859775673	df.xs(structure, level='Structure', axis=1)	46	9	46	52	-5799502232293084558
1	46	70	46	71	8777212523943509804	Te.data2array('./cluster/clus_%s_con.npy'%(typ), dic=1)	46	17	46	72	3088196930348303620
1	46	84	46	85	-8624852069310506783	df.xs(structure, level='Structure', axis=1).xs('AXB', level='planID', axis=1)	46	9	46	86	-42500496775124447
1	46	113	46	114	864012394335645583	df[['m_co','m_co_r0']].apply(lambda x: conv.mics_co_ppb_polyfit(x.values[0], x.values[1]), axis=1)	46	17	46	115	3886125269907490456
1	48	69	48	70	5324881158569491492	post_street.drop(post_street.columns[[0,2,3,5,6]],axis = 1)	48	12	48	71	8377100158956189172
1	49	36	49	37	-6239083410611698641	FunctionApproximator(n_out=1, n_hidden=i)	49	9	49	50	-1755704797973505557
1	50	52	50	53	-6935793798803308889	np.concatenate((X_img, zeros), axis=1)	50	16	50	54	-5057798832243345838
1	50	57	50	58	-4895536062830019688	samples_ratio.apply(np.sum,axis=1)	50	25	50	59	-5947873793010072951
1	50	59	50	60	-2410051270560933746	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	50	0	50	73	-3788675041583091273
1	51	48	51	49	6773950555784993364	np.sum((vx-Z)**2, axis=1)	51	25	51	50	5442485658357640315
1	51	51	51	52	2075869142121792719	sh.drop(sh.columns[[7,8,9,10,11,12]],axis=1)	51	9	51	53	8127494331471468032
1	51	64	51	65	-3778442685708230475	tf.reduce_sum(Y*tf.log(hypothesis), axis=1)	51	23	51	66	-6786136825474270048
1	52	24	52	25	2781396328569313699	ax.legend(scatterpoints=1, markerscale=.7, labelspacing=1)	52	0	52	58	4381367320041715016
1	52	47	52	48	-9024159619906922583	army.interpolate(method='linear', axis=1, limit=5, inplace=False, limit_direction='both')	52	8	52	97	-2516046408702769049
1	52	56	52	57	657338941447974327	ax.legend(scatterpoints=1, markerscale=.7, labelspacing=1)	52	0	52	58	4381367320041715016
1	52	64	52	65	3127603291538850627	sales.random_split(.9,seed=1)	52	37	52	66	8215575168581698962
1	53	51	53	52	1600789614345239321	np.mean(train_scores, axis=1)	53	24	53	53	4391859669504145273
1	53	55	53	56	7696956200536333088	products.random_split(.8, seed=1)	53	24	53	57	-4050123718198038550
1	53	72	53	73	1556369040726197900	training_and_validation.random_split(0.5, seed=1)	53	25	53	74	574616397772984542
1	53	91	53	92	-669170169729478425	data_subset.drop('over_200000', axis = 1)	53	52	53	93	-3244358771066250781
1	54	36	54	37	-1221800600759595061	AAA_df.mean(axis = 1)	54	17	54	38	-7899346380902928897
1	54	39	54	40	6775945786765517602	df.drop(['dag', 'tijdstip'], axis=1)	54	5	54	41	-4789002271363032765
1	54	49	54	50	8092407383039389959	np.mean(test_scores, axis=1)	54	23	54	51	-6455139231901448341
1	54	64	54	65	-4260167274724724979	plt.axvline(a_s.mean(), color='r', linestyle='solid', linewidth=1)	54	0	54	66	-6145743003215951883
1	54	73	54	74	866567802771022605	AAA_df.mean(axis = 1)	54	54	54	75	-6539191333611586644
1	54	93	54	94	892786917204284498	datasets.make_classification(n_features = 2, n_informative = 1,\n                                                            n_redundant = 1, n_clusters_per_class = 1,\n                                                            random_state = 1 )	54	32	56	78	1581585273349022126
1	54	96	54	97	-7713896161547048192	AAA_df.std(axis = 1)	54	78	54	98	8113699974004711803
1	54	128	54	129	-1970584763587069392	AAA_df.mean(axis = 1)	54	109	54	130	-4692492223518314651
1	54	151	54	152	2538864340936221300	AAA_df.std(axis = 1)	54	133	54	153	-773356812645722
1	55	28	55	29	6305154142037970397	AAA_df.mean(axis = 1)	55	9	55	30	-8715178048487088070
1	55	34	55	35	5287418813677499791	log_df.drop(columns_to_drop, axis=1, inplace=True)	55	0	55	50	1727816420484357192
1	55	41	55	42	-2963663064256932590	np.var(x, axis=0, ddof=1)	55	18	55	43	5528576446472848983
1	55	44	55	45	8546638435476250644	Tf.triSup(zeros((512,512)), ind=1)	55	12	55	46	-979023319716131994
1	55	59	55	60	-4477563182794015252	df.apply (lambda row: keep_by_time (row),axis=1)	55	13	55	61	-8141684288716382262
1	55	74	55	75	87951987710999733	datasets.make_classification(n_features = 2, n_informative = 1,\n                                                            n_redundant = 1, n_clusters_per_class = 1,\n                                                            random_state = 1 )	54	32	56	78	1581585273349022126
1	55	100	55	101	3397058076520468222	datasets.make_classification(n_features = 2, n_informative = 1,\n                                                            n_redundant = 1, n_clusters_per_class = 1,\n                                                            random_state = 1 )	54	32	56	78	1581585273349022126
1	56	49	56	50	1813786633581852729	ax[0, 0].plot(Xtrue[:10].T, c='gray', lw=1)	56	8	56	51	2406022524506317623
1	56	56	56	57	4575285269622286371	input_data['labels'].replace(to_replace = "PO", value = 1, inplace = True)	56	0	56	74	-3477429549683594382
1	56	75	56	76	8934143740999516124	datasets.make_classification(n_features = 2, n_informative = 1,\n                                                            n_redundant = 1, n_clusters_per_class = 1,\n                                                            random_state = 1 )	54	32	56	78	1581585273349022126
1	56	117	56	118	-1717310658802178113	df[['m_no2','m_no2_r0']].apply(lambda x: conv.mics_no2_ppb_polyfit(x.values[0], x.values[1]), axis=1)	56	18	56	119	-6791798012150905745
1	57	36	57	37	119229476392617575	AXB_df.mean(axis = 1)	57	17	57	38	3941960999513419929
1	57	49	57	50	2238468427738037566	ax[1, 1].plot(Xtrue[:10].T, c='gray', lw=1)	57	8	57	51	3080807735429798823
1	57	62	57	63	-4710985685066284830	np.max(get_p_y_given_x(X[start:end]), axis=1)	57	19	57	64	3201398896700186729
1	57	73	57	74	8113441322644176621	AXB_df.mean(axis = 1)	57	54	57	75	-5002723103364939868
1	57	96	57	97	-4095806877079375694	AXB_df.std(axis = 1)	57	78	57	98	4602714537399669977
1	57	128	57	129	4609267869037442753	AXB_df.mean(axis = 1)	57	109	57	130	7014488090572875430
1	57	151	57	152	2009270568386185594	AXB_df.std(axis = 1)	57	133	57	153	-7701653995213660068
1	58	28	58	29	-2668124571164274325	AXB_df.mean(axis = 1)	58	9	58	30	-3134601024614206309
1	58	36	58	37	-4065789928913512770	human_tissue_experiment.dropna(axis=1, how='all')	58	0	58	49	-2604412046367907468
1	58	42	58	43	720649778789022633	ax[0, 0].plot(X[:10].T, c='black', lw=1)	58	4	58	44	9104753192169087353
1	58	92	58	93	815582582776531694	roads_data_df[['start_x', 'start_y', 'end_x', 'end_y']].isnull().any(axis=1)	58	18	58	94	4752105042842472435
1	59	42	59	43	-5374221596971725489	ax[1, 1].plot(Y[:10].T, c='black', lw=1)	59	4	59	44	-2559164558799912149
1	60	37	60	38	8272572140643051627	image[:, i1:i2].mean(axis=1)	60	11	60	39	711857606137770722
1	60	46	60	47	-7382458354436580746	pd.concat([site_df, mzb_df, hi_df], axis=1)	60	5	60	48	-6163684150328528493
1	60	86	60	87	4708554433009539990	Te.data2array('./FCDclust%s/win_%i_typ_%s.npy'%(ddd,w,typ), dic=1)	60	22	60	88	-1841522010785210394
1	62	124	62	125	5393355394475402983	plt.scatter(train[:,0], train[:,1], color='blue', marker='o',s=40,lw=2,label='train',zorder=1)	62	32	62	126	6840088343666820681
1	63	123	63	124	-7172232549540288002	plt.scatter(test[:,0], -0.23+0*test[:,1], color='red', s=40,marker='^',label='test',zorder=1)	63	32	63	125	7805084881851787271
1	64	50	64	51	-5322999353629734003	data.drop([target_feature], axis = 1, inplace = False)	64	15	64	69	5742456312976705128
1	64	117	64	118	-6664114354525305323	plt.scatter(test[:,0], test[:,1], color='red', s=40,label='test ground truth',zorder=1)	64	32	64	119	-7554529159740494258
1	65	19	65	20	-3184000996856866063	SVC(gamma=2, C=1)	65	4	65	21	-3939150612301952104
1	65	42	65	43	6388173899049949322	data.drop('Delicatessen', axis=1)	65	11	65	44	4047553861660546599
1	66	28	66	29	7370087715729652330	np.mean(Xk, axis = 1)	66	9	66	30	4003650717104008860
1	67	47	67	48	-1246132948512636222	census_df.drop('STATE_ASIAN', axis=1)	67	12	67	49	-5996575071151795876
1	67	53	67	54	-7995100031133261111	df.apply(MatchTitles, axis=1)	67	26	67	55	1020725173370910198
1	67	70	67	71	-3744058381153836362	RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)	67	4	67	72	4944537880148559078
1	67	94	67	95	6935450242443038138	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
1	67	112	67	113	-3652593174121645773	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
1	68	24	68	25	2218012905559149104	MLPClassifier(alpha=1)	68	4	68	26	605975672206265716
1	68	29	68	30	4400321761500964422	pd.concat([last_data['GSPC'],\n  last_data['Jp8692'],\n  last_data['Jp4684'],\n  last_data['Jp9076'],\n  last_data['Jp8358']], axis=1)	64	19	68	31	-3277533758365645587
1	68	44	68	45	240869259690723102	census_df.drop('STATE_PI', axis=1)	68	12	68	46	-6185602511395917582
1	68	56	68	57	10548965382349603	StratifiedKFold(kfold, shuffle=True, random_state=1)	68	6	68	58	-5917931965043727005
1	68	88	68	89	-2823872499275935021	roads_data_df[['start_x', 'start_y', 'end_x', 'end_y']].isnull().any(axis=1)	68	14	68	90	-4064062890526440969
1	69	50	69	51	6278136186414946601	advise_wide_field(vt, wprojection_planes=1)	69	9	69	52	6329682888718327186
1	70	25	70	26	-903294818545974536	g2.add_edge(1, 0, weight=1)	70	0	70	27	-2710105143000216862
1	70	33	70	34	7144433944771501469	np.concatenate( [\n                        stats.poisson.rvs( lambda_1_true, size = (N,1)),\n                        stats.poisson.rvs( lambda_2_true, size = (N,1))\n                        ],  axis=1 )	67	7	70	36	122933646333772093
1	70	62	70	63	8631192513290576780	loans_data.random_split(.8, seed=1)	70	29	70	64	6235858093813274294
1	70	138	70	139	-6620985641238722392	pd.concat([meanWeightChangeBySubreddit, stdWeightChangeBySubreddit, medianWeightChangeBySubreddit], axis=1)	70	33	70	140	5122965313759712745
1	71	42	71	43	4105892405990996097	AAA_df.mean(axis = 1)	71	23	71	44	1161709937676775928
1	71	85	71	86	1632514781223421698	AAA_df.mean(axis = 1)	71	66	71	87	1508299219102370560
1	71	128	71	129	7603033057920237197	AAA_df.mean(axis = 1)	71	109	71	130	-4353608161695777575
1	73	53	73	54	8364102933612375021	census_df.drop('STATE_OTHER_ALONE', axis=1)	73	12	73	55	-798752605791504684
1	73	57	73	58	-6113323753560664983	ax.plot_surface(L, C, utility, rstride=1, cstride=1, cmap=mpl.cm.terrain,\n                                  linewidth=0, vmin=-10, vmax=np.max(utility),\n                                  antialiased=False)	73	18	75	52	2684203492910617269
1	73	64	73	65	8285709384225025473	tf.reduce_sum(Y*tf.log(hypothesis), axis=1)	73	23	73	66	-3452278186051579661
1	73	68	73	69	7911766083057575474	ax.plot_surface(L, C, utility, rstride=1, cstride=1, cmap=mpl.cm.terrain,\n                                  linewidth=0, vmin=-10, vmax=np.max(utility),\n                                  antialiased=False)	73	18	75	52	2684203492910617269
1	74	50	74	51	7076824533685280389	census_df.drop('STATE_TWO_PLUS', axis=1)	74	12	74	52	-5906595836879911226
1	74	78	74	79	7879152448506032457	df.drop(['str_year_x', 'str_year_y', 'Airport', 'Year', 'airport_year'], axis=1, inplace=1)	74	0	74	91	2711884942526356194
1	74	89	74	90	9015834105753326790	df.drop(['str_year_x', 'str_year_y', 'Airport', 'Year', 'airport_year'], axis=1, inplace=1)	74	0	74	91	2711884942526356194
1	75	34	75	35	-4718399468097885924	sns.heatmap(percentiles, vmin=1, vmax=99, annot=True)	75	4	75	57	6796659196746609956
1	75	39	75	40	-7263290536948933685	df.drop(["is_duplicated"], axis = 1)	75	5	75	41	8187166223605740048
1	75	84	75	85	1557041624604110977	np.array( [stats.poisson.pmf( data[:,0], _x) for _x in x]).prod(axis=1)	75	15	75	86	6992849026708061439
1	76	61	76	62	394353285409723810	ps_ave_cpt.drop(ps_ave_cpt.columns[[1,2,3,4]],axis=1)	76	10	76	63	4630521406019603301
1	76	80	76	81	5805978240381253042	data[data[best_feature] == value].drop(best_feature, axis=1)	76	22	76	82	-4855546080645793904
1	76	84	76	85	3405642602592556933	np.array( [stats.poisson.pmf( data[:,1], _y) for _y in y]).prod(axis=1)	76	15	76	86	8752401154922921287
1	77	32	77	33	5474890706114044314	FunctionApproximator(n_out=1, n_hidden=5)	77	5	77	46	1645432426196939550
1	77	42	77	43	-8147221930592236365	AXB_df.mean(axis = 1)	77	23	77	44	8909021554554887593
1	77	55	77	56	-8885258634063837738	np.fromfile(fname, dtype=header_dt, count=1)	77	13	77	57	-2566957685239405899
1	77	60	77	61	-528277909838460120	ax[1].hexbin(teff,mag,bins='log',gridsize=400,mincnt=1)	77	7	77	62	-3571683260291060670
1	77	78	77	79	1713893734643677848	create_image_from_visibility(vt, npixel=npixel, cellsize=0.001, nchan=1,\n                                     polarisation_frame=PolarisationFrame('stokesI'))	77	8	78	85	-3904061870113493004
1	77	85	77	86	-7310834061472038768	AXB_df.mean(axis = 1)	77	66	77	87	-2040757445286481914
1	77	128	77	129	113100865857940740	AXB_df.mean(axis = 1)	77	109	77	130	-1175171428099230637
1	78	56	78	57	-779708457722846132	input_data['labels'].replace(to_replace = "PO", value = 1, inplace = True)	78	0	78	74	-2657967322420518796
1	78	85	78	86	-5344631831430959316	dfgenre[['Foreign', 'Short', 'Documentary']].apply(any, axis = 1)	78	22	78	87	-3416436706562740713
1	78	108	78	109	5919975799657991519	roads_data_df[['start_x', 'start_y', 'end_x', 'end_y']].isnull().any(axis=1)	78	34	78	110	4457123578812784038
1	79	50	79	51	-8522260384785026061	df.drop(['GP_RANK', 'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'FGM_RANK',\n            'FGA_RANK', 'FG_PCT_RANK', 'FG3M_RANK', 'FG3A_RANK', 'FG3_PCT_RANK',\n            'FTM_RANK', 'FTA_RANK', 'FT_PCT_RANK', 'OREB_RANK', 'DREB_RANK',\n            'REB_RANK', 'AST_RANK', 'TOV_RANK', 'STL_RANK', 'BLK_RANK', 'BLKA_RANK',\n            'PF_RANK', 'PFD_RANK', 'PTS_RANK', 'PLUS_MINUS_RANK', 'DD2_RANK',\n            'TD3_RANK', 'CFID', 'CFPARAMS'], axis=1, inplace=True)	74	4	79	66	8626583835717577739
1	79	58	79	59	8382914092472048125	pd.concat([n_df,aa_df,c_df],axis=1)	79	25	79	60	-7139465495252850220
1	79	59	79	60	7176917937475801050	frontiere(f, X_test, y_pred, w=None, step=50, alpha_choice=1)	79	0	79	61	841005217914756798
1	79	154	79	155	-8440834857803439703	data.reindex_axis([['94', '95', '96', '97', '98', '99', '00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13']], axis=1)	79	7	79	156	8688420814206598050
1	80	38	80	39	5195355340344536729	r_mat_g[:,add].sum(axis=1)	80	14	80	40	5152396883474519302
1	80	68	80	69	1681952357677785504	r_mat_g[:,drop].sum(axis=1)	80	43	80	70	-2498846278562275238
1	81	42	81	43	4454039590014004887	ax.bar(np.arange(24), u,\n    color='#3F5D7D',edgecolor=None, alpha=1, bottom=m+f)	80	8	81	56	5456450715232711026
1	82	22	82	23	4205034358367722032	countries.idxmax(axis=1)	82	0	82	24	662557088938932397
1	82	28	82	29	-7426659306510664210	log_df.drop('usertag', axis=1, inplace=True)	82	0	82	44	1634620502829110755
1	82	49	82	50	-3897962092958405599	neighbors.KNeighborsClassifier(n_neighbors=1)	82	6	82	51	6020202503846291522
1	83	38	83	39	2621360839944312533	df.drop(dropMe, axis=1)	83	17	83	40	3837485591450293102
1	84	41	84	42	1099108709879052889	new_data.drop('Detergents_Paper', axis = 1, inplace = True)	84	0	84	59	-8666307693830091924
1	85	35	85	36	-4160899862880188148	pd.concat([log_return_data['GSPC'],\n  log_return_data['Jp8692'],\n  log_return_data['Jp4684'],\n  log_return_data['Jp9076'],\n  log_return_data['Jp8358']], axis=1)	81	4	85	37	-8935144120697994759
1	85	50	85	51	7646198458879074722	df.xs(structure, level='Structure', axis=1)	85	9	85	52	-7981086086013835996
1	85	53	85	54	-3141297507730490661	test_pos_data.drop(['class'], axis=1)	85	18	85	55	-5379252033247722191
1	85	85	85	86	-4227288635344981107	pd.concat([show_tollgate_1_entry,temp_dateframe_10],axis=1)	85	28	85	87	-6178364973099346269
1	85	85	85	86	2682093352798786971	df.xs(structure, level='Structure', axis=1).xs(patient, level='patID', axis=1)	85	9	85	87	-4598572903390673028
1	86	20	86	21	-3988811257946816675	dict(\n    minor_tick_in=None,\n    minor_tick_out=None,\n    major_tick_in=None,\n    major_label_text_font_size="10pt",\n    major_label_text_font_style="normal",\n    axis_label_text_font_size="10pt",\n\n    axis_line_color='#AAAAAA',\n    major_tick_line_color='#AAAAAA',\n    major_label_text_color='#666666',\n\n    major_tick_line_cap="round",\n    axis_line_cap="round",\n    axis_line_width=1,\n    major_tick_line_width=1,\n)	72	15	88	1	-7724905104362843423
1	86	50	86	51	-1397529470764517758	df.xs(structure, level='Structure', axis=1)	86	9	86	52	-2245293098066772027
1	86	85	86	86	5353980043945618317	df.xs(structure, level='Structure', axis=1).xs(patient, level='patID', axis=1)	86	9	86	87	1408014981016021308
1	87	26	87	27	7009375182660614576	dict(\n    minor_tick_in=None,\n    minor_tick_out=None,\n    major_tick_in=None,\n    major_label_text_font_size="10pt",\n    major_label_text_font_style="normal",\n    axis_label_text_font_size="10pt",\n\n    axis_line_color='#AAAAAA',\n    major_tick_line_color='#AAAAAA',\n    major_label_text_color='#666666',\n\n    major_tick_line_cap="round",\n    axis_line_cap="round",\n    axis_line_width=1,\n    major_tick_line_width=1,\n)	72	15	88	1	-7724905104362843423
1	87	94	87	95	406082034203782743	roc_curve(y_validation_set, y_predicted_proba[:, 1], pos_label=1)	87	31	87	96	-581146675331746484
1	87	96	87	97	-9056740017852311892	AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy',max_depth=4),n_estimators=1,learning_rate=4)	87	6	87	114	-5161303527293773844
1	88	35	88	36	2511063484720594831	sns.cubehelix_palette(light=1, as_cmap=True)	88	7	88	51	9079250450299334381
1	88	46	88	47	-1189830066606667818	np.triu_indices_from(axes, k=1)	88	17	88	48	-3141374479098559746
1	88	48	88	49	3694466815681632909	pd.concat([test, dfWithClass], axis=1)	88	12	88	50	-1501971626195536580
1	89	48	89	49	-1252080189985954412	ax.grid(color='grey', linestyle='--', linewidth=1, alpha=0.2)	89	0	89	61	-5278709860864357982
1	89	62	89	63	1228023634842727964	canvas.get_tk_widget().pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)	89	0	89	64	-2532626043923584376
1	90	34	90	35	-2370437893458060866	plt.imshow(M, interpolation='none', origin='lower',\n                cmap=cm.jet, vmax=1, vmin = -.15, extent=(0,5,0,5))	89	5	90	67	-56654566960749208
1	90	39	90	40	6206615895063153832	pd.DataFrame(result[result['match_bool']==1])\n              .drop('match_bool', axis=1)	89	14	90	41	-3746663886993223612
1	90	41	90	42	-2464505237803796505	train_data.drop('Response', axis=1, inplace=True)	90	8	90	57	-5714385259794989748
1	90	53	90	54	6527188787872601796	pd.concat([cp_h_month,cp_l_month],axis=1)	90	14	90	55	-6893094480687031882
1	90	56	90	57	1574565733484918981	SingleIntervalTicker(interval=1)	90	26	90	58	5392260143290988083
1	91	29	91	30	-8386821089616015338	tester_df.drop('click', axis=1, inplace=True)	91	0	91	45	189501370054729857
1	91	55	91	56	5625505015382264304	StratifiedKFold(kfold, shuffle=True,random_state=1)	91	6	91	57	-7637520583311743386
1	92	22	92	23	-3782140645392583967	countries.idxmin(axis=1)	92	0	92	24	4651513248959298086
1	92	34	92	35	-8915804621526012850	dataset.sample(frac=1)	92	14	92	36	1020600254571809489
1	92	43	92	44	638347367586701728	new_data.drop(['Detergents_Paper'], axis = 1, inplace = True)	92	0	92	61	-7432505510611043035
1	93	15	93	16	-1978133136003034988	plt.legend(loc=1,prop={'size':40})	93	0	93	34	2593065564122948441
1	93	56	93	57	-9108359116226538057	canvas._tkcanvas.pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)	93	0	93	58	-3736452949683034854
1	93	58	93	59	-709752848901348491	pd.concat([n_df,aa_df,c_df],axis=1)	93	25	93	60	1363222977965712801
1	93	77	93	78	-7685625583619544320	tf.one_hot(indices=index, depth=env.observation_space.n, on_value=1, off_value=0, axis=None, name=name)	93	11	93	114	4199278662275588280
1	94	20	94	21	-7918936324684031815	ModelCheckpoint(\n            filepath,\n            monitor='loss',\n            verbose=1,\n            save_best_only=True,\n            mode='min')	91	21	96	23	-4450658091922869616
1	94	35	94	36	-2017667383220888465	pd.concat([log_return_data['GSPC'],\n  log_return_data['Jp2353'],\n  log_return_data['Jp4684'],\n  log_return_data['Jp9076'],\n  log_return_data['Jp8358']], axis=1)	90	19	94	37	2569552380215910373
1	94	59	94	60	-2439647201931029336	frontiere(f, X_test, y_pred, w=None, step=50, alpha_choice=1)	94	0	94	61	1692962304581988552
1	94	70	94	71	1278428860179401526	beta.fit(shpdf.ShP, floc=0, fscale=1)	94	35	94	72	-7421513146166607205
1	95	31	95	32	-5315828751727536464	plt.subplots(nrows=1, ncols=2)	95	12	95	42	2040251658156822377
1	96	37	96	38	6899304098662861585	theta.copy().apply(max, axis=1)	96	8	96	39	4902052790948282942
1	96	41	96	42	-7077825609662632988	tester_df.drop(col, axis=1)	96	16	96	43	-5433668307854448363
1	97	40	97	41	7621975428939387197	plt.subplots(nrows=1, ncols=3, figsize=(18, 8), tight_layout=False)	97	21	97	88	-360381688180946754
1	97	43	97	44	-2443169778778504134	df.drop(['dag', 'tijdstip'], axis=1)	97	9	97	45	8336495957678387826
1	97	53	97	54	1862052405931092520	pd.concat([tester_df, one_hot], axis=1)	97	16	97	55	-1532384595022125544
1	97	85	97	86	-110893479889543025	pd.concat([show_tollgate_2_entry,temp_dateframe_20],axis=1)	97	28	97	87	-3043291017269020038
1	98	20	98	21	-861820414341396012	np.diff(X, axis=1)	98	4	98	22	3168688173359203580
1	98	29	98	30	-1604855121498407701	np.sum(X, axis = 1)	98	12	98	31	3189065607144785366
1	98	49	98	50	7269534549927039954	known_labels.reset_index().apply(f, axis=1)	98	8	98	51	-2438065270357664868
1	98	100	98	101	1256275472895650669	MLPClassifier(solver='adam', activation = 'logistic',hidden_layer_sizes=(10, 50), random_state=1)	98	5	98	102	-4349249581194957593
1	99	26	99	27	4746484221286356932	fut.sum(axis=1)	99	13	99	28	-6907700271953706649
1	99	32	99	33	999240390701302699	FunctionApproximator(n_out=1, n_hidden=2)	99	5	99	46	8182645017762211205
1	99	35	99	36	3327136029550415255	df.isnull().any(axis=1)	99	14	99	37	2369217683878797610
1	99	36	99	37	2991161736334110838	np.insert(Xval, 0, 1, axis = 1)	99	7	99	38	5281957775181947877
1	99	88	99	89	5580095672225589294	pd.concat([roads_data_df, roads_data_df_start, roads_data_df_end], axis=1)	99	16	99	90	2636862502337299790
1	101	50	101	51	5617789820968962371	journals.drop(['content'], inplace = True, axis = 1)	101	0	101	52	6588471453046524427
1	102	37	102	38	-5063875447244709888	df.dropna(axis=0, how='any', inplace=1)	102	0	102	39	458813632100446278
1	102	83	102	84	789419973019111344	Te.data2array('./FCDclust%s/win_%i_typ_%s.npy'%(ddd,w,typ), dic=1)	102	19	102	85	-7724054796484007047
1	102	130	102	131	4472640343912865766	plt.plot(relative_porosity, brit_crush_str, linestyle=':', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round')	102	8	102	155	3545392065272091383
1	103	48	103	49	-5125654353395241787	bx.grid(color='grey', linestyle='--', linewidth=1, alpha=0.2)	103	0	103	61	1878644812437073770
1	103	71	103	72	-3432883109254924768	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 1)	102	10	103	73	2934476473305307850
1	103	130	103	131	7904478316424581774	plt.plot(relative_porosity, closedcell_str, linestyle=':', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round')	103	8	103	155	-2606778810806287792
1	104	50	104	51	-4179007714658921023	df['train'].drop('class', axis=1)	104	19	104	52	1478848108543571712
1	105	41	105	42	8021018276226950764	plt.subplots(nrows=1, ncols=2, figsize=(6, 3))	105	22	105	68	-1805348241094352061
1	105	54	105	55	4228167676949530608	right_df.drop('geometry', axis=1)	105	23	105	56	4957882864108583045
1	106	15	106	16	-7407758745656628436	plt.legend(loc=1,prop={'size':40})	106	0	106	34	-8003501819076991364
1	106	52	106	53	-4799560167114882963	df['test'].drop('class', axis=1)	106	22	106	54	6751727723500091445
1	106	135	106	136	2763073247470164477	plt.plot(relative_density_table, brit_crush_str, linestyle=':', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round')	106	8	106	160	-8134554359127205557
1	107	135	107	136	-5068638924816756288	plt.plot(relative_density_table, closedcell_str, linestyle=':', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round')	107	8	107	160	-3409795237217666481
1	108	29	108	30	-1331187036459918039	tester_df.drop('click', axis=1, inplace=True)	108	0	108	45	-2096190895448644587
1	109	37	109	38	-2564259914685389960	new_data.drop('Delicatessen', axis = 1, inplace = True)	109	0	109	55	329193521511574926
1	109	58	109	59	-6139201186294329789	theta.copy().apply(lambda row:sorted(row)[::-1], axis=1)	109	4	109	60	2480041385879083820
1	109	85	109	86	-7562707883938291176	pd.concat([show_tollgate_3_entry,temp_dateframe_30],axis=1)	109	28	109	87	-3853080324384089951
1	109	87	109	88	6919569965105771297	plt.scatter(test[:,0], 0*test[:,1], color='red', s=40,marker='^',label='test',zorder=1)	109	2	109	89	2912459371922799111
1	110	39	110	40	-3966602691888934427	ModelCheckpoint(filepath='mnist.model.best.hdf5',\n                               verbose=1, save_best_only=True)	109	15	110	62	-1855717249429358527
1	111	31	111	32	4981305961747163586	plt.subplots(nrows=1, ncols=2)	111	12	111	42	4475117986850477918
1	111	41	111	42	6249047798051474443	tester_df.drop(col, axis=1)	111	16	111	43	-7525066186599377253
1	111	48	111	49	5757166530823156917	graphlab.deploy.environment.EC2('food_predictive_service_notebook',\n                                      's3://gl-internal-test/food_app',\n                                      region='us-west-1',\n                                      instance_type='m3.large',\n                                      aws_access_key=YOUR_ACCESS_KEY,\n                                      aws_secret_key=YOUR_SECRET_KEY,\n                                      num_hosts=1)	105	6	111	50	-7665258544489821045
1	112	53	112	54	6440565007573854477	pd.concat([tester_df, one_hot], axis=1)	112	16	112	55	-6393960586082605456
1	112	128	112	129	-3032448091209190279	plt.plot(strength_table, strength_table, linestyle='--', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round', markevery='2')	112	8	112	168	5248721601833147179
1	113	35	113	36	6109118501246612123	human_tissue_knowledge.dropna(axis=1, how='all')	113	0	113	48	-3081898812565331178
1	113	38	113	39	-7458480992256438414	display2.plot_ppi('RhoHV',vmin=0,vmax=1)	113	0	113	40	1996020670462510767
1	113	41	113	42	-4423125231998870369	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
1	113	52	113	53	-1554437787251448609	data.copy().drop('Detergents_Paper',axis=1)	113	11	113	54	-3225902827817131674
1	114	54	114	55	-3163970523590241548	right_df.drop('geometry', axis=1)	114	23	114	56	7769571898028549346
1	115	74	115	75	8159341850195604546	df.drop(['TEAM_ID', 'GP', 'W', 'L', 'MIN', 'OPP_FGM', 'OPP_FGA', 'OPP_FG3M', 'OPP_FG3A','OPP_FTM', 'OPP_FTA',\n             'OPP_REB', 'GP_RANK', 'W_RANK', 'L_RANK','W_PCT_RANK', 'MIN_RANK', 'OPP_FGM_RANK', 'OPP_FGA_RANK',\n             'OPP_FG_PCT_RANK', 'OPP_FG3M_RANK', 'OPP_FG3A_RANK', 'OPP_FG3_PCT_RANK','OPP_FTM_RANK', 'OPP_FTA_RANK',\n             'OPP_FT_PCT_RANK', 'OPP_OREB_RANK','OPP_DREB_RANK', 'OPP_REB_RANK', 'OPP_AST_RANK', 'OPP_TOV_RANK',\n             'OPP_STL_RANK', 'OPP_BLK_RANK', 'OPP_BLKA_RANK', 'PLUS_MINUS','OPP_PF_RANK','OPP_PFD_RANK',\n             'OPP_PTS_RANK', 'PLUS_MINUS_RANK', 'CFID', 'CFPARAMS'], axis=1, inplace=True)	110	4	115	90	4166209234381394355
1	116	38	116	39	3835976719085119265	fig.subplots_adjust(left=0, right=1, bottom=0)	116	4	116	50	-7290039311198501800
1	116	55	116	56	7759294341144752088	ax1.tick_params('both', which='major', length=8, width=1)	116	0	116	57	1122850074783823134
1	117	48	117	49	3038900355214805898	display2.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	117	0	117	50	7160287107557398832
1	117	73	117	74	-4403087828279106711	theta.apply(lambda row: np.sum(row > threshold), axis=1)	117	19	117	75	-6781576121270437695
1	118	71	118	72	8314598438933440918	journalsFinal.drop(['isOctSpam', 'isSiteSpam'], inplace = True, axis = 1)	118	0	118	73	6860164391360592128
1	121	34	121	35	4282246456524290076	dict(algorithm=1, trees=5)	121	19	121	45	-1827464983025561200
1	121	39	121	40	-3711430071805255838	left_df\n                .drop('geometry', axis=1)	120	16	121	41	-2618351366246805997
1	121	83	121	84	-5726735339245926806	pd.concat([show_tollgate_1_exit,temp_dateframe_11],axis=1)	121	27	121	85	562602875599843481
1	123	65	123	66	-1862505352784042471	timeit.timeit('for i in range(0, n): list3[i] = i', number=1, setup='from __main__ import n, list3')	123	6	123	106	4286889815911178856
1	124	40	124	41	5079476393299813140	svm.SVC(gamma=2, C=1)	124	21	124	42	-6035466067243746494
1	124	68	124	69	9014225812678034239	timeit.timeit('for i in range(0, n): list4.append(i)', number=1, setup='from __main__ import n, list4')	124	6	124	109	-3824291172675519627
1	125	10	125	11	-515576247048045499	data.plot(kind='density', subplots=True, layout=(3,2), sharex=False, legend=False,\nfontsize= 1)	124	0	125	12	-6368635180965694479
1	126	59	126	60	5151847082356928350	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
1	126	79	126	80	6513470363985478408	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
1	127	54	127	55	-8408675954403035453	log_return_data.drop('gspc_log_return_positive', axis=1, inplace=True)	127	0	127	70	4564937696549562127
1	127	74	127	75	-3913403459970557922	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
1	128	49	128	50	-2545959721463965892	neighbors.KNeighborsClassifier(n_neighbors=1)	128	6	128	51	7233323050875933577
1	128	54	128	55	-3394224668571147624	log_return_data.drop('gspc_log_return_negative', axis=1, inplace=True)	128	0	128	70	-8803043612741671330
1	129	93	129	94	-4559364078557734230	all_pept.drop(["RepliconName","RepliconAccession","ProteinProduct_y","COGs"],axis=1)	129	11	129	95	6146341751471566443
1	130	43	130	44	-7552005191463912294	sns.heatmap(correlations, vmin=0, vmax=1, annot=True)	130	4	130	57	-3579592535373262786
1	130	53	130	54	-8105945017631540734	Slider(start=years[0], end=years[-1], value=1, step=1, title="Year", callback=callback, name='testy')	130	9	130	110	-2808496788221266639
1	130	55	130	56	5758318715912863857	ax1.tick_params('both', which='major', length=8, width=1)	130	0	130	57	3655823880282572057
1	130	61	130	62	-1756153230828509257	Slider(start=years[0], end=years[-1], value=1, step=1, title="Year", callback=callback, name='testy')	130	9	130	110	-2808496788221266639
1	131	66	131	67	7857797137953506594	zoom(centerbias, [factor_y, factor_x], order=1, mode='nearest')	131	21	131	84	3034112038593695508
1	132	48	132	49	4946163163665754365	cx.grid(color='grey', linestyle='--', linewidth=1, alpha=0.2)	132	0	132	61	-840769859196584771
1	133	83	133	84	-4012712475421895039	pd.concat([show_tollgate_3_exit,temp_dateframe_31],axis=1)	133	27	133	85	676293534550203311
1	134	17	134	18	823883449470474173	plt.legend(loc = 1)	134	0	134	19	1503925025928124039
1	135	42	135	43	-6241138375177314485	pd.concat([count,summ], axis=1)	135	13	135	44	3975463954122282501
1	135	45	135	46	-1111741540827871210	pd.concat([site_df, pb_df, hi_df], axis=1)	135	5	135	47	8516772006732709415
1	135	50	135	51	-6136258521604970201	upset.apply(predupset,axis = 1)	135	21	135	52	6111859392323568567
1	136	36	136	37	4738235297866565520	samples.drop('total',axis=1)	136	10	136	38	5322256575277171892
1	140	54	140	55	-6014585547964831321	processor(vtpredict, model, nprocessor=1, timeslice='auto', vis_slices=31,\n                         oversampling=4, facets=8, wstep=advice['w_sampling_primary_beam'])	140	15	141	91	8017141038555901416
1	143	36	143	37	-7262654718761033209	CountVectorizer(min_df=1,stop_words=stopWordsCounter,\n                             vocabulary = vocabDict)	143	13	144	52	7934176907374845924
1	144	37	144	38	6505513913434040350	plt.scatter(bigdf.x, bigdf.y, zorder=1, s=abs(bigdf.rssiAdj)*100, alpha=0.02)	144	0	144	77	972742534475348886
1	144	41	144	42	2866280120211792667	a.reshape((n/2, 2)).mean(axis=1)	144	11	144	43	-7223681973535806940
1	144	79	144	80	7040771107592768513	np.genfromtxt("data_mcmc_1/challenger_data.csv", skip_header=1, usecols=[1, 2], missing_values="NA", delimiter=",")	144	18	144	133	-6779294956129215953
1	147	44	147	45	-2698790301465559174	svm.LinearSVC(max_iter=50000, verbose=1)	147	6	147	46	-3815622864876185836
1	147	59	147	60	6339531635300097395	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	147	0	147	73	4460889049567238131
1	148	25	148	26	-6239058579138699045	mono_MW.drop(['pI'],axis=1,inplace=True)	148	0	148	40	7507229303877963101
1	148	25	148	26	-1289247059678661962	laliga.drop('goal', axis=1, inplace=True)	148	0	148	41	-3144988282760707369
1	148	57	148	58	-4493388991432863898	ax[1].hexbin(vx,vy,bins='log',gridsize=650,mincnt=1)	148	7	148	59	-6545072670191545726
1	149	55	149	56	8919748413339719712	ax1.tick_params('both', which='major', length=8, width=1)	149	0	149	57	3906196640348417477
1	150	56	150	57	4395797978777305825	my_map.tissot(lon_0=lon_edex_mean, lat_0=lat_edex_mean, radius_deg=eddy_radius_degree,\n              npts=100, fc='#cccccc', ec='none', zorder=1)	149	0	150	58	4074994673106612548
1	151	32	151	33	-3214434044572821766	Week(weekday=1)	151	19	151	34	-1209008734715276633
1	151	48	151	49	9205551791613839880	np.append(X_poly, poly, axis = 1)	151	17	151	50	-3979871659020869179
1	151	89	151	90	-425376885551887814	ax[1].contour(counts,linewidths=3,extent=[-150,90,-90,90],extend='both',colors='k',alpha=1)	151	0	151	91	3078215495223028583
1	152	33	152	34	-7019040535655803019	datetime.date(int(miny), month=1, day=1)	152	2	152	42	-6904561093346388148
1	152	40	152	41	6880186876129221834	datetime.date(int(miny), month=1, day=1)	152	2	152	42	-6904561093346388148
1	152	77	152	78	-4225040175027092443	master_total_df.apply(expandedTitle,axis=1)	152	36	152	79	857095122250471663
1	153	73	153	74	-3123290172729984190	master_total_df.apply(prefixTitle,axis=1)	153	34	153	75	6721819982275876478
1	154	31	154	32	-7391873240660767410	pd.concat(dfs, axis=1)	154	11	154	33	8168025493902482055
1	154	66	154	67	-9138321157359593138	binaryCrossTabWeightLossSubreddit.sum(axis=1)	154	23	154	68	-7567710868032475481
1	154	97	154	98	-7537506672992414103	pd.concat([DataFrame(np.array(data_drop)),DataFrame(np.array(year_dummy)),region_by_year],axis=1)	154	2	154	99	79705642878624340
1	155	66	155	67	714656986053368667	np.pad(data, padding, mode='constant', constant_values=1)	155	11	155	68	-8624370989891304939
1	156	36	156	37	1882328506373896007	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
1	156	42	156	43	4858628676533229762	pd.concat([count,summ], axis=1)	156	13	156	44	-7890399190201543545
1	156	46	156	47	8952790622841514974	X_sel.drop('Unnamed: 0', inplace=True, axis = 1)	156	0	156	48	2509131224553157113
1	156	50	156	51	-5032929270105258508	df.groupby('country').describe().xs('mean', level=1)	156	0	156	52	7174317003002569479
1	157	98	157	99	-6066613018787357797	pd.concat([top_h_month, top_h_month_date, bottom_l_month, bottom_l_month_date],axis=1)	157	14	157	100	-7953228715984656776
1	158	73	158	74	-4017146662409402491	ps_new_ave_cpt.drop(ps_new_ave_cpt.columns[[1,2,3,4]],axis=1)	158	14	158	75	4053795492617359067
1	159	88	159	89	-6233202726335050830	create_image_from_visibility(vt, npixel=npixel, cellsize=0.001, nchan=1,\n                                              polarisation_frame=PolarisationFrame('stokesI'))	159	18	160	94	3306367486268816125
1	160	56	160	57	4187125280393036356	kernel_mean_matching(test, train, kern='rbf', B=1)	160	8	160	58	-7358739779755674312
1	161	66	161	67	-7736488518286134818	np.pad(data, padding, mode='constant', constant_values=1)	161	11	161	68	4026683692416314923
1	163	52	163	53	3792586875122951684	g.plot_joint(plt.scatter, c="cyan", s=30, linewidth=1, marker="+")	163	0	163	66	7069746542993961024
1	163	71	163	72	4468168495470404033	without_seasonality_df.drop("Unnamed: 0",axis=1)	163	25	163	73	-4461777102776846761
1	165	34	165	35	7194231935616214191	game_df.drop('Odds', axis=1, inplace=True)	165	8	165	50	6387260766325672906
1	168	36	168	37	-819377881001290645	human_tissue_textmining.dropna(axis=1, how='all')	168	0	168	49	5602609521351881595
1	169	37	169	38	-3289860153665051560	display.plot_ppi('RhoHV',vmin=0,vmax=1)	169	0	169	39	-632152990807473823
1	169	38	169	39	-722077974267753518	pd.concat(list_of_data, axis=1)	169	9	169	40	8171817491389379492
1	169	38	169	39	6744170014216232690	P.rc('lines', markersize=4, linewidth=1, markeredgewidth=0.2)	169	0	169	61	8891696031833531130
1	169	81	169	82	1345102117069517402	pd.concat([without_seasonality_df,with_seasonality_df],axis=1)	169	21	169	83	-2598954647581638314
1	170	25	170	26	-1181632496241753491	P.rc('legend', numpoints=1, frameon=False, handletextpad=0.3, scatterpoints=1, handlelength=2, handleheight=0.1)	170	0	170	112	6412631352673677337
1	170	36	170	37	-4700853871314469687	np.std(normX,axis=0,ddof=1)	170	11	170	38	-4093332258538542831
1	170	76	170	77	6186642886581323540	P.rc('legend', numpoints=1, frameon=False, handletextpad=0.3, scatterpoints=1, handlelength=2, handleheight=0.1)	170	0	170	112	6412631352673677337
1	171	41	171	42	-5435579724264130472	np.expand_dims(np.array(masks), axis=1)	171	4	171	43	8075083916443009513
1	179	35	179	36	6407889169015101997	plt.axvline(x=loc, ymin=-1, ymax = 1, linewidth=2, color='black',label="1:3 EOLR")	179	0	179	82	7709365567739490862
1	180	25	180	26	-138688204063900054	X.drop('result',axis = 1)	180	2	180	27	7254711850477367228
1	180	50	180	51	8488519993650951149	np.nanmean(day_station_table,axis=1)	180	16	180	52	4149072577080695349
1	180	51	180	52	5493204732321431927	cv2.warpAffine(src, M, dsize, borderMode=1)	180	10	180	53	-2943690363507771071
1	182	59	182	60	7822280918360534075	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	182	0	182	73	-1931039812533034310
1	183	44	183	45	3849321492091553075	df_fact.drop(['Request Date', 'date'], axis=1, inplace=True)	183	0	183	60	-5574837049669181684
1	184	31	184	32	-1856900826063338867	np.mean(phis1[tri1],axis=1)	184	6	184	33	-7960164701642282840
1	184	49	184	50	2013910457264221096	plt.plot(sa, ct, color='#cccccc', zorder=1)	184	8	184	51	5912815922409238104
1	184	97	184	98	-2118863390963562169	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c=post_prob[m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	184	0	184	112	-1889501870135959898
1	185	43	185	44	3370951918412040988	game_df.drop('True_Result_U', axis=1, inplace=True)	185	8	185	59	1934123715115802611
1	185	46	185	47	-6960943987818724678	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=1)	185	0	185	48	-3417475230800158610
1	186	45	186	46	1511291257522956621	df_fact.drop(['Response Date', 'date'], axis=1, inplace=True)	186	0	186	61	-4225099591760560868
1	186	70	186	71	-6446640963990517473	savefig('images/components_v_reads_paired_and_single.pdf', pad_inches=1)	186	0	186	72	8886873410109057068
1	186	100	186	101	479113231745477681	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c=post_prob[~m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	186	0	186	115	8655850365270254544
1	187	20	187	21	-7679174860027886580	np.mean(X, axis=1)	187	4	187	22	-5664391249941348643
1	187	37	187	38	3531751609329715063	display.plot_ppi('RhoHV',vmin=0,vmax=1,sweep=1)	187	0	187	47	-2512975019501053407
1	187	40	187	41	-841618169041292792	np.mean(pos1[tri4,:],axis=1)	187	14	187	42	-2954339764315436137
1	187	45	187	46	7583756867062923943	display.plot_ppi('RhoHV',vmin=0,vmax=1,sweep=1)	187	0	187	47	-2512975019501053407
1	189	40	189	41	3572736612928228469	np.insert(X_poly, 0, 1, axis = 1)	189	9	189	42	-8840655945620611570
1	189	45	189	46	6722941829959147861	display.plot_ppi('ZDR',vmin=-7,vmax=11,sweep=1)	189	0	189	47	6958275227470495976
1	189	63	189	64	1235902518031429728	tf.reduce_sum(Y*tf.log(hypothesis),axis=1)	189	23	189	65	-447259249574528620
1	190	48	190	49	-5848116033408338401	np.insert(X_poly_val, 0, 1, axis = 1)	190	13	190	50	-4443243182395241228
1	191	47	191	48	-702967949944258683	display.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	191	0	191	49	9188366317665067491
1	191	50	191	51	-681849184868098158	np.insert(X_poly_test, 0, 1, axis = 1)	191	14	191	52	8108508117033305120
1	196	51	196	52	-2018032678796343285	np.sum(P, axis=1)	196	36	196	53	-8147931334817520342
1	196	71	196	72	2751313176413980593	np.random.uniform(size=1)	196	48	196	73	-7721012403123736997
1	197	42	197	43	1545584414896118104	game_df.drop('Matchup_Date', axis=1, inplace=True)	197	8	197	58	7731022327112686231
1	197	45	197	46	5572447952072936479	np.mean(y.reshape(-1, n), axis=1)	197	14	197	47	7319222051833451691
1	200	37	200	38	3031148628918405816	game_df.drop('Matchup', axis=1, inplace=True)	200	8	200	53	-7833185880236760562
1	200	50	200	51	8774880877879050396	pd.concat([bike_subdf, noun_parsed], axis=1)	200	8	200	52	-2869535305433073908
1	201	54	201	55	4702243705657398998	(np.tril(cov) - np.triu(cov).transpose()).argmin(axis=1)	201	0	201	56	-1018834716827295016
1	204	35	204	36	-7553567051820799540	plt.scatter(df.x, df.y, zorder=1, s=abs(df.rssiAdj)*100, alpha=0.2)	204	4	204	71	2988092292974653843
1	204	46	204	47	6620372299146756222	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=1)	204	0	204	48	-6654751671107252780
1	206	22	206	23	-2865540472204519155	df.sum(axis=1)	206	10	206	24	-1831533821422974945
1	207	120	207	121	3471981427497943992	pd.concat([np.max(means_e1_a.T),np.max(means_e2_a.T),np.max(means_e1_b.T),np.max(means_e2_b.T)],axis=1)	207	19	207	122	-8907692106731374250
1	208	51	208	52	6670097351052449321	cv2.warpAffine(src, M, dsize, borderMode=1)	208	10	208	53	-8237461823488885779
1	208	120	208	121	6272944080724719759	pd.concat([np.min(means_e1_a.T),np.min(means_e2_a.T),np.min(means_e1_b.T),np.min(means_e2_b.T)],axis=1)	208	19	208	122	118833027108421565
1	209	29	209	30	4280378254757790276	bos.drop('PRICE', axis = 1)	209	4	209	31	-3091024271477539985
1	209	120	209	121	1087530950620708810	pd.concat([np.max(means_e1_a.T),np.max(means_e2_a.T),np.max(means_e1_b.T),np.max(means_e2_b.T)],axis=1)	209	19	209	122	3662976577963337939
1	210	31	210	32	-3610481967735161402	df_locations.drop('temp', axis=1, inplace=True)	210	0	210	47	-465328664887204044
1	210	120	210	121	-6125639617440944393	pd.concat([np.min(means_e1_a.T),np.min(means_e2_a.T),np.min(means_e1_b.T),np.min(means_e2_b.T)],axis=1)	210	19	210	122	-5494925938414821676
1	214	49	214	50	8037733769010838713	np.tensordot(x[tri1,iDip,:],p,1).mean(axis=1)	214	6	214	51	6471818221718019755
1	214	53	214	54	4171698195505281069	demographics_df.drop('ASIAN', axis=1)	214	18	214	55	7133310951862580720
1	215	41	215	42	1707909287097527530	np.random.normal(loc=0, scale=1, size=(1,2))	215	11	215	55	7094165938103852895
1	215	42	215	43	2141505460153837126	manifold.MDS(n_components=2, n_init=1, max_iter=100)	215	6	215	58	-466724360669131111
1	215	53	215	54	-4280306333428784511	np.insert(xmat,xmat.shape[1],xvals.T,axis=1)	215	11	215	55	-8668355433695939369
1	215	64	215	65	-2171680273670378446	demographics_df.drop('PACIFIC_ISLANDER', axis=1)	215	18	215	66	-6946605830296694805
1	217	28	217	29	3694543984303222160	pd.concat([pd.DataFrame(np.array([np.NAN,np.NAN,np.NAN]),columns=['0.8'],index=index),\n                        df,\n                        pd.DataFrame(np.array([np.NAN,np.NAN,np.NAN]),columns=['2.4'],index=index)],\n                       axis=1)	214	13	217	30	3548317412885123819
1	217	48	217	49	-3951035405914326131	plt.plot(ct, d, color='#cccccc', zorder=1)	217	8	217	50	9220089147780263779
1	217	54	217	55	-5092044551677727596	master_total_df.apply(fixState,axis=1)	217	18	217	56	-7717856410502324709
1	218	27	218	28	-8489623110181125596	ax.contour(L, C, utility, np.linspace(-8, np.max(utility), 10), colors=np.repeat('k', 10),\n                linewidths=1, linestyles='solid')	217	5	218	49	7152385935676566748
1	218	31	218	32	5144659955333730039	laliga.drop('possession', axis=1, inplace=True)	218	0	218	47	339635229966255005
1	218	57	218	58	-5142571212745235279	sv_data.drop(["Width", "Height"], inplace=True, axis=1)	218	4	218	59	-9099469932421068982
1	218	58	218	59	-6170991275611726924	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=2, row_step=2,\n                                                col_end=shapes[k]['w'],\n                                                row_end=shapes[k]['h'])	215	23	221	71	5749420223800921298
1	218	61	218	62	-4648233679330600349	np.tensordot(x[tri2+NoTri+NoPnt,iDip,:],p,1).mean(axis=1)	218	6	218	63	-4814490249297592155
1	218	70	218	71	1578340067450605193	plt.plot([all_centroid["x"], all_centroidweighted["x"]],\n             [all_centroid["y"], all_centroidweighted["y"]], 'k-', lw=1)	217	4	218	72	3337803113295509516
1	218	71	218	72	7678199278902094714	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=2, row_step=2,\n                                                col_end=shapes[k]['w'],\n                                                row_end=shapes[k]['h'])	215	23	221	71	5749420223800921298
1	218	71	218	72	8250714235421801233	np.random.uniform(size=1)	218	48	218	73	-9730338997374870
1	218	113	218	114	5117125207555270642	x.rolling(window=num_games,min_periods=1)	218	74	218	115	-7685093975544879319
1	219	21	219	22	-8301757425165976302	ax.clabel(CS, inline=1, fmt='%1.2f')	219	0	219	36	5752008662195152412
1	219	28	219	29	-1277186521924444449	pd.concat([pd.DataFrame(np.array([np.NAN,np.NAN,np.NAN]),columns=['0.8'],index=index),\n                        df,\n                        pd.DataFrame(np.array([np.NAN,np.NAN,np.NAN]),columns=['2.4'],index=index)],\n                       axis=1)	216	13	219	30	-52047305457676005
1	219	47	219	48	-5969625941152935484	np.median(y.reshape(-1, n), axis=1)	219	14	219	49	8506991698803997200
1	220	17	220	18	1687639368653165703	mean(Dt,axis=1)	220	4	220	19	-3315854123907271899
1	220	29	220	30	-4896480716455114995	plot( p_trace, label = "$p$: frequency of assignment to cluster 0",\n     color = "#467821", lw = 1)	219	0	220	31	-5823512984105754537
1	220	36	220	37	1542664576578027328	sns.PairGrid(skin.sample(1000), vars=["R", "G"],\n                 hue="skin", aspect=1, size=5)	219	4	220	46	40169509588374986
1	221	16	221	17	1682822440018084913	std(Dt,axis=1)	221	4	221	18	3224093518127585967
1	221	65	221	66	-819588857594446416	np.tensordot(x[tri3+2*(NoTri+NoPnt),iDip,:],p,1).mean(axis=1)	221	6	221	67	-3290968312770493839
1	223	47	223	48	-7077014652733588405	plt.axvline(x=wiki['length'][wiki['name'] == 'Joe Biden'][0], color='g', linestyle='--', linewidth=4,\n           label='Length of Joe Biden', zorder=1)	222	0	223	49	2222904614420149584
1	224	87	224	88	7876462751270613564	duplicate_ps_new.drop(duplicate_ps_new.columns[[1,2,3,4]],axis=1)	224	24	224	89	-447964091311228323
1	225	65	225	66	2923020276685099209	np.tensordot(x[tri4+3*(NoTri+NoPnt),iDip,:],p,1).mean(axis=1)	225	6	225	67	-4567075456942570528
1	227	36	227	37	-2880618499331865267	sns.PairGrid(skin.sample(1000), vars=["R", "B"],\n                 hue="skin", aspect=1, size=5)	226	4	227	46	-8115653986764091663
1	228	58	228	59	-1325258520323975769	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=1, row_step=1,\n                                                col_end=shapes[k]['w']-1,\n                                                row_end=shapes[k]['h']-1)	225	23	231	73	-4220361763512287916
1	228	65	228	66	-8241065398683509815	arr.sum(axis=1)	228	52	228	67	5410608130637268959
1	228	71	228	72	-5982719335565511654	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=1, row_step=1,\n                                                col_end=shapes[k]['w']-1,\n                                                row_end=shapes[k]['h']-1)	225	23	231	73	-4220361763512287916
1	229	45	229	46	-2544933529520004165	pd.concat([site_df, pb_df, hi_df], axis=1)	229	5	229	47	1940528477198011764
1	229	57	229	58	-3654381377660308779	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=1, row_step=1,\n                                                col_end=shapes[k]['w']-1,\n                                                row_end=shapes[k]['h']-1)	225	23	231	73	-4220361763512287916
1	229	69	229	70	5956152891753444044	get_hex_rectangle_coords(shapes[k]['w'],\n                                                shapes[k]['h'],\n                                                start_uv[k],\n                                                col_start=1, row_start=1,\n                                                col_step=1, row_step=1,\n                                                col_end=shapes[k]['w']-1,\n                                                row_end=shapes[k]['h']-1)	225	23	231	73	-4220361763512287916
1	230	66	230	67	1096397222204472248	known_labels.reset_index().apply(get_features_no_id, axis=1)	230	8	230	68	-1375235737831900324
1	230	70	230	71	5184555931448439180	canvas.get_tk_widget().pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)	230	8	230	72	-2655695578799241464
1	231	64	231	65	-7315202094733230744	canvas._tkcanvas.pack(side=Tk.TOP, fill=Tk.BOTH, expand=1)	231	8	231	66	7647164395501290271
1	232	15	232	16	3335816661456988307	plt.legend(loc=1,prop={'size':20})	232	0	232	34	-2814213520607695078
1	233	29	233	30	2469398188433270685	bos.drop('PRICE', axis = 1)	233	4	233	31	1566159083181634351
1	234	45	234	46	3248178013028234403	mcmc.trace("centers", chain = 1)	234	15	234	47	-6886705115492572697
1	235	29	235	30	-1165365469311072303	plt.legend(["line",\n                "detections",\n                "centroid",\n                "centroid weighted",\n                "top N_centroid weighted",\n                "top N_centroid",\n                "top Ntile centroid weighted",\n                "top Ntile centroid"],\n               loc=2, #legend loc='upper left'\n               scatterpoints=1,\n               frameon=False\n               )	226	4	237	16	7115522464313205573
1	235	40	235	41	2052285596149060155	ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n                       linewidth=0, antialiased=False)	235	7	236	54	-7386960939680423698
1	235	51	235	52	-7649849060705753155	ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n                       linewidth=0, antialiased=False)	235	7	236	54	-7386960939680423698
1	237	35	237	36	2958882221923862738	plt.axvline(x=loc, ymin=-1, ymax = 1, linewidth=2, color='red',label="3:1")	237	0	237	75	-6654553551286560328
1	237	50	237	51	6434463946514929967	knn_model_dog.query(image_test_dog, k = 1)	237	10	237	52	-4214399919209186729
1	238	36	238	37	-3396533721307337510	plt.axvline(x=loc2, ymin=-1, ymax = 1, linewidth=2, color='green',label="2:1")	238	0	238	78	-1157387928474582139
1	239	30	239	31	-2254777600006716523	sns.FacetGrid(data = genome_stats[genome_stats['paper1_LG'] == 2], sharex=False, hue_kws=dict(marker=["o", 'o']),\n           size = 8, aspect = 1, palette=sns.xkcd_palette(reversed(colors)), hue = 'paralog')	238	4	239	93	-8855636080202238515
1	240	121	240	122	319932787782093097	pd.concat([p_change_month_max, p_change_month_maxdate, p_change_month_min, p_change_month_mindate],axis=1)	240	17	240	123	-839629696613331174
1	243	15	243	16	2655674082598115959	A.sum(axis=1)	243	4	243	17	-2872795949431137101
1	243	31	243	32	5201621350434396450	df_fact.drop(['Latitude', 'Longitude', 'Location', 'latitude', 'longitude', 'location'],\n                          axis=1, inplace=True)	242	0	243	47	2289147609018610807
1	244	87	244	88	3792456254239810487	duplicate_ps_old.drop(duplicate_ps_old.columns[[1,2,3,4]],axis=1)	244	24	244	89	2066444980897637999
1	246	39	246	40	-6179660315163258966	sm.TSNE(n_components=2, verbose=1, n_iter=1000)	246	7	246	54	-286395297359099334
1	247	100	247	101	6764727086696449178	np.concatenate((\\n                            np.nanmean(hflux.GAD['ADVx_TH'][0:12,:,40*kk,53*kk:68*kk],axis=0),\\n                            np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,40*kk:58*kk,68*kk],axis=0)),axis=1)	245	42	247	102	-257697388417083526
1	248	55	248	56	-7698880019706709614	laliga.apply(shoton_home, axis=1)	248	24	248	57	7503443131631988697
1	249	48	249	49	-1974759062691936054	plt.plot(sa, d, color='#cccccc', zorder=1)	249	8	249	50	236770821748623081
1	249	55	249	56	467086284708662979	laliga.apply(shoton_away, axis=1)	249	24	249	57	-5387194373739329907
1	250	27	250	28	-2218117715584371092	laliga.drop('shoton', axis=1, inplace=True)	250	0	250	43	-8480212137906138891
1	250	100	250	101	-4718750692900215963	np.concatenate((\\n                            np.nanmean(hflux.GAD['DFxE_TH'][0:12,:,40*kk,53*kk:68*kk],axis=0),\\n                            np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,40*kk:58*kk,68*kk],axis=0)),axis=1)	248	39	250	102	7163413873218866538
1	251	36	251	37	7933001849292300158	pd.concat([df, ranked], axis=1)	251	7	251	38	5253154317349181854
1	252	115	252	116	80595464513274181	df.apply(lambda x: x['Home_Team'] if x['Predicted_Result'] == 1 else x['Visitor_Team'], axis=1)	252	22	252	117	-7906291507493911490
1	253	100	253	101	3064793691744598804	np.concatenate((\\n                            np.nanmean(hflux.GAD['ADVx_TH'][0:12,:,60*kk:95*kk,15*kk],axis=0),\\n                            np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,95*kk,15*kk:30*kk],axis=0)),axis=1)	251	42	253	102	-5544268152477097937
1	254	102	254	103	773199287923060005	df.apply(\n            lambda x: x['Home_Team'] if x['Home_Odd'] < x['Visitor_Odd'] else x['Visitor_Team'], axis=1)	253	31	254	104	6135509882912113992
1	255	114	255	115	-2083641247537523410	df[['Sibyl', 'Bookies_choice']].apply(lambda x: 'Y' if x[0] != x[1] else "N", axis=1)	255	31	255	116	-9189915244507092526
1	256	79	256	80	285604618287978133	decade_agg_ap.sort_values(by=['percent on-time gate arrivals'],axis=0, inplace=1)	256	0	256	81	392970596219725254
1	256	100	256	101	6155042340361426520	np.concatenate((\\n                            np.nanmean(hflux.GAD['DFxE_TH'][0:12,:,60*kk:95*kk,15*kk],axis=0),\\n                            np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,95*kk,15*kk:30*kk],axis=0)),axis=1)	254	39	256	102	2532035652909864443
1	257	45	257	46	1940800574294146530	pd.concat([site_df, pb_df, hi_df], axis=1)	257	5	257	47	-5233253416676551440
1	258	32	258	33	400514697924583675	df.drop('ID', axis=1)	258	13	258	34	-4051702640949428215
1	259	40	259	41	-3707599609055350394	df.drop('V_Team_PTS', axis=1)	259	13	259	42	-7932617951478234805
1	260	40	260	41	-8449534181656748940	df.drop('H_Team_PTS', axis=1)	260	13	260	42	-7323684240504409885
1	261	27	261	28	5033512662984548904	X.drop('result',axis = 1)	261	4	261	29	7860064318840721516
1	261	48	261	49	1038459561826079971	knn_model_cat.query(image_test_dog, k=1)	261	10	261	50	2254517011668850055
1	262	50	262	51	-3368925887723705173	knn_model_auto.query(image_test_dog, k=1)	262	11	262	52	-6054673554126096982
1	263	40	263	41	-9061859988283727287	df.drop(df.columns[[1,2,3,4,8,9]], axis=1, inplace=True)	263	0	263	56	-1555800385782798548
1	263	50	263	51	4578026947600616017	knn_model_bird.query(image_test_dog, k=1)	263	11	263	52	-8427896665742435882
1	264	47	264	48	8403948784721653400	plt.axvline(x=wiki['length'][wiki['name'] == 'Joe Biden'][0], color='g', linestyle='--', linewidth=4,\n           label='Length of Joe Biden', zorder=1)	263	0	264	49	6364673904392404084
1	265	57	265	58	2679698843856192237	laliga.apply(shotoff_home, axis=1)	265	25	265	59	-93854835031805493
1	266	57	266	58	-7292525268279570527	laliga.apply(shotoff_away, axis=1)	266	25	266	59	6214231084320162687
1	267	15	267	16	-9029523311816389370	animation.FuncAnimation(fig, animate, np.arange(1, len(y)),\n    interval = 1, blit=False, init_func=init)	266	6	267	45	-1690770988771672886
1	267	28	267	29	-2896834373072917034	laliga.drop('shotoff', axis=1, inplace=True)	267	0	267	44	-8569596936074784986
1	270	43	270	44	-5893006209942737182	pd.concat([X, New_cols_df], axis = 1)	270	8	270	45	-5646837716435817616
1	270	52	270	53	2483885213430442867	ax.legend(['ETHN == 1', 'ETHN == 0'], scatterpoints=1)	270	0	270	54	7668403126007863914
1	270	74	270	75	7284256472120185197	ax.contour(L, C, utility, np.array([u_star]), colors='k', linewidths=1,\n                linestyles='solid')	270	5	271	35	417739331975121587
1	271	38	271	39	8197462992080779112	pd.concat(\n            [df['Date'], df['Time'], df['League'], df['Matchup_US_P'], df['Visitor_Team'], df['Home_Team'],\n             df['Visitor_Odd'], df['Home_Odd'], df['Bookies_choice'], df['Sibyl'], df['Confidence'], df['Divergence_Y/N'],\n             df['True_Result']], axis=1)	268	22	271	40	-1124085243665212764
1	271	156	271	157	8588648582352723445	plt.plot(porosity_table, func(porosity_table, fitParamsIT[0], fitParamsIT[1], fitParamsIT[2]), marker='', linestyle=':', color='k', dashes=[0.3, 2], zorder=1, dash_capstyle='round')	271	0	271	181	-6036326694285323399
1	272	21	272	22	-1311495785321068975	ax.clabel(CS, inline=1, fmt='%1.4f')	272	0	272	36	4311360897038170287
1	275	42	275	43	5808450699171032339	pd.concat([count,summ], axis=1)	275	13	275	44	1817180927453402528
1	276	38	276	39	-240119699113496258	pd.concat(\n            [df['Date'], df['Time'], df['League'], df['Matchup_EU_P'], df['Home_Team'], df['Visitor_Team'],\n             df['Home_Odd'], df['Visitor_Odd'], df['Bookies_choice'], df['Sibyl'], df['Confidence'], df['Divergence_Y/N'],\n             df['True_Result']], axis=1)	273	22	276	40	-2059405910208395539
1	277	53	277	54	4573406921044968834	sn.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1,\n           square=True, linewidths=.5, annot=True,\n           annot_kws={'fontsize':10}, fmt='.2f',\n           cbar_kws={"shrink": .5}, ax=ax)	277	0	280	42	4428500316809765754
1	278	47	278	48	-5333295183514464123	plt.plot(o, d, color='#cccccc', zorder=1)	278	8	278	49	5118117987147375533
1	282	51	282	52	2731035847100455382	laliga.apply(foul_home, axis=1)	282	22	282	53	2213840706527327288
1	283	37	283	38	-5252391431039539614	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	283	18	283	65	-1752398385346999394
1	283	51	283	52	-8984872135668700297	laliga.apply(foul_away, axis=1)	283	22	283	53	-6362405298033764858
1	284	31	284	32	-6944669761545758595	laliga.drop('foulcommit', axis=1, inplace=True)	284	0	284	47	1153624764339796724
1	285	45	285	46	-8419288497113173934	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	284	4	285	54	-8020422986165235269
1	285	45	285	46	1356314192062273017	pd.concat([site_df, pb_df, hi_df], axis=1)	285	5	285	47	-6478175787625979684
1	286	52	286	53	-936062161425094514	ax.legend(['ETHN == 1', 'ETHN == 0'], scatterpoints=1, loc='upper left')	286	0	286	72	-530115250424484652
1	287	56	287	57	-1521039114368107393	pd.concat([bike_subdf, new_noun_parsed], axis=1)	287	10	287	58	6498147504935136187
1	288	57	288	58	7573269371627590136	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	288	8	288	65	656766383827902049
1	290	37	290	38	6234903675213963064	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	290	18	290	65	6759630139307608876
1	290	69	290	70	8463612303725204554	Te.data2array('./FCDclust/win_%i_typ_%s.npy'%(30,'512r'), dic=1)	290	7	290	71	-6174645186972966173
1	291	125	291	126	-8479237613051223103	df.apply(lambda x: x['PTS'] + 1.2*x['REB'] + 1.5*x['AST'] + 2*x['BLK'] + 2*x['STL'] - x['TOV'], axis=1)	291	24	291	127	-3735840645346594916
1	292	51	292	52	-4276802234909849444	df_fact.drop(['Topic', 'topic', 'dep_count'], axis=1, inplace=True)	292	0	292	67	-1762704150120679811
1	293	99	293	100	-173565707575047356	roc_curve(indep_y, indep_y_predicted_proba[:, 1], pos_label=1)	293	39	293	101	-4944914013767505055
1	296	36	296	37	-7665462453326068494	ax.plot(x, x+13, color="purple", lw=1, ls='-', marker='o', markersize=2)	296	0	296	72	2740781268762736408
1	297	36	297	37	-3348212849972235980	ax.plot(x, x+14, color="purple", lw=1, ls='-', marker='o', markersize=4)	297	0	297	72	-4549189668428020519
1	298	36	298	37	8762560361944784965	ax.plot(x, x+15, color="purple", lw=1, ls='-', marker='o', markersize=8, markerfacecolor="red")	298	0	298	95	1844061538920874073
1	298	69	298	70	-3702938596528222277	dataframe.apply(lambda x: unique_id(x, level=level), axis=1)	298	11	298	71	-385221728589234985
1	299	36	299	37	3399646083440222225	ax.plot(x, x+16, color="purple", lw=1, ls='-', marker='s', markersize=8,\n        markerfacecolor="yellow", markeredgewidth=2, markeredgecolor="blue")	299	0	300	76	3735684027595230213
1	299	53	299	54	-4608929685061553945	laliga.apply(cross_home, axis=1)	299	23	299	55	4549505896981391929
1	300	53	300	54	-1338153173351544980	laliga.apply(cross_away, axis=1)	300	23	300	55	1342570394075237419
1	301	26	301	27	-8860023494131804320	laliga.drop('cross', axis=1, inplace=True)	301	0	301	42	-7053135197910632441
1	301	28	301	29	3338715887840458675	NYC.plot(column='Km', alpha=1, colormap='YlOrRd')	301	0	301	49	2863527052919552117
1	302	37	302	38	-6232061544454043550	display.plot_ppi('RhoHV',vmin=0,vmax=1)	302	0	302	39	-7308457324732210457
1	302	104	302	105	8005496523912411272	bblnrgdatacut.plot(kind='scatter',x='nrg',y='UnitsTotal', fontsize=22, colormap='gist_rainbow', alpha = 1, marker='o',  figsize=(16, 14), loglog=True,  xlim=(1000,1e11), ylim=(1,1000), c=bblnrgdatacut['YearBuilt']-1900, s=bblnrgdatacut['UnitsTotal']/bblnrgdatacut['UnitsRes']*100)	302	0	302	280	-1239077568165988674
1	303	37	303	38	918842754932500855	plt.subplots(nrows=1, ncols=2, figsize=(20,10))	303	18	303	65	8817492634719737204
1	307	68	307	69	8577156825027056626	male_first_names['name'].sample(n= 1)	307	33	307	70	2397549951731338877
1	308	107	308	108	8217464092454039931	section_data_df[['from', 'to']].apply(lambda t: tuple(sorted([t[0], t[1]])), axis=1)	308	25	308	109	-1291008369664147710
1	309	69	309	70	-8240185059277560119	female_first_names['name'].sample(n=1)	309	33	309	71	-475270621722896318
1	310	52	310	53	-9035683525133094904	ax.legend(['ETHN == 1', 'ETHN == 0'], scatterpoints=1, loc='upper left')	310	0	310	72	-7758623316738541126
1	311	32	311	33	8527641433557799629	nyc_map.plot(column='DB', alpha=1, colormap='YlOrRd')	311	0	311	53	1254049348580872802
1	312	104	312	105	-32040626468798030	x.rolling(window=10,min_periods=1)	312	72	312	106	-8057621588932967960
1	314	64	314	65	-3215089960292665699	Te.data2array('./FCDclust/win_%s_typ_%s.npy'%(w,typ), dic=1)	314	6	314	66	-4149411677820885028
1	314	87	314	88	3971127382076358161	np.genfromtxt("boxoffice.csv", delimiter='\t', dtype=str,skip_header=1)	314	18	314	89	3603591776980576118
1	315	38	315	39	-63576726028659507	plt.hist(x,50,normed=1,facecolor='g',alpha=0.75)	315	17	315	65	784819679426095242
1	315	41	315	42	-3551238398045696202	pd.concat([df,ap_type_dums], axis = 1)	315	5	315	43	317733627672829707
1	316	55	316	56	802431346545966533	laliga.apply(corner_home, axis=1)	316	24	316	57	4159397322393669499
1	317	55	317	56	4147774921393833580	laliga.apply(corner_away, axis=1)	317	24	317	57	-6709135226833351889
1	318	22	318	23	-7556417494097268597	plt.clabel(CS, inline=1, fontsize=10)	318	0	318	37	-529377627355772990
1	318	27	318	28	-8934555355684273727	laliga.drop('corner', axis=1, inplace=True)	318	0	318	43	3006527905896595398
1	318	68	318	69	4393521537480607783	male_first_names['name'].sample(n= 1)	318	33	318	70	1400747492618682309
1	320	51	320	52	5880304358607305115	Td.mapMatrices([DDD[k] for k in range(len(DDD))], lTitl=range(len(DDD)),\n               fs=(13,15), ncl=(4,3), vmin=0, vmax=1, cmap="seismic", cbar=1)	319	0	320	77	-1927851544002136358
1	320	75	320	76	-197370017290287287	Td.mapMatrices([DDD[k] for k in range(len(DDD))], lTitl=range(len(DDD)),\n               fs=(13,15), ncl=(4,3), vmin=0, vmax=1, cmap="seismic", cbar=1)	319	0	320	77	-1927851544002136358
1	320	90	320	91	-7170164213644627981	np.genfromtxt("OscarInfo.csv", delimiter='\t', dtype=str,skip_header=1)	320	21	320	92	-5616931109872740071
1	325	53	325	54	-1812244847722969802	Te.data2array('cluster/clus_512u_con.npy', dic=1)	325	6	325	55	6373723067587902250
1	326	28	326	29	-2632601652357294393	df.drop(col_names, axis=1, inplace=True)	326	4	326	44	7956934257304632684
1	327	40	327	41	-4070929971264361121	true_centers.apply(np.sum,axis=1)	327	9	327	42	1163674667734878057
1	328	29	328	30	-7466669789942551135	Tk.Radiobutton(kernel_group, text="RBF", variable=controller.kernel,\n                       value=1, command=controller.refit)	327	8	328	57	-8011687242011609498
1	329	46	329	47	-2012857669217137875	true_centers.sum(axis=1)	329	24	329	48	-7678379610608638032
1	333	51	333	52	-88575987837279287	np.genfromtxt(dir + '/apo/' + this.name + '_chi_pop_hist_targ.txt', delimiter=',',\n                                       skip_header=1)	332	26	333	53	309966577195007158
1	333	52	333	53	-3962016627407959811	ax.legend(['ETHN == 1', 'ETHN == 0'], scatterpoints=1, loc='upper left')	333	0	333	72	3709733235816311549
1	335	51	335	52	-408745825540410445	np.genfromtxt(dir + '/atpmg/' + this.name + '_chi_pop_hist_ref.txt', delimiter=',',\n                                       skip_header=1)	334	24	335	53	2157044727711122883
1	344	13	344	14	6105951250266178743	arr.sum(axis=1)	344	0	344	15	-9104405379574289652
1	344	28	344	29	-4239975479277049238	plt.plot(t, mean_prob_t, lw=1, ls="--", color="k", label="average posterior \nprobability of defect")	344	0	344	101	-6091860215929360791
1	345	81	345	82	3532094864353915197	Td.circular(allLinesT[:,clus], down=dow, cmap='afmhot', lbl=lbl, avg=1,\n                        save='cicular_fig/con_%i_%s_%i_%i.png'%(15,k,cc,icc+1))	345	12	346	79	-7036973836525886869
1	346	57	346	58	3314828289412620544	df_fact.drop(['Assigned Department', 'department'], axis=1, inplace=True)	346	0	346	73	8478548605853871963
1	349	11	349	12	3154791933589690520	section_data_df[['start', 'end']].apply(\n    lambda t: (\n        20 * cos(atan2(t[0].x - t[1].x, t[0].y - t[1].y) + pi/2),\n        20 * sin(atan2(t[0].x - t[1].x, t[0].y - t[1].y) + pi/2),\n    )\n    , axis=1\n)	344	28	350	1	6752613774564700702
1	349	17	349	18	7222885260965722541	mean(Dt,axis=1)	349	4	349	19	1699503517465056327
1	350	16	350	17	-1684778062403528431	std(Dt,axis=1)	350	4	350	18	-6593698184281802762
1	350	20	350	21	-7232285744322941237	arr.mean(axis=1)	350	6	350	22	-4875982052339400558
1	351	54	351	55	-1542929123447557955	plt.pcolormesh(sc_yedges, sc_xedges, sc_H, vmin=1,  norm=matplotlib.colors.LogNorm())	351	6	351	91	2452240325170736297
1	351	73	351	74	6874952693474592000	pd.concat([df1,df2,df3,df_labels,df_labels_years,df_colors],axis = 1)	351	6	351	75	-3713176994476517031
1	355	62	355	63	-6152746777348861574	bblnrgdata.plot(kind='scatter',x='nrg',y='UnitsTotal',\n                fontsize=22, colormap='gist_rainbow', alpha = 1,\n                marker='o',  figsize=(16, 14), loglog=True,\n                xlim=(1000,1e11), ylim=(1,1000),\n                c=bblnrgdata['YearBuilt']-1900,\n                s=bblnrgdata['UnitsTotal']/bblnrgdata['UnitsRes']*100)	354	0	359	70	-8267963167352388908
1	355	100	355	101	-192762351411051654	MLPClassifier(solver='adam', activation = 'logistic',hidden_layer_sizes=(10, 50), random_state=1)	355	5	355	102	6411097785699248540
1	356	52	356	53	5400408702727016024	ax.legend(['ETHN == 1', 'ETHN == 0'], scatterpoints=1, loc='upper left')	356	0	356	72	-6450907318348424137
1	357	29	357	30	-7506940877840586806	A.sum(axis=1)	357	18	357	31	8233794652359943239
1	359	30	359	31	5901158492454632527	plt.Circle((0,0), radius=1, fill=False)	359	5	359	44	-7885536374790363944
1	363	45	363	46	912450407455413127	pd.concat([inc, out_one_std], axis=1, join='inner')	363	10	363	61	1123276176446811343
1	364	45	364	46	-3670594600219142149	pd.concat([dec, out_one_std], axis=1, join='inner')	364	10	364	61	-3679564600864059513
1	364	63	364	64	8759762648160545864	(s.gas['pos'][:, 0:2] * s.gas['vel'][:, 0:2]).sum(axis=1)	364	8	364	65	5494142290540033397
1	364	72	364	73	-7150100346775108393	df_topics.apply(lambda x: get_topic_wc(x), axis=1)	364	24	364	74	-5595362629119198566
1	365	19	365	20	1498328210679628763	(arr > 0).sum(axis=1)	365	0	365	21	-3793727037921605272
1	366	9	366	10	-918561023077802103	inversed[['geometry', 'offset']].apply(\n    lambda t: translate(t[0], yoff=t[1][0], xoff=t[1][1]) ,\n    axis=1\n)	364	23	367	1	-6820063428061674029
1	366	29	366	30	-6285987890637408102	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n         c='r', s=100, alpha=1, marker = 'o', edgecolor = 'k', linewidth = 1.0)	365	0	366	79	3855291344375119264
1	369	63	369	64	-4967793331570502846	Tk.Radiobutton(cmap_group, text="Surface",\n                       variable=controller.surface_type, value=1,\n                       command=controller.refit)	368	8	370	48	1763229821639939165
1	369	75	369	76	-6159936619670609557	ax.contour(L, C, utility, np.array([u_star0]), colors='k', linewidths=1, linestyles='solid')	369	5	369	97	7659917376901205105
1	370	21	370	22	7680252258551706416	ax.clabel(CS, inline=1, fmt='%1.4f')	370	0	370	36	8603561627059922685
1	377	40	377	41	7199714383065321736	pd.concat([df, POS_DUMMY],axis=1)	377	9	377	42	5126074380105943192
1	379	22	379	23	-7861497481468790227	plt.clabel(CS, inline=1, fontsize=10)	379	0	379	37	-8837687480196764555
1	379	39	379	40	-3809784552532552358	plt.bar(x, autocorr( y_t )[1:], width =1, label="$y_t$",\n        edgecolor = colors[0], color = colors[0] )	379	0	380	50	6693032370456288991
1	381	39	381	40	4439941508983582133	plt.bar(x, autocorr( x_t )[1:], width =1,label = "$x_t$",\n        color = colors[1], edgecolor = colors[1] )	381	0	382	50	3437617657289279308
1	383	43	383	44	-1042564680905131048	manifold.MDS(2, max_iter=100, n_init=1)	383	6	383	45	-5867606046585449730
1	388	57	388	58	-5393387489643589790	pd.concat([bike_df_temp, noun_adj_parsed], axis=1)	388	9	388	59	-8148904626560222522
1	389	22	389	23	-8377513314272391126	plt.clabel(CS, inline=1, fontsize=10, manual=manual_locations)	389	0	389	62	5246727740047935580
1	390	40	390	41	-736540290200108222	pd.concat([df, POS_DUMMY],axis=1)	390	9	390	42	4970411778497117485
1	393	50	393	51	1105169790173137231	np.argmax(np.abs(ica.components_), axis=1)	393	10	393	52	-1164933678322285819
1	394	96	394	97	-7746590978431651602	AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy',max_depth=4),n_estimators=1,learning_rate=4)	394	6	394	114	5316529189215550691
1	397	18	397	19	7871816279993556307	np.sort(arr, axis=1)	397	0	397	20	4608128844889600265
1	397	55	397	56	9040905934396742806	plt.bar(x, autocorr( y_t )[1:max_x], edgecolor=colors[0],\n        label="no thinning", color = colors[0], width =1 )	396	0	397	58	-2178054465131954399
1	397	90	397	91	-1174443809510642844	mergedData.apply(lambda x: dateutil.parser.parse(x.timeStamp) , axis=1)	397	21	397	92	5356033360155950124
1	398	34	398	35	-4502542362489873931	plt.clabel(CS, fontsize=9, inline=1)	398	0	398	36	2040321736911236875
1	398	42	398	43	-739962997371104959	np.random.normal(loc=0, scale=1, size=(num_samples, latent_dim))	398	12	398	76	-5962730334803913938
1	399	54	399	55	5887367227382865047	mergedData.sort_values("time", ascending=1)	399	13	399	56	3475892903220835545
1	399	66	399	67	-6094160591750375896	plt.bar(x, autocorr( y_t[::2] )[1:max_x], edgecolor=colors[1],\n        label="keeping every 2d sample", color = colors[1], width=1 )	398	0	399	69	4255622924992032748
1	400	39	400	40	-8302594911489856072	eq.drop(eq.columns[[1,5,6]],axis=1)	400	6	400	41	7904395466884403703
1	400	49	400	50	2992172561874494504	plt.bar(x, autocorr( y_t[::3] )[1:max_x], width =1, edgecolor = colors[2],\n        label="keeping every 3rd sample", color = colors[2] )	400	0	401	61	5918103853306597975
1	400	56	400	57	-7411307502182057458	pd.merge(df_pca_2, df, left_index=1, right_index=1)	400	22	400	73	8826660712961154827
1	400	71	400	72	3727844099824346564	pd.merge(df_pca_2, df, left_index=1, right_index=1)	400	22	400	73	8826660712961154827
1	403	51	403	52	7514816047264538589	plt.imshow(x_gen.reshape(28, 28), vmin=0, vmax=1, cmap="gray")	403	4	403	66	-6570058676893075456
1	404	67	404	68	-5404196668006230961	laliga.apply(cards_home_yellow, axis=1)	404	30	404	69	-5058596341182649039
1	405	61	405	62	-1191759364409770017	laliga.apply(cards_home_red, axis=1)	405	27	405	63	-689191360438501473
1	406	67	406	68	8983597551666230156	laliga.apply(cards_away_yellow, axis=1)	406	30	406	69	3616756477275612307
1	407	34	407	35	8356997446271664343	plt.clabel(CS, fontsize=9, inline=1)	407	0	407	36	-2289176966538127860
1	407	61	407	62	1629616032705412427	laliga.apply(cards_away_red, axis=1)	407	27	407	63	7280141894606353704
1	408	57	408	58	116921462286192560	pd.merge(df_pca_3, df, left_index=1, right_index=1)	408	23	408	74	-6202196796744004870
1	408	72	408	73	6633428703820834782	pd.merge(df_pca_3, df, left_index=1, right_index=1)	408	23	408	74	-6202196796744004870
1	408	77	408	78	190759391679483671	ax.contour(L, C, utility, np.array([u_star0]), colors='k', linewidths=1, linestyles='solid', alpha=0.25)	408	7	408	111	-8239414590776562030
1	409	25	409	26	-3126884312485688406	laliga.drop('card', axis=1, inplace=True)	409	0	409	41	-7018651312275067122
1	409	58	409	59	-6013115336052391512	ax.scatter(stickerLocations.x, stickerLocations.y, zorder=1)	409	0	409	60	-1728252456855995129
1	409	77	409	78	-8478717771589243333	ax.contour(L, C, utility, np.array([u_star1]), colors='k', linewidths=1, linestyles='solid')	409	7	409	99	5804230501031402061
1	410	23	410	24	-9208514028721875902	ax.clabel(CS_1, inline=1, fmt='%1.4f')	410	0	410	38	-5709764950764250914
1	414	45	414	46	4289607952921223787	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	413	4	414	54	6842099077418229338
1	416	42	416	43	-6372525148964861385	plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)	416	19	416	71	3157537019805761873
1	417	26	417	27	-8473332878150907925	my_df.reset_index(inplace=1)	417	0	417	28	-1591617598548264015
1	417	34	417	35	-524934792018848041	plt.clabel(CS, fontsize=9, inline=1)	417	0	417	36	1262263026211807309
1	417	57	417	58	6526783836328349602	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	417	8	417	65	3655740941668474552
1	425	36	425	37	2607337906721473526	df_by_author_topic.apply(\n    lambda x: get_main_pct(x), axis=1\n)	424	39	426	1	-7730989595160190316
1	427	33	427	34	-8606297745876349873	cmap.set_bad(color="black",alpha=1)	427	0	427	35	8368066408216310608
1	427	45	427	46	3315163776212585500	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	426	4	427	54	6953547065135165108
1	428	35	428	36	-1446200182049310551	cmap.set_under(color="black",alpha=1)	428	0	428	37	3131303504897536827
1	429	34	429	35	-3463769249316494448	cmap.set_over(color="white",alpha=1)	429	0	429	36	-2688325534289989938
1	430	57	430	58	-7356180392392273804	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	430	8	430	65	-1297565595430734842
1	437	18	437	19	-609015909874747656	plt.clabel(CS, levels[1::2],  # label every second level\n           inline=1,\n           fmt='%1.1f',\n           fontsize=14)	436	0	439	23	3127135430133223689
1	437	34	437	35	4534477047818850364	my_df.set_index('people', inplace=1)	437	0	437	36	7556714174896248445
1	440	104	440	105	-3264696989826529562	np.nanmean((data_pert.fluxes[var][flux]-data_diff.fluxes[var][flux])[:,k,:],axis=1)	440	23	440	106	3033693047021181241
1	445	23	445	24	-6196051983870686	laliga.drop("id", axis=1, inplace=True)	445	0	445	39	-6288303440241164609
1	449	37	449	38	8226609169740451608	SGDClassifier(loss='log', eta0=1, learning_rate='constant', penalty=None)	449	6	449	79	-8318970753728310211
1	449	49	449	50	4379603833404587740	plot_total_flux(pert_const,pert_bench,'Flux',row=1,col=1)	449	0	449	57	-5665042726547911018
1	449	55	449	56	6599164382227405532	plot_total_flux(pert_const,pert_bench,'Flux',row=1,col=1)	449	0	449	57	-5665042726547911018
1	457	40	457	41	9177593458962079749	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,\n        linewidth=0, antialiased=False)	457	7	458	39	4002728354256283703
1	457	51	457	52	-8620358044818436696	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,\n        linewidth=0, antialiased=False)	457	7	458	39	4002728354256283703
1	459	47	459	48	1821730872624259686	np.genfromtxt(dir + '/apo/' + name + '_chi_pop_hist_targ.txt', delimiter=',',\n                                   skip_header=1)	458	26	459	49	2957107695328218946
1	461	47	461	48	-6736022002915617648	np.genfromtxt(dir + '/atpmg/' + name + '_chi_pop_hist_ref.txt', delimiter=',',\n                                   skip_header=1)	460	24	461	49	7214765947206704390
1	462	36	462	37	8328105265674072534	pd.concat([df, ranked], axis=1)	462	7	462	38	-6040444641331231176
1	463	70	463	71	-2935167298191240504	fig.suptitle("Dimensional Plots - Political Party", fontsize = 60,y = 1,verticalalignment = "bottom" )	463	0	463	102	-702850609515704279
1	468	97	468	98	-5012407090854188602	windowDetections.apply(lambda x: dateutil.parser.parse(x.time) , axis=1)	468	27	468	99	-4846426898077991571
1	469	26	469	27	7151143950083832570	Perceptron(alpha = 1, penalty = None,fit_intercept = False)	469	7	469	66	-8489357744387976939
1	479	51	479	52	-780449276820254434	np.genfromtxt(dir + '/apo/' + name + '_chi_pop_hist_targ.txt', delimiter=',',\n                                       skip_header=1)	478	30	479	53	-3823166977662775906
1	479	52	479	53	-1186367239111021421	pd.concat([df_heatmap, data], axis=1)	479	17	479	54	6572784527060473637
1	481	51	481	52	6340082650472550644	np.genfromtxt(dir + '/atpmg/' + name + '_chi_pop_hist_ref.txt', delimiter=',',\n                                       skip_header=1)	480	28	481	53	-8237295620613885746
1	483	72	483	73	-4845106217879938534	MDS(n_components=2, dissimilarity="precomputed", random_state=1, n_jobs=num_jobs)	483	10	483	91	5988568686961172068
1	484	93	484	94	-8305467523429900055	beta.fit(top_offenses.ShP, floc=0, fscale=1)	484	51	484	95	6171820234266495213
1	495	67	495	68	8688618825084377439	plt.plot_date(windowDetections.time, windowDetections.rssi, zorder=1, alpha=0.5)	495	0	495	80	-4449554861507492140
1	496	40	496	41	-4304690782345984314	ax.plot_surface(X,Y,Z, rstride = 1,cstride=1, cmap=cm.jet, linewidth=0, antialiased=False)	496	7	496	97	-705707174207070820
1	496	47	496	48	8511626908771839599	np.genfromtxt(dir + '/apo/' + name + '_chi_pop_hist_targ.txt', delimiter=',',\n                                   skip_header=1)	495	26	496	49	-8700896598347999053
1	496	50	496	51	-6872019609707400694	ax.plot_surface(X,Y,Z, rstride = 1,cstride=1, cmap=cm.jet, linewidth=0, antialiased=False)	496	7	496	97	-705707174207070820
1	498	47	498	48	-8487600838198687111	np.genfromtxt(dir + '/atpmg/' + name + '_chi_pop_hist_ref.txt', delimiter=',',\n                                   skip_header=1)	497	24	498	49	1443587735697741512
1	500	41	500	42	-8136634333341703949	plt.subplots(nrows=1, ncols=2, figsize=(18, 8), tight_layout=True)	500	22	500	88	-45604085668237932
1	513	33	513	34	2517643250334716931	ax.plot_surface(x,y,V,rstride=1,cstride=1,linewidth=0, cmap=cm.coolwarm)	513	3	513	75	-2205950612627632955
1	513	43	513	44	-3380488459978788335	ax.plot_surface(x,y,V,rstride=1,cstride=1,linewidth=0, cmap=cm.coolwarm)	513	3	513	75	-2205950612627632955
1	513	58	513	59	-6823864708545403240	ax.scatter(stickerLocations.x, stickerLocations.y, zorder=1)	513	0	513	60	-905921440204966893
1	516	124	516	125	4344291908130258406	plt.plot(strength_table, strength_table, linestyle='--', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round', markevery='2')	516	4	516	164	-3720465430626813164
1	521	28	521	29	-8870175935147742015	generated_nodes.argmax(axis=1)	521	0	521	30	-8104989415923238803
1	522	39	522	40	7023462927206623231	plt.scatter(walkDF.x, walkDF.y, zorder=1, s=abs(walkDF.rssi)*10, alpha=0.01)	522	0	522	76	-278831700181624586
1	523	28	523	29	-6685935805760165487	plt.plot(t, mean_prob_t, lw=1, ls="--", color="k", label="average posterior \nprobability of defect")	523	0	523	101	-4583366704275841173
1	523	105	523	106	-5235264638629939104	get_mds(bike_df_Nouns_final,sample_size=Nouns_sample_size, nouns_only=True, ngram=1)	523	23	523	107	-4152512480974354907
1	523	120	523	121	-8247192933310622793	ax1.plot(strength_table, strength_table, linestyle='--', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round', markevery='2')	523	0	523	160	7608270121251534110
1	525	29	525	30	2867246229347130741	ax.scatter(this.offset_factor, np.mean(this.flux_u + this.flux_b),\n         c='r', s=100, alpha=1, marker = 'o', edgecolor = 'k', linewidth = 1.0)	524	0	525	79	3328580635593191323
1	530	120	530	121	212873215466741231	ax2.plot(strength_table, strength_table, linestyle='--', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round', markevery='2')	530	0	530	160	-1438775393934012399
1	531	15	531	16	-4643367419753732804	a.argsort(axis=1)	531	0	531	17	-8428613104855140442
1	533	58	533	59	6722683131656377083	fit1((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1,cutoff=0.2)	533	0	533	71	1551108491435502961
1	538	120	538	121	8671283030232104144	ax3.plot(strength_table, strength_table, linestyle='--', linewidth='0.5', marker='', dashes=[2, 2], color='0.5', zorder=1, dash_capstyle='round', markevery='2')	538	0	538	160	-6319099639761388213
1	539	23	539	24	5334542498930622045	lai.mean(axis=1)	539	9	539	25	2992130675090407658
1	539	36	539	37	5901480657789147712	lai.mean(axis=1).mean(axis=1)	539	9	539	38	6154356440996067712
1	543	58	543	59	5147963633250548981	fit2((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1,cutoff=0.2)	543	0	543	71	7075271638523091699
1	544	58	544	59	-5054727609586770972	lai.mean(axis=1)	544	44	544	60	2887153439989270776
1	544	71	544	72	-1949822289233930881	lai.mean(axis=1).mean(axis=1)	544	44	544	73	-4630707776501163608
1	555	60	555	61	-7288635119548283671	fit((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1, cutoff=0.2)	555	0	555	74	-3109979336477302602
1	561	37	561	38	-3878815962509812900	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n                   linewidth=0, antialiased=False)	561	4	562	50	-3843361364894442248
1	561	48	561	49	-1076528145677344738	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n                   linewidth=0, antialiased=False)	561	4	562	50	-3843361364894442248
1	567	74	567	75	1386063904419556946	fig.suptitle("Dimensional Plots - Presidential Rating", fontsize = 60,y = 1,verticalalignment = "bottom" )	567	0	567	106	-3169009767698323184
1	577	58	577	59	7146436837212218534	traffic_data.sample(frac=1)	577	33	577	60	1941348403569552446
1	578	81	578	82	-2816952191160372706	traffic_injuries_only.sample(frac=1)	578	47	578	83	4169459578118828007
1	579	63	579	64	7579818097317144316	traffic_data_50.sample(frac=1)	579	35	579	65	2783000546016535163
1	588	38	588	39	-4757106030189895570	x1.apply(calcrow,axis = 1)	588	14	588	40	4485499451683846834
1	588	61	588	62	-1608473441870782404	interpolate.approximate_taylor_polynomial(f, x=1, degree=1, scale=0.01)	588	14	588	85	3570460401851039109
1	588	71	588	72	-5351349194795566340	interpolate.approximate_taylor_polynomial(f, x=1, degree=1, scale=0.01)	588	14	588	85	3570460401851039109
1	589	43	589	44	5660602389152224787	x1.apply(scorerow,axis =1)	589	19	589	45	-909145671532708479
1	589	61	589	62	8794008212829631098	interpolate.approximate_taylor_polynomial(f, x=1, degree=2, scale=0.01)	589	14	589	85	7997301780110804467
1	590	61	590	62	-2790113821674697715	interpolate.approximate_taylor_polynomial(f, x=1, degree=3, scale=0.01)	590	14	590	85	399747812610286652
1	591	61	591	62	8922320971029815927	interpolate.approximate_taylor_polynomial(f, x=1, degree=4, scale=0.01)	591	14	591	85	3009300424948878630
1	592	32	592	33	-7964637645426727920	SVC(kernel='linear',C=1)	592	10	592	34	-5396077563726052839
1	592	61	592	62	1646895449522068468	interpolate.approximate_taylor_polynomial(f, x=1, degree=5, scale=0.01)	592	14	592	85	-3566665012894489271
1	608	32	608	33	-189755058723841558	svm.SVC(kernel='linear',C=1,tol=0.001)	608	6	608	44	6143988596648742005
1	618	18	618	19	2925654200661908791	SVC(C=1, kernel='rbf', gamma=0.001)	618	12	618	47	7772591473378161024
1	623	66	623	67	6754326341459613910	gensim.models.ldamodel.LdaModel(corpus_gensim_final,\n                                                     alpha='auto',\n                                                     id2word=id2words_final,\n                                                     num_topics=eachtopic,\n                                                     update_every=1,\n                                                     chunksize=1000,\n                                                     passes=5)	619	38	625	62	-6551039708748265267
1	655	57	655	58	-2662318796771066113	np.nansum(datapl[:,0:k],axis=1)	655	28	655	59	1890877691581088266
1	659	57	659	58	-1960528275160544203	np.nansum(datapl[:,0:k],axis=1)	659	28	659	59	-4973530260670755447
1	678	59	678	60	8293179833173323729	fig.suptitle("Dimensional Plots - Year", fontsize = 60,y = 1,verticalalignment = "bottom" )	678	0	678	91	483962630431335773
1	691	19	691	20	-7322550496687562964	DBSCAN(eps = 1, min_samples = 5)	691	6	691	38	4402771485680869828
1	692	102	692	103	6715552683603687687	np.nansum(datapl[:,0:k],axis=1)	692	73	692	104	-376591528484651653
1	695	102	695	103	-6863429392393207568	np.nansum(datapl[:,0:k],axis=1)	695	73	695	104	-9082702204752867079
1	696	44	696	45	6625790943568058619	np.max(coef, axis=1)	696	26	696	46	5431416731227824742
1	697	44	697	45	6624859453713984967	np.min(coef, axis=1)	697	26	697	46	-8754720062647720378
1	702	50	702	51	2618911943784560875	np.min(coef, axis=1)	702	32	702	52	-6213482165150505163
1	703	32	703	33	-5444130536456287706	np.max(coef, axis=1)	703	14	703	34	2374639531222476284
1	711	64	711	65	3391074043148794160	pd.concat([df_N_topic_analysis, topicdf], axis=1)	711	17	711	66	8478206252721790920
1	720	28	720	29	739682437637866823	plt.plot(t, mean_prob_t, lw=1, ls="--", color="k", label="average posterior \nprobability of defect")	720	0	720	101	830718305184047429
1	729	50	729	51	8075203057377173750	np.nansum(datapl[:,0:30],axis=1)	729	20	729	52	-8974250309330385429
1	733	19	733	20	3197971247520573016	DBSCAN(eps = 1, min_samples = 5)	733	6	733	38	7101427547267369405
1	733	50	733	51	7080500390164388451	np.nansum(datapl[:,0:30],axis=1)	733	20	733	52	-1751851094142085564
1	735	47	735	48	1029902195383545617	np.nansum(datapl1[:,0:30],axis=1)	735	16	735	49	7931296990131600724
1	744	19	744	20	2655069181532645369	DBSCAN(eps = 1, min_samples = 5)	744	6	744	38	-3963901331349930028
1	827	98	827	99	1803494290603110318	axes1.scatter(projected_data_pca[c==clusters_lda,0], projected_data_pca[c==clusters_lda,1], s=1,\n                  label=c, alpha=0.5)	827	4	828	37	4066305552357777776
1	830	90	830	91	-5246510779903211776	axes2.scatter(projected_data_pca[c==y_true,0], projected_data_pca[c==y_true,1], s=1,\n                      label=complaints_map[c][:7], alpha=0.5)	830	8	831	61	-4190971274848778200
1	835	48	835	49	3086181717528664994	pred.apply(predupset,axis = 1)	835	20	835	50	-9200151874046237118
1	861	71	861	72	2057644287685408058	axarr[1, 0].bar(np.arange(-0.5, len(values)-1, 1), values, width = 1)	861	4	861	73	-198603989764247404
1	862	98	862	99	5519572320958084087	axes1.scatter(projected_data_pca[c==clusters_nmf,0], projected_data_pca[c==clusters_nmf,1], s=1, label=c, alpha=0.5)	862	4	862	120	-8900090268387052725
1	865	106	865	107	-4730136077374622323	axes2.scatter(projected_data_pca[np.int64(i)==y_true,0], projected_data_pca[np.int64(i)==y_true,1], s=1,\n                  label=complaints_map[i][:7], alpha=0.5)	865	4	866	57	-6581751970457281376
1	867	69	867	70	298361723327818691	axarr[1, 1].bar(np.arange(-0.5,len(values)-1,1), values, width = 1)	867	4	867	71	3216867597139167517
1	884	38	884	39	-5395338274970232183	x1.apply(calcrow,axis = 1)	884	14	884	40	-2495047563050576383
1	885	43	885	44	6750078949350476716	x1.apply(scorerow,axis =1)	885	19	885	45	-1187051241020337523
1	895	98	895	99	-575410322771649930	axes1.scatter(projected_data_pca[c==clusters_kmn,0], projected_data_pca[c==clusters_kmn,1], s=1, label=c, alpha=0.5)	895	4	895	120	-4025172026161640228
1	897	90	897	91	29434034080201842	axes2.scatter(projected_data_pca[c==y_true,0], projected_data_pca[c==y_true,1], s=1,\n                  label=complaints_map[c][:7], alpha=0.5)	897	8	898	57	6934249276096232202
1	912	35	912	36	1626690293504851664	prob.drop('Team_Id_x',axis =1)	912	7	912	37	5312680906552053343
1	913	35	913	36	76597339028825293	prob.drop('Team_Id_y',axis =1)	913	7	913	37	-2112344818118260140
1	951	28	951	29	-8390310243266048523	plt.plot(t, mean_prob_t, lw=1, ls="--", color="k", label="average posterior \nprobability of defect")	951	0	951	101	-5858314063920664092
1	961	42	961	43	1191731785997318559	plt.bar(bin_edges[:-1], hist, width = 1)	961	4	961	44	4277518541804396681
1	972	42	972	43	-2933306795078786353	plt.bar(bin_edges[:-1], hist, width = 1)	972	4	972	44	-5856495257269344602
1	1000	60	1000	61	-4282401365916632782	np.sum(cnf_matrix, axis=1)	1000	36	1000	62	-3288804470924573614
1	1008	22	1008	23	3670309294826079853	axes1.scatter(projected_other[c == clusters_lda_o,0],\n                  projected_other[c == clusters_lda_o, 1],\n                  s = 1, label = c, alpha = 0.5)	1006	4	1008	48	-5768612246369178337
1	1012	22	1012	23	7728712957348602883	axes2.scatter(projected_other[c == clusters_nmf_o,0],\n                  projected_other[c == clusters_nmf_o, 1],\n                  s = 1, label = c, alpha = 0.5)	1010	4	1012	48	6064451688903567193
1	1016	22	1016	23	1368146456753101848	axes3.scatter(projected_other[c == clusters_kmn_o,0],\n                  projected_other[c == clusters_kmn_o, 1],\n                  s = 1, label = c, alpha = 0.5)	1014	4	1016	48	6008437219766897820
1	1051	88	1051	89	-365720201934915516	outputFeatureMap(images[0], x, layers[0], activation_min=-1, activation_max=-1 ,plt_num=1)	1051	0	1051	90	8602194780048898746
1	1056	88	1056	89	-3667149388717562281	outputFeatureMap(images[2], x, layers[0], activation_min=-1, activation_max=-1 ,plt_num=1)	1056	0	1056	90	-8304426431505857030
1	1061	88	1061	89	6072632015440037346	outputFeatureMap(images[4], x, layers[0], activation_min=-1, activation_max=-1 ,plt_num=1)	1061	0	1061	90	-6869666837272354147
1	1063	42	1063	43	-8822678507623737875	plt.bar(bin_edges[:-1], hist, width = 1)	1063	4	1063	44	-3496639820222580148
1	1066	89	1066	90	-3127132554671645537	outputFeatureMap(images[6], x,  layers[0], activation_min=-1, activation_max=-1 ,plt_num=1)	1066	0	1066	91	-4371609093267501073
1	1089	46	1089	47	236901728039625803	cm.sum(axis=1)	1089	34	1089	48	-5833245720490969030
1	1118	63	1118	64	5396234355334607471	plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.5), ncol=1, fancybox=True, shadow=True)	1118	0	1118	93	4592944422313101283
1	1128	102	1128	103	-313917790661452615	np.nansum(datapl[:,0:k],axis=1)	1128	73	1128	104	-7507677054282814754
1	1131	102	1131	103	-5925138185195488220	np.nansum(datapl[:,0:k],axis=1)	1131	73	1131	104	1929923007431774428
1	1190	15	1190	16	-3672951482480057029	T.sum(-T.log(model_merged_1.p_y_given_x_relaxed) * model_1.p_y_given_x_relaxed,\n          axis=1)	1189	4	1190	17	-3744292412262909746
1	1229	28	1229	29	-475496332115691922	plt.plot(t, mean_prob_t, lw=1, ls="--", color="k", label="average posterior \nprobability of defect")	1229	0	1229	101	7240304214489707866
1	1284	51	1284	52	-963967559287374263	gensim.models.ldamodel.LdaModel(corpus=mm,\n                                      id2word=dictionary,\n                                      num_topics=50,\n                                      update_every=1,\n                                      chunksize=10000,\n                                      passes=100)	1281	6	1286	49	7036574731868352903
1	1318	15	1318	16	2914269472146931603	T.sum(-T.log(model_merged_2.p_y_given_x_relaxed) * model_1.p_y_given_x_relaxed,\n          axis=1)	1317	4	1318	17	9013053282460382912
1	1323	15	1323	16	6692314860802841913	T.sum(-T.log(model_merged_2.p_y_given_x_relaxed) * model_merged_1.p_y_given_x_relaxed,\n          axis=1)	1322	4	1323	17	-7237716915897795076
1	1347	87	1347	88	-3849382670010767230	np.nanmean(data.ptracers[ptracer][t,:,:,0:200],axis=1)	1347	35	1347	89	3732406531037414291
1	1348	101	1348	102	-5981029237361549666	np.nanmean(data.ptracers[ptracer][t,:,:,0:200],axis=1)	1348	49	1348	103	7660250876060252318
1	1437	69	1437	70	2160405507839406059	np.nanmean(diff[t,:,:,0:200],axis=1)	1437	35	1437	71	7599119254561292169
1	1438	101	1438	102	-184236475679279201	np.nanmean(data.ptracers[ptracer][t,:,:,0:200],axis=1)	1438	49	1438	103	7284979871706553679
1	1451	15	1451	16	4343333810210881816	T.sum(-T.log(model_merged_3.p_y_given_x_relaxed) * model_1.p_y_given_x_relaxed,\n          axis=1)	1450	4	1451	17	-7889981237114245065
1	1456	15	1456	16	30333591830552321	T.sum(-T.log(model_merged_3.p_y_given_x_relaxed) * model_merged_2.p_y_given_x_relaxed,\n          axis=1)	1455	4	1456	17	-3417249935660164243
1	1599	15	1599	16	8353128062224080573	T.sum(-T.log(model_merged_1.p_y_given_x_relaxed) * model_1.p_y_given_x_relaxed,\n          axis=1)	1598	4	1599	17	8416613952278403115
1	1604	15	1604	16	6850540964993475589	T.sum(-T.log(model_merged_1.p_y_given_x_relaxed) * model_2.p_y_given_x_relaxed,\n          axis=1)	1603	4	1604	17	-7942173703427255248
1	1604	31	1604	32	619167217165619100	np.concatenate((\n                        data.ptracers[ptracer][t,0:41,45*kk:58*kk,49*kk],\n                        data.ptracers[ptracer][t,0:41,58*kk,49*kk:66*kk]\n                        ),axis=1)	1601	35	1604	33	1230444226061811847
1	1608	31	1608	32	8213658711314839042	np.concatenate((\n                        data.ptracers[ptracer][t,0:41,45*kk:58*kk,49*kk],\n                        data.ptracers[ptracer][t,0:41,58*kk,49*kk:66*kk]\n                        ),axis=1)	1605	34	1608	33	-8619877885627553390
1	1741	15	1741	16	7981685687235135578	T.sum(-T.log(model_merged_2.p_y_given_x_relaxed) * model_merged_1.p_y_given_x_relaxed,\n          axis=1)	1740	4	1741	17	7408442048878726798
1	1746	15	1746	16	3579495712467594350	T.sum(-T.log(model_merged_2.p_y_given_x_relaxed) * model_3.p_y_given_x_relaxed,\n          axis=1)	1745	4	1746	17	8852218278633045652
1	1759	45	1759	46	173014209038489812	plt.legend(bbox_to_anchor=(1.05, 8), loc=1, borderaxespad=0.)	1759	4	1759	65	-5296798569961552845
1	1856	57	1856	58	6907018852156271289	plt.errorbar(linmean,linresolution,linresolutionerr,linmeanerr, marker='o', color='indigo',markersize=10, linestyle="",\n             label='Linear CES energy resolution', alpha=1)	1855	0	1856	59	-2838111590889231101
1	1859	62	1859	63	6558588350941715791	plt.errorbar(linmean,csresolution,csresolutionerr,csmeanerr, marker='o', color='royalblue',markersize=10, linestyle="",\n             label='Single line CES energy resolution', alpha=1)	1858	0	1859	64	-616559936193388232
1	1862	63	1862	64	3135408206834585367	plt.errorbar(linmean,parresolution,parresolutionerr,parmeanerr, marker='o', color='seagreen',markersize=10, linestyle="",\n             label='Parametrized CES energy resolution', alpha=1)	1861	0	1862	65	-5334230830350459560
1	1907	21	1907	22	-9103057943975069809	plot_dynStLayers({0:pert_const, 1 :pert_bench},['LaUH1TH_ave','LaVH1TH_ave','LaUH2RHO_ave','LaVH2RHO_ave'],\\n                 reg=1,row=2,col=2)	1906	0	1907	35	-5132290542186514365
1	1910	48	1910	49	-2652369465844468911	plt.errorbar(linmean,lindeltaenergy,lindeltaenergyerr,linmeanerr, marker='o', color='indigo',markersize=10, linestyle="",\n             label='Linear CES accuracy', alpha=1)	1909	0	1910	50	-1649682475758859383
1	1913	53	1913	54	-2218219995378630448	plt.errorbar(csmean,csdeltaenergy,csdeltaenergyerr,csmeanerr, marker='o', color='royalblue',markersize=10, linestyle="",\n             label='Single line CES accuracy', alpha=1)	1912	0	1913	55	-1350440438197371095
1	1916	54	1916	55	-14809843592967087	plt.errorbar(parmean,pardeltaenergy,pardeltaenergyerr,parmeanerr, marker='o', color='seagreen',markersize=10, linestyle="",\n             label='Parametrized CES accuracy', alpha=1)	1915	0	1916	56	-5885878675569113869
1	1919	15	1919	16	-7953172340066600848	T.sum(-T.log(model_merged_final.p_y_given_x_relaxed) * model_merged_1.p_y_given_x_relaxed,\n          axis=1)	1918	4	1919	17	6842679874434462253
1	1924	15	1924	16	4697616315631884854	T.sum(-T.log(model_merged_final.p_y_given_x_relaxed) * model_merged_2.p_y_given_x_relaxed,\n          axis=1)	1923	4	1924	17	7338908939585517679
3	6	30	6	31	1754941009982005821	np.set_printoptions(precision=3)	6	0	6	32	5699115787059551666
3	15	30	15	31	-5866045133773075444	np.set_printoptions(precision=3, suppress=True)	15	0	15	47	-7658498586583733998
3	20	31	20	32	6548445680932821180	hc.sample.df_timeseries(N=3, Nb_bd=2000)	20	5	20	45	-199428737668036561
3	23	30	23	31	3234338654325131039	player_game_log_15to16.head(n=3)	23	0	23	32	-5428611309601400241
3	23	77	23	78	8684793763516614873	DecisionTreeClassifier(max_depth=3)	23	44	23	79	7537730290341804613
3	32	31	32	32	-5455525007252399356	d[...,b0].std(axis=3, ddof=1)	32	12	32	41	6842214693927361060
3	33	14	33	15	3086283910577123486	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	30	16	35	1	660775984864435510
3	33	33	33	34	-2308509968048916857	d[...,b0].mean(axis=3)	33	13	33	35	7010132858499508337
3	38	36	38	37	-4851198514700663624	stats.expon.pdf( x, scale = 3)	38	8	38	38	210731067070832643
3	44	40	44	41	-5835572965295381846	item_item.get_similar_items(k=3)	44	10	44	42	6917012634092032093
3	45	37	45	38	-2909283818597161496	d[...,b0==0].mean(axis=3)	45	14	45	39	1974023074231183481
3	45	43	45	44	5322334792109519271	plot(date_ful,zeros(grdlen),'k-',linewidth=3)	45	0	45	45	-6513789522992246810
3	46	71	46	72	-5858689434335876506	data.rank(axis=0, pct=True).iloc[indices].round(decimals=3)	46	14	46	73	846251517124780643
3	47	87	47	88	-5376605782807738815	RandomForestRegressor(n_estimators=100, max_depth=3)	47	37	47	89	5911423604566722113
3	48	28	48	29	1234940718129607742	team_game_log_15to16.head(n=3)	48	0	48	30	-6803099034665400353
3	48	41	48	42	134182603476866747	ax.plot(x, T, color='red', linewidth=3)	48	4	48	43	-3651946992605663294
3	49	42	49	43	6667768552434414504	ax.plot(x, R, color='blue', linewidth=3)	49	4	49	44	-1345671932648286891
3	54	43	54	44	1987160421792635421	plot(date_ful,zeros(grdlen),'k-',linewidth=3)	54	0	54	45	9087862917079054424
3	55	34	55	35	-5187620338621436732	xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)	55	6	55	74	7398172325393511404
3	55	39	55	40	3700318050404397270	np.expand_dims(X_tests, axis=3)	55	10	55	41	1600131669733087398
3	56	50	56	51	-6641438377136416066	decomposition.PCA(copy=True, iterated_power=3, n_components=2,\n                        whiten=False, svd_solver='randomized')	56	6	57	62	4972156510544883061
3	56	50	56	51	4676828961469293732	pl.plot(x0, x0 * p[0] + p[1], color="#8d44ad", lw=3, alpha=0.5)	56	0	56	63	-2905091503646669297
3	62	49	62	50	-8909478698888714074	sns.pairplot(skin.sample(1000), hue="skin", size=3)	62	0	62	51	-5871883100669699539
3	64	34	64	35	-4583538645757356502	ax.plot(xx, zz(0), lw=3)	64	12	64	36	-8620774973542783489
3	66	101	66	102	720494205647109780	plt.plot(target[:,0], linear.predict(target[:,0:1]), color='blue',lw=3,label='linear',zorder=2)	66	32	66	127	1528334268609395672
3	67	103	67	104	-7651998078536498901	plt.plot(target[:,0], kde002.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.02',zorder=4)	67	33	67	156	-144954444229109048
3	68	153	68	154	6702309000395234354	plt.scatter(train[:,0], train[:,1], color='green', s=10+kde002_ratio*40,label='KDE-ratio-weighted train, W=0.02',zorder=3)	68	33	68	155	1085565062416215131
3	69	45	69	46	-8979829407321749300	percentiles.round(decimals=3)	69	18	69	47	4128665669816804562
3	71	103	71	104	-5910381127864443795	plt.plot(target[:,0], kde005.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.05',zorder=4)	71	33	71	156	1772569573835634527
3	72	55	72	56	-5418033654872161991	draw_3d(rat.p2a_prob, rat.a2p_prob, trial_window = 3)	72	4	72	57	7912182039015299835
3	72	153	72	154	2238848872587325053	plt.scatter(train[:,0], train[:,1], color='green', s=10+kde005_ratio*40,label='KDE-ratio-weighted train, W=0.05',zorder=3)	72	33	72	155	-8516668605770501379
3	75	42	75	43	4798339828679621215	plot(date_ful,zeros(grdlen),'k',linewidth=3)	75	0	75	44	8619895234065066894
3	75	101	75	102	-3155776233556894652	plt.plot(target[:,0], kde01.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.1',zorder=4)	75	32	75	153	1766649901380758584
3	76	37	76	38	1370903029368249907	ax[0].plot(teff,mag,'k.',alpha=.1,ms=3)	76	0	76	39	-9082221485672389027
3	76	150	76	151	345995779592229718	plt.scatter(train[:,0], train[:,1], color='green', s=10+kde01_ratio*40,label='KDE-ratio-weighted train, W=0.1',zorder=3)	76	32	76	152	5242014130145367238
3	77	24	77	25	4323490846931219860	graf(cos,100,i,V,o_,f,n=3)	77	0	77	26	4146557593860581361
3	78	27	78	28	-1348831779157299061	graf(cos,100*40,i,V,o_,f,n=3)	78	0	78	29	473179596684692297
3	79	101	79	102	6497169106073392828	plt.plot(target[:,0], kde02.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.2',zorder=4)	79	32	79	153	-7279543275457017682
3	80	150	80	151	1647689001488077498	plt.scatter(train[:,0], train[:,1], color='green', s=10+kde02_ratio*40,label='KDE-ratio-weighted train, W=0.2',zorder=3)	80	32	80	152	-4204556567489896980
3	83	101	83	102	-1895404495315208048	plt.plot(target[:,0], kmm1.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=1',zorder=4)	83	32	83	145	-1646188557944180816
3	84	42	84	43	7173131384637690379	plot(date_ful,zeros(grdlen),'k',linewidth=3)	84	0	84	44	-1632560898877749227
3	84	142	84	143	2906696300060850576	plt.scatter(train[:,0], train[:,1], color='orange', s=10+coef1[:,0]*40,label='KMM-weighted train, B=1',zorder=3)	84	32	84	144	-7121584724603890786
3	85	101	85	102	5224486714857718768	plt.plot(target[:,0], kmm2.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=2',zorder=4)	85	32	85	145	-3370060523980937033
3	86	142	86	143	7423711866255042150	plt.scatter(train[:,0], train[:,1], color='orange', s=10+coef2[:,0]*40,label='KMM-weighted train, B=2',zorder=3)	86	32	86	144	3193876471502622685
3	87	50	87	51	-1195559923507214551	sns.pairplot(skinx.sample(1000), hue="skin", size=3)	87	0	87	52	-195995336220074748
3	87	101	87	102	-2708831029001510873	plt.plot(target[:,0], kmm5.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=5',zorder=4)	87	32	87	145	4181261568880518420
3	88	24	88	25	-3034658370991394916	graf(sen,200,i,V,o_,f,n=3)	88	0	88	26	-4378526677318306007
3	88	142	88	143	-3356282946376331027	plt.scatter(train[:,0], train[:,1], color='orange', s=10+coef5[:,0]*40,label='KMM-weighted train, B=5',zorder=3)	88	32	88	144	-1070332439412133429
3	89	102	89	103	-7326466865133384908	plt.plot(target[:,0], kmm10.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=10',zorder=4)	89	32	89	147	-6868132458697930110
3	90	24	90	25	-6011641154479306023	graf(sen,200,i,V,o_,f,n=3)	90	0	90	26	7316463364613499425
3	90	144	90	145	9185344772160152749	plt.scatter(train[:,0], train[:,1], color='orange', s=10+coef10[:,0]*40,label='KMM-weighted train, B=10',zorder=3)	90	32	90	146	8847420700772513727
3	91	100	91	101	-1577120940555113497	plt.plot(target[:,0], kmm2q.predict(target[:,0:1]), color='cyan',lw=3,label='KMM-weighted quadratic, B=2',zorder=4)	91	32	91	147	1868897371205960727
3	93	38	93	39	-5504191223619671505	plt.plot(x,temp_1D_dir,'r-',linewidth=3)	93	0	93	40	-1761785122892553373
3	94	38	94	39	5186002124094618503	plt.plot(x,temp_1D_neu,'k-',linewidth=3)	94	0	94	40	1768806582074359113
3	97	49	97	50	3513714273977714292	plt.subplots(nrows=1, ncols=3, figsize=(18, 8), tight_layout=False)	97	21	97	88	-360381688180946754
3	98	55	98	56	-8202561564474218922	ecoreg.best_lasso(df, resp_var, exp_vars, kcv=3, cv_path=True, hists=False)	98	9	98	84	-7169309556621666194
3	102	23	102	24	4472881329393145819	graf(sen,75,i,V,o_,f,n=3)	102	0	102	25	548696498505558842
3	103	29	103	30	-6610505659557908263	graf(sen,75,.0001,"-",o_,f,n=3)	103	0	103	31	-2936662644466828762
3	105	42	105	43	-108967383035993210	plot(date_ful,zeros(grdlen),'k',linewidth=3)	105	0	105	44	-5475919849073894890
3	106	42	106	43	-3043443334070043772	stats.expon.pdf( x,loc=0, scale = 3)	106	8	106	44	5729776740074333081
3	106	71	106	72	7212750139672967875	np.rot90(img.reshape(32,32,3,order='F')[::-1,:,::-1], k=3)	106	15	106	73	7735015960849375866
3	107	32	107	33	7986154147274215623	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	107	12	107	63	-4656248289431326341
3	107	43	107	44	-9090644693559830284	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	107	12	107	63	-4656248289431326341
3	114	42	114	43	-4364407142443177905	plot(date_ful,zeros(grdlen),'k',linewidth=3)	114	0	114	44	2877264792365286484
3	117	46	117	47	-4410350642229449065	ax1.tick_params('both', which='minor', length=3, width=0.5)	117	0	117	59	2107846649023513777
3	119	34	119	35	1647497538592370516	team_opponent_stats_15to16.head(n=3)	119	0	119	36	-1048010284094016494
3	123	52	123	53	7812443975590475038	ax1.plot(sx1, sy1, c='k', linestyle='-.', linewidth=3)	123	0	123	54	3431842633757928051
3	128	32	128	33	-5281439983740804930	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	128	12	128	63	21177215522172225
3	128	43	128	44	-5469165029569052233	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	128	12	128	63	21177215522172225
3	131	46	131	47	2288500209966007720	ax1.tick_params('both', which='minor', length=3, width=0.5)	131	0	131	59	-90974908558296913
3	132	90	132	91	3436913002306404264	GradientBoostingRegressor(min_samples_split=2, max_depth=3, learning_rate=0.1)	132	33	132	111	-1667282952749129373
3	133	39	133	40	8273043049194877899	np.sum(X_train/3, axis =3, keepdims = True)	133	15	133	58	4213584901617796603
3	133	79	133	80	254697503827656886	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	133	35	133	114	1124544790473857417
3	133	92	133	93	6732082126341484026	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	133	35	133	114	1124544790473857417
3	134	40	134	41	428516212293022838	np.sum(X_valid/3, axis = 3, keepdims = True)	134	15	134	59	5375305170254328830
3	134	79	134	80	-6957020347885376437	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.09)	134	35	134	114	-8335371949776074257
3	134	92	134	93	-1483733762416303008	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.09)	134	35	134	114	-8335371949776074257
3	135	25	135	26	-2136711843349145866	plt.scatter(X, Y, zorder=3, c='r', s=60)	135	0	135	40	2726770031031432254
3	135	38	135	39	5024762642095103592	np.sum(X_test/3, axis = 3, keepdims = True)	135	14	135	57	5196193907179808596
3	135	42	135	43	865954408009674189	plot(date_ful,zeros(grdlen),'k',linewidth=3)	135	0	135	44	-4432822675264494476
3	135	79	135	80	5956578838670217257	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.10)	135	35	135	114	6854344890561255756
3	135	92	135	93	5581731275712570813	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.10)	135	35	135	114	6854344890561255756
3	136	68	136	69	8488643789389824585	GridSearchCV(pipeline, param_grid=param_grid, verbose=3, scoring='accuracy',\n                           cv = StratifiedShuffleSplit(train_y, n_iter=10, test_size=0.2,\n                                                       train_size=None, random_state=123)\n                          )	136	14	139	27	-3331654246897059501
3	137	23	137	24	2947895449034856736	KMeans(n_clusters=3, n_init=100)	137	5	137	37	5820437045395883845
3	138	33	138	34	-2458134035921313176	linear_model.Ridge(alpha = 3)	138	6	138	35	-1232898138450661004
3	138	55	138	56	-3696315517065331804	draw_3d(rat.p2a_prob, rat.a2p_prob, trial_window = 3)	138	4	138	57	-1550250394459988154
3	140	27	140	28	-7123959483799903550	trianglegroup(4,p=3,q=3,r=4)	140	9	140	37	-1830910437260675342
3	140	31	140	32	-6141470976604111398	trianglegroup(4,p=3,q=3,r=4)	140	9	140	37	-1830910437260675342
3	140	52	140	53	-1110335683168135506	ax1.plot(sx2, sy2, c='k', linestyle='-.', linewidth=3)	140	0	140	54	-3377870991415646310
3	142	55	142	56	8947738412031562946	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	142	11	142	90	-1793788612138448715
3	142	68	142	69	-4956355726698824465	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	142	11	142	90	-1793788612138448715
3	143	30	143	31	269705277407194226	np.set_printoptions(precision=3, suppress=True)	143	0	143	47	6312405285691570193
3	143	37	143	38	9171647368693183960	np.sum(X_train/3, axis=3, keepdims=True)	143	14	143	54	-3023624473998413470
3	143	42	143	43	-5657365829473036405	plot(date_ful,zeros(grdlen),'k',linewidth=3)	143	0	143	44	-8636453593598998992
3	143	69	143	70	3674376247698286193	ax.plot(xs_g60, gamma.pdf(xs_g60, k_g60, loc_g60, theta_g60), lw=3, label="Prior")	143	4	143	86	3214921519855668733
3	144	36	144	37	-3459275142113741901	player_advanced_stats_15to16.head(n=3)	144	0	144	38	6977178436774683451
3	145	56	145	57	-7117085516091300559	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	145	12	145	91	-2673742940967535013
3	145	62	145	63	7175705931252525410	RandomForestRegressor(n_estimators=15, max_depth=3)	145	13	145	64	6159070962506976915
3	145	69	145	70	4940034345152749171	GradientBoostingRegressor(min_samples_split=3, max_depth=3, learning_rate=0.08)	145	12	145	91	-2673742940967535013
3	146	35	146	36	-4966271756356192001	np.sum(X_test/3, axis=3, keepdims=True)	146	13	146	52	7942780108579634593
3	146	75	146	76	1278528977399914542	cross_val_score(grid_search.best_estimator_, train_x, train_y, cv=3, scoring='accuracy')	146	9	146	97	6732034716872846483
3	149	14	149	15	1836316788630180177	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	146	16	151	1	-3537157781248254314
3	149	32	149	33	-6260111445870103857	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	149	12	149	63	7052083223217361581
3	149	43	149	44	-5052598066491341812	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	149	12	149	63	7052083223217361581
3	150	46	150	47	-1256470356716920979	ax1.tick_params('both', which='minor', length=3, width=0.5)	150	0	150	59	-3733162825780822236
3	151	32	151	33	715331797476699328	ax[1].contour(counts,linewidths=3,extent=[-150,90,-90,90],extend='both',colors='k',alpha=1)	151	0	151	91	3078215495223028583
3	153	71	153	72	-4576883154928684141	cross_val_score(grid_search.best_estimator_, val_x, val_y, cv=3, scoring='accuracy')	153	9	153	93	3654444981699590769
3	159	32	159	33	-5917976719491139060	np.mean(X_train, axis=3, keepdims=True, dtype=np.float32)	159	10	159	67	-3081534538551030441
3	160	32	160	33	-1074338133805562354	np.mean(X_valid, axis=3, keepdims=True, dtype=np.float32)	160	10	160	67	-6936682030172263046
3	161	31	161	32	-241516300060242988	np.mean(X_test, axis=3, keepdims=True, dtype=np.float32)	161	10	161	66	9081984789506616194
3	164	42	164	43	8690536071802581936	plot(date_ful,zeros(grdlen),'k',linewidth=3)	164	0	164	44	-825936259770833165
3	170	32	170	33	-3914062965842139371	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	170	12	170	63	1153729611129877623
3	170	43	170	44	3884067793579725952	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	170	12	170	63	1153729611129877623
3	170	64	170	65	-8734284329544620404	RandomForestRegressor(n_estimators=15, max_depth=3)	170	15	170	66	5911296475782386985
3	172	42	172	43	4411534956052373957	plot(date_ful,zeros(grdlen),'k',linewidth=3)	172	0	172	44	-7576207930349860983
3	173	61	173	62	577518243589252560	pl.plot(years, kc3[i], '-', color=colormap[i], linewidth=3)	173	4	173	63	6654615726934694833
3	181	55	181	56	7823779704343940669	draw_3d(rat.p2a_prob, rat.a2p_prob, trial_window = 3)	181	4	181	57	1359732111266681745
3	187	41	187	42	-669661745463445070	plt.plot(SA, CT, color='#000000', zorder=3)	187	0	187	43	-5200368883748658944
3	187	56	187	57	-7652816320427089307	json.dump( speeches_clean, speeches_jason, indent = 3 )	187	4	187	59	9090399335465152949
3	190	25	190	26	-6662365597353668510	plt.scatter(X, Y, zorder=3, c='r', s=60)	190	0	190	40	-4971426208755726634
3	191	14	191	15	310657345109546058	tree.DecisionTreeClassifier(\n    criterion='entropy',\n    max_features=2,\n    max_depth=3,\n#     random_state = 1337\n)	188	16	193	1	-6595224594010388118
3	191	32	191	33	7211547545296865610	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	191	12	191	63	-6587605405133526675
3	191	43	191	44	-8335514570808362026	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	191	12	191	63	-6587605405133526675
3	193	55	193	56	1889688547981566927	ecoreg.best_lasso(df, resp_var, exp_vars, kcv=3, cv_path=True, hists=False)	193	9	193	84	-7248164797032758861
3	194	42	194	43	-7447641086747498964	plot(date_ful,zeros(grdlen),'k',linewidth=3)	194	0	194	44	6580062256210011489
3	203	42	203	43	1836053062987806080	plot(date_ful,zeros(grdlen),'k',linewidth=3)	203	0	203	44	5993780901369351093
3	208	46	208	47	8195865653842990633	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=3)	208	0	208	48	-1965368415360285197
3	212	32	212	33	-5575164688373903883	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	212	12	212	63	-5002612333797824410
3	212	43	212	44	4849549193176538556	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	212	12	212	63	-5002612333797824410
3	217	42	217	43	-8639270206893404599	plt.hist(wiki['length'], 50, color='k', edgecolor='None', histtype='stepfilled', normed=True,\n         label='Entire Wikipedia', zorder=3, alpha=0.8)	216	0	217	55	-8453285163726728272
3	218	49	218	50	8646498265599551155	plot(xx, slope*xx + intercept, "k--", lw=3, alpha=0.5)	218	8	218	62	-3965359002856499980
3	220	41	220	42	4962933105158262545	plt.plot(CT, DT, color='#000000', zorder=3)	220	0	220	43	-4107066137714224384
3	221	61	221	62	-4483972535835965110	pl.plot(years, kc4[i], '.', color=colormap[i], linewidth=3)	221	4	221	63	8346578224766874305
3	233	32	233	33	198705804762621992	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	233	12	233	63	3863225378310105611
3	233	43	233	44	2704390925127210660	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	233	12	233	63	3863225378310105611
3	252	41	252	42	-5173100760965151705	plt.plot(SA, DS, color='#000000', zorder=3)	252	0	252	43	-5607868193658836282
3	254	32	254	33	3476908562405015397	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	254	12	254	63	-1641950046914429439
3	254	43	254	44	4126824622536330713	pl.subplots(nrows = 3, ncols = 3, figsize = (5, 5))	254	12	254	63	-1641950046914429439
3	255	25	255	26	6388515236504871624	TSNE(n_components=3)	255	7	255	27	-3405355518312768823
3	256	42	256	43	-1732439235709220470	plt.hist(wiki['length'], 50, color='k', edgecolor='None', histtype='stepfilled', normed=True,\n         label='Entire Wikipedia', zorder=3, alpha=0.8)	255	0	256	55	-745478583653947362
3	264	37	264	38	-462599190012756408	decomposition.PCA(n_components=3)	264	6	264	39	-5041151906758666821
3	269	39	269	40	-3100967694560987293	KNeighborsClassifier(n_neighbors=3)	269	6	269	41	2816308502992609726
3	269	61	269	62	40817294374460868	pl.plot(years, DB3[i], '-', color=colormap[i], linewidth=3)	269	4	269	63	-7420190841575837670
3	271	57	271	58	4630291635251010481	cross_val_score(lr, x_train, y_train, cv=3, scoring='roc_auc')	271	16	271	78	-2166944459022453177
3	276	36	276	37	2735301973450319217	P.rc('axes', labelsize='medium', lw=3, facecolor='None', edgecolor='k')	276	0	276	71	-4664920997447437966
3	281	40	281	41	6496865760203657860	plt.plot(O, DO, color='#000000', zorder=3)	281	0	281	42	-7101198223720433476
3	283	35	283	36	-7918183702940821587	GaussianMixture(n_components=3,\n                      covariance_type="spherical")	283	6	284	50	2280185296989219987
3	284	23	284	24	-2793337773193219447	MDS(n_components=3, dissimilarity="euclidean")	284	6	284	52	3112235962850799026
3	296	29	296	30	-5894784205594630978	np.sum(X/3, axis=3, keepdims=True)	296	12	296	46	255169715440213007
3	297	81	297	82	6773743770188478799	ax.plot(xs_g60, gamma.pdf(xs_g60, k_g60_top, loc_g60_top, theta_g60_top), lw=3, label="Prior")	297	4	297	98	5081839511145392284
3	298	23	298	24	4911888896132521077	PCA(n_components=3)	298	6	298	25	1251790910035249766
3	307	23	307	24	-2000241277980902850	PCA(n_components=3)	307	6	307	25	-1358991154438087054
3	312	73	312	74	-5154223182951706101	plt.plot(x, y, label = "Cluster 0 (using posterior-mean parameters)", lw=3 )	312	0	312	76	4445433518046425568
3	317	75	317	76	-8857898254758483035	plt.plot(x, y, label = "Cluster 1 (using posterior-mean parameters)", lw = 3 )	317	0	317	78	8480577335782631380
3	322	28	322	29	-1058799915117603563	plt.plot(t, mean_prob_t, lw=3, label="average posterior \nprobability of defect")	322	0	322	81	1370576703357372251
3	335	71	335	72	-7966372030547035192	data.rank(axis=0, pct=True).iloc[indices].round(decimals=3)	335	14	335	73	2856388513565245008
3	339	64	339	65	3327232771626473159	cross_val_score(lr_test, train_meta, y_train, cv=3,scoring='roc_auc')	339	15	339	84	-8964618451692063453
3	339	109	339	110	-3477220660042214701	ax1.hist(Xs, weights = xslastq/N.sum(xslastq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	339	0	339	111	5513276773333626657
3	340	89	340	90	-2934303079226423725	ax1.hist(Xs, weights = xsladtq/N.sum(xsladtq), bins=Xs, histtype='step', color='k', lw = 3)	340	0	340	91	-8901506040384035456
3	343	49	343	50	5941730758283971921	plot(xx, slope*xx + intercept, "k--", lw=3, alpha=0.5)	343	8	343	62	3522735719029771758
3	350	109	350	110	-7121764243776888731	ax2.hist(Xs, weights = xsmastq/N.sum(xsmastq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	350	0	350	111	4044705032901827907
3	351	89	351	90	2729256697601509564	ax2.hist(Xs, weights = xsmadtq/N.sum(xsmadtq), bins=Xs, histtype='step', color='k', lw = 3)	351	0	351	91	9043127241990357974
3	361	30	361	31	-2285004373165462755	plt.Circle((0,0), radius=3, fill=False)	361	5	361	44	4546249560232008259
3	362	36	362	37	-5274116053051342274	plt.plot( y_t, label= "$y_t$", lw = 3 )	362	0	362	39	-6423617521704506389
3	362	109	362	110	-3853195933795433002	ax3.hist(Xs, weights = xshastq/N.sum(xshastq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	362	0	362	111	931627567389849021
3	363	37	363	38	-3731060674851104552	plt.plot( x_t, label = "$x_t$", lw = 3 )	363	0	363	40	-6254652687930888767
3	363	89	363	90	-2065744386298360185	ax3.hist(Xs, weights = xshadtq/N.sum(xshadtq), bins=Xs, histtype='step', color='k', lw = 3)	363	0	363	91	723886746273853745
3	366	15	366	16	1799269572685662053	plt.legend(loc=3)	366	0	366	17	2268850470393791543
3	373	109	373	110	-6549210783330387729	ax4.hist(Xs, weights = xslistq/N.sum(xslistq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	373	0	373	111	4879914372550540390
3	374	89	374	90	-5183400492542917286	ax4.hist(Xs, weights = xslidtq/N.sum(xslidtq), bins=Xs, histtype='step', color='k', lw = 3)	374	0	374	91	-299982584142037462
3	375	40	375	41	-968496584802844633	ExtraTreesClassifier(n_estimators=3, criterion = 'entropy',max_depth = 4)	375	6	375	79	1526768990013221878
3	382	44	382	45	-1490585601611934269	plot_flux_total(pert_100,varlist ,row=2,col=3)	382	0	382	46	-3491051915224671264
3	382	75	382	76	-7770462407625322848	ax.plot(xs_shp, beta.pdf(xs_shp, a_shp, b_shp, loc_g60, scale_shp), lw=3, label="Prior")	382	4	382	92	6250051933871728476
3	384	109	384	110	-4223624197391678794	ax5.hist(Xs, weights = xsmistq/N.sum(xsmistq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	384	0	384	111	-6447100039423816486
3	385	89	385	90	-5417947114363708033	ax5.hist(Xs, weights = xsmidtq/N.sum(xsmidtq), bins=Xs, histtype='step', color='k', lw = 3)	385	0	385	91	-8608812077429321204
3	387	42	387	43	-3940656976928623979	np.mean(new_features, axis=3, keepdims=True, dtype=np.float32)	387	15	387	77	1319155623234239861
3	390	25	390	26	-8593911782956580494	PCA(n_components=3)	390	8	390	27	-2622383041226331945
3	394	109	394	110	796007361851611700	ax6.hist(Xs, weights = xshistq/N.sum(xshistq), bins=Xs, histtype='step', color='k', linestyle='dashed', lw = 3)	394	0	394	111	-8515192121885867832
3	395	89	395	90	-105351219910209927	ax6.hist(Xs, weights = xshidtq/N.sum(xshidtq), bins=Xs, histtype='step', color='k', lw = 3)	395	0	395	91	4738683171386564790
3	417	55	417	56	8010217337381045510	ax.plot(mergedData.x,mergedData.y,alpha=0.7, linewidth=3, solid_capstyle='round', zorder=2)	417	0	417	91	4953089933564221597
3	417	62	417	63	-585616280595900558	plot_flux_total_diff(pert_const,pert_bench,varlist ,row=2,col=3)	417	0	417	64	4581447171010729293
3	426	49	426	50	-5962413667867048075	plot(xx, slope*xx + intercept, "k--", lw=3, alpha=0.5)	426	8	426	62	2354312424851001766
3	430	33	430	34	-5911192344488652618	ax.plot(t, t, color = 'blue', lw=3)	430	0	430	35	5524725921820467309
3	431	39	431	40	-6424168695061104045	anova_lm(ols('np.log(Days+1) ~ C(Duration, Sum) * C(Weight, Poly)',\n                   data=kt).fit(), typ=3)	430	6	431	41	5726393365699227299
3	436	28	436	29	-6293069119214451442	KMeans(n_clusters=3)	436	10	436	30	-3581958877315032951
3	444	26	444	27	1673037142384695937	np.mean(images, axis=3)	444	5	444	28	-2930466791329489859
3	445	42	445	43	867569341333191971	plt.subplots(ncols=3, sharey=False, figsize=(16, 8))	445	23	445	75	-3159098735006570655
3	457	45	457	46	-8048159922852174981	plt.subplot2grid((3,3), (0,0), colspan=3)	457	6	457	47	6961495604233690196
3	458	42	458	43	8524796577662016230	plt.subplots(ncols=3, sharey=False, figsize=(16, 8))	458	23	458	75	-3622282003149751556
3	468	111	468	112	-5908143354014381860	ax1.hist(Ys, weights = yslastau/N.sum(yslastau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 3)	468	0	468	113	7440148239868837061
3	469	91	469	92	-6801292936849774431	ax1.hist(Ys, weights = ysladtau/N.sum(ysladtau), bins=Ys, histtype='step', color='k', lw = 3)	469	0	469	93	7156251319914728482
3	479	111	479	112	7089839917873099211	ax2.hist(Ys, weights = ysmastau/N.sum(ysmastau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 3)	479	0	479	113	7909537244871184425
3	480	91	480	92	-5037540886773466197	ax2.hist(Ys, weights = ysmadtau/N.sum(ysmadtau), bins=Ys, histtype='step', color='k', lw = 3)	480	0	480	93	2940931953843333993
3	492	91	492	92	-6594191295182249398	ax3.hist(Ys, weights = yshadtau/N.sum(yshadtau), bins=Ys, histtype='step', color='k', lw = 3)	492	0	492	93	-6329562155803069405
3	502	111	502	112	3162303632569113042	ax4.hist(Ys, weights = yslistau/N.sum(yslistau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 3)	502	0	502	113	-4210952463472500981
3	503	91	503	92	2409806542235221780	ax4.hist(Ys, weights = yslidtau/N.sum(yslidtau), bins=Ys, histtype='step', color='k', lw = 3)	503	0	503	93	6118574503702252715
3	507	91	507	92	-1402829808822349330	ax.plot(xs_shp, beta.pdf(xs_shp, a_shp_top, b_shp_top, loc_g60_top, scale_shp_top), lw=3, label="Prior")	507	4	507	108	-8425863295904818913
3	512	111	512	112	1094866463288497754	ax5.hist(Ys, weights = ysmistau/N.sum(ysmistau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 3)	512	0	512	113	4945744627932357874
3	513	91	513	92	-579355035807653757	ax5.hist(Ys, weights = ysmidtau/N.sum(ysmidtau), bins=Ys, histtype='step', color='k', lw = 3)	513	0	513	93	-6297049121123859828
3	519	55	519	56	-7749044686503732766	ax.plot(mergedData.x,mergedData.y,alpha=0.7, linewidth=3, solid_capstyle='round', zorder=2)	519	0	519	91	-503506319487502600
3	522	111	522	112	6335116190615024892	ax6.hist(Ys, weights = yshistau/N.sum(yshistau), bins=Ys, histtype='step', color='k', linestyle='dashed', lw = 3)	522	0	522	113	6953221493763378205
3	523	91	523	92	-8396878065054639909	ax6.hist(Ys, weights = yshidtau/N.sum(yshidtau), bins=Ys, histtype='step', color='k', lw = 3)	523	0	523	93	-6891819018908793674
3	549	108	549	109	-5186474589789556458	get_mds(bike_df_Nouns_Adj,sample_size=Nouns_Adj_sample_size, nouns_only=False, ngram=3)	549	23	549	110	-55382878726402626
3	558	61	558	62	2346051002560801299	np.nansum(datam[:,:,:,:],axis=3)	558	31	558	63	4890124989520281402
3	590	71	590	72	3481919321810635474	interpolate.approximate_taylor_polynomial(f, x=1, degree=3, scale=0.01)	590	14	590	85	399747812610286652
3	594	57	594	58	-5362199058718420418	np.nansum(datam[:,:,:,:],axis=3)	594	27	594	59	2248074887814746798
3	648	61	648	62	-6426140921611811823	np.nansum(datam[:,:,:,:],axis=3)	648	31	648	63	4684767556687903345
3	651	42	651	43	-272518564604110161	np.sum(my_images/3, axis=3, keepdims=True)	651	17	651	59	-5618253379351457854
3	664	49	664	50	3226520455508487292	plt.legend(bbox_to_anchor=(1.05, 1), loc=3, borderaxespad=0.)	664	8	664	69	-635961333122017222
3	686	38	686	39	3099213902628481813	tf.nn.top_k(softmax_logits, k=3)	686	8	686	40	773666710300166247
3	686	57	686	58	-3739436022202050369	np.nansum(datam[:,:,:,:],axis=3)	686	27	686	59	-4889502632852580234
3	687	108	687	109	6139740552052115177	df_N_topic_analysis.theft_desc_nouns.apply(get_doc_topic, lda_model_in =lda_model_nouns_dict, num_clust=3)	687	4	687	110	2526926588880660235
3	707	70	707	71	5320542170241855064	RandomForestClassifier(n_estimators= 500, n_jobs=-1,random_state=3)	707	5	707	72	-6349249037887375716
3	723	67	723	68	-5765705493860287360	np.nansum((1-data/34.8)*maskcalc ,axis=3)	723	28	723	69	6300671169578393126
3	724	57	724	58	-730873979932399942	np.nansum(datam[:,:,:,:],axis=3)	724	27	724	59	3910141035389278673
3	745	49	745	50	6123543669145829516	plt.legend(bbox_to_anchor=(1.05, 1), loc=3, borderaxespad=0.)	745	8	745	69	2139683559436138444
3	773	46	773	47	2592443477734963083	np.sum(new_images/3, axis = 3, keepdims = True)	773	18	773	65	-4494758527634414025
3	775	24	775	25	8107459030813178441	PCA(n_components=3)	775	7	775	26	-4797446614941976263
3	802	40	802	41	1328708401882325381	tf.nn.top_k(softmax_logits, k = 3)	802	8	802	42	-5269259039232271034
3	980	24	980	25	8584583090274164089	PCA(n_components=3)	980	7	980	26	5399438905797055491
3	1038	91	1038	92	8948853508403496087	cross_val_score(LogisticRegression(C=10), other_tfid, clusters_nmf_o, cv=3, scoring='f1_macro')	1038	18	1038	113	1167701211970774343
3	1041	91	1041	92	-1770929338894892311	cross_val_score(LogisticRegression(C=10), other_tfid, clusters_kmn_o, cv=3, scoring='f1_macro')	1041	18	1041	113	-8750575486575672439
3	1044	91	1044	92	-690278744526535612	cross_val_score(LogisticRegression(C=10), other_tfid, clusters_lda_o, cv=3, scoring='f1_macro')	1044	18	1044	113	-2951870736198932096
3	1085	42	1085	43	1297612520620509567	plt.bar(bin_edges[:-1], hist, width = 3)	1085	4	1085	44	-3094210155737195457
3	1086	57	1086	58	3854920498267692513	np.nansum(datam[:,:,:,:],axis=3)	1086	27	1086	59	6702142518346910610
3	1122	57	1122	58	-5723310971037836129	np.nansum(datam[:,:,:,:],axis=3)	1122	27	1122	59	367941265994543069
3	1229	50	1229	51	638042567304026828	plot_flux_in_out(pert,varlist,'FluxSum',row=2,col=3)	1229	0	1229	52	2057609927927599845
3	1266	39	1266	40	-434471641163158469	plot_flux_total(pert,varlist,row=2,col=3)	1266	0	1266	41	6804114166335491736
3	1797	35	1797	36	-8425841735981600610	plt.subplots(ncols=3,nrows=4,sharex=True)	1797	16	1797	57	-2631877016661537494
3	1846	45	1846	46	-3085253044543098047	plt.legend(bbox_to_anchor=(1.05, 1), loc=3, borderaxespad=0.)	1846	4	1846	65	6303815265252018783
3	1846	191	1846	192	-1836114530242308845	plt.plot(xvaluesforplot, resfit(xvaluesforplot, linresfitparams[0], linresfitparams[1]),\n         label=('Fit to linear CES energy resolution with $\\chi^2/ndf = %3.1f$' % chisquare(resfit, linresfitparams, linmean, linresolution, linresolutionerr)[0]), color='indigo', linewidth=3, linestyle="-")	1845	0	1846	208	6388652232448177731
3	1848	195	1848	196	-5070775124939733027	plt.plot(xvaluesforplot, resfit(xvaluesforplot, csresfitparams[0], csresfitparams[1]),\n         label=('Fit to single line CES energy resolution with $\\chi^2/ndf = %3.1f$' % chisquare(resfit, csresfitparams, csmean, csresolution, csresolutionerr)[0]), color='royalblue', linewidth=3, linestyle="-")	1847	0	1848	212	-8182614302726641736
3	1850	199	1850	200	-736650845872209523	plt.plot(xvaluesforplot, resfit(xvaluesforplot, parresfitparams[0], parresfitparams[1]),\n         label=('Fit to parametrized CES energy resolution with $\\chi^2/ndf = %3.1f$' % chisquare(resfit, parresfitparams, parmean, parresolution, parresolutionerr)[0]), color='seagreen', linewidth=3, linestyle="-")	1849	0	1850	216	-7948310323818941528
7	136	49	136	50	5115607199707035472	VideoClip(make_frame, duration = 7)	136	16	136	51	-3627533316273046422
7	249	24	249	25	-3358198700550777152	ax.scatter(y, x, c=z, s=7, edgecolor='')	249	0	249	40	-3658365520355863907
7	290	52	290	53	4789787152272905970	plt.text(angle_rad, 1.05, features[i], size=7, horizontalalignment=ha, verticalalignment="center")	290	8	290	106	-8969382421951164306
7	337	49	337	50	-768835910215490615	Tk.Label(c, text="C:", anchor="e", width=7)	337	8	337	51	-2470061921385612239
7	345	53	345	54	-1059546677892337421	Tk.Label(g, text="gamma:", anchor="e", width=7)	345	8	345	55	6807372750386170391
7	352	54	352	55	317012228294457850	Tk.Label(d, text="degree:", anchor="e", width=7)	352	8	352	56	6625184193775142640
7	359	53	359	54	-2368753633040451837	Tk.Label(r, text="coef0:", anchor="e", width=7)	359	8	359	55	8207057381540928593
4	22	30	22	31	1297280634393372240	np.set_printoptions(precision=4,suppress=True)	22	0	22	46	4574626832265527203
4	22	81	22	82	-7501821980380080268	plt.plot(rate1, rate2, label=curve_name + ' (area = %0.2f)' % AUC, linewidth=4)	22	4	22	83	-1817881279299039680
4	23	46	23	47	9062268619275318629	plt.plot([0, 1], [0, 1], 'k--', linewidth=4)	23	4	23	48	-3669602754054376755
4	38	30	38	31	622449747244818359	np.set_printoptions(precision=4,suppress=True)	38	0	38	46	-877688828025374414
4	45	80	45	81	-2658933207740319513	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	45	52	45	112	-403443544484575185
4	46	80	46	81	-425165915004952209	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	46	52	46	112	-3747151126198113622
4	47	85	47	86	-1995223575648910496	tagger.tag(openfood_sf, query_name='product_features', k=4)	47	28	47	87	511095187347888932
4	49	30	49	31	8848976458582317017	dict(opacity=1.0, weight=4)	49	5	49	32	3676639274884633304
4	62	79	62	80	-247171365167741631	cascade.detectMultiScale(img, scaleFactor=1.01, minNeighbors = 4, minSize= (40, 40))	62	16	62	100	1565595229220393248
4	66	101	66	102	5834261858427221077	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
4	67	154	67	155	4554228724260841756	plt.plot(target[:,0], kde002.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.02',zorder=4)	67	33	67	156	-144954444229109048
4	69	223	69	224	-4971054023696534271	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde002_train.score_samples(target[:,0:1])),facecolor='blue',label='KDE on train, W=0.02',alpha=0.5,zorder=4)	69	33	69	225	-4875181575337343573
4	70	25	70	26	-316352829783022411	plt.plot(x, y, 'b--', lw=4)	70	0	70	27	7188393466751621290
4	70	220	70	221	-6027412322797646571	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde002_test.score_samples(target[:,0:1])),facecolor='red',label='KDE on test, W=0.02',alpha=0.5,zorder=4)	70	33	70	222	149008081998688921
4	71	154	71	155	-2340231690900027820	plt.plot(target[:,0], kde005.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.05',zorder=4)	71	33	71	156	1772569573835634527
4	72	133	72	134	4868764230445654204	CountVectorizer(encoding='latin1', stop_words=['and', 'or', 'before', 'a', 'an', 'am', 'the', 'at', 'by', 'br'], min_df=4)	72	13	72	135	-7121589926318528431
4	73	223	73	224	4551716681441080706	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde005_train.score_samples(target[:,0:1])),facecolor='blue',label='KDE on train, W=0.05',alpha=0.5,zorder=4)	73	33	73	225	5091970097761558210
4	74	220	74	221	5290472007617487001	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde005_test.score_samples(target[:,0:1])),facecolor='red',label='KDE on test, W=0.05',alpha=0.5,zorder=4)	74	33	74	222	5186419994894910034
4	75	151	75	152	1957570801738176142	plt.plot(target[:,0], kde01.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.1',zorder=4)	75	32	75	153	1766649901380758584
4	76	71	76	72	4461893771540603498	plt.plot(splits, np.array(acc_T).mean(axis=0), label='Test', c='r', lw=4)	76	0	76	73	8678966730661673415
4	77	72	77	73	-5063793793711338810	plt.plot(splits, np.array(acc_V).mean(axis=0), label='Train', c='b', lw=4)	77	0	77	74	-486715202820181490
4	77	220	77	221	7788009734351739358	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde01_train.score_samples(target[:,0:1])),facecolor='blue',label='KDE on train, W=0.1',alpha=0.5,zorder=4)	77	32	77	222	-1386163831221946783
4	78	217	78	218	6919712721415252781	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde01_test.score_samples(target[:,0:1])),facecolor='red',label='KDE on test, W=0.1',alpha=0.5,zorder=4)	78	32	78	219	3951833676216383865
4	79	151	79	152	-7921726563206339759	plt.plot(target[:,0], kde02.predict(target[:,0:1]), color='green',lw=3,label='KDE-ratio-weighted linear, W=0.2',zorder=4)	79	32	79	153	-7279543275457017682
4	81	17	81	18	1507353545121277400	plota.legend(loc=4)	81	0	81	19	8635190549921114802
4	81	220	81	221	-3058675500743490087	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde02_train.score_samples(target[:,0:1])),facecolor='blue',label='KDE on train, W=0.2',alpha=0.5,zorder=4)	81	32	81	222	-4099023523071612539
4	82	217	82	218	1363690321231799313	plt.fill_between(target[:,0],np.repeat(-0.25,np.shape(target)[0]),-0.25+0.15*np.exp(kde02_test.score_samples(target[:,0:1])),facecolor='red',label='KDE on test, W=0.2',alpha=0.5,zorder=4)	82	32	82	219	3497548572029046723
4	83	143	83	144	-2526640235814571340	plt.plot(target[:,0], kmm1.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=1',zorder=4)	83	32	83	145	-1646188557944180816
4	84	81	84	82	6828767354471873281	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	84	53	84	113	8553067472601386944
4	85	81	85	82	7194079927327564402	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	85	53	85	113	1242869415776402056
4	85	143	85	144	5681532210826564375	plt.plot(target[:,0], kmm2.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=2',zorder=4)	85	32	85	145	-3370060523980937033
4	87	80	87	81	3931843973005631236	DecisionTreeClassifier(criterion = 'entropy',max_depth=4)	87	25	87	82	-3319537474756045725
4	87	112	87	113	-5972908264277559668	AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy',max_depth=4),n_estimators=1,learning_rate=4)	87	6	87	114	-5161303527293773844
4	87	143	87	144	-5673628209521767645	plt.plot(target[:,0], kmm5.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=5',zorder=4)	87	32	87	145	4181261568880518420
4	89	57	89	58	-2841838091769309329	np.random.uniform(low=10.0, high=1000.0, size=4)	89	11	89	59	-4600129929858901062
4	89	145	89	146	2736125540389484197	plt.plot(target[:,0], kmm10.predict(target[:,0:1]), color='orange',lw=3,label='KMM-weighted linear, B=10',zorder=4)	89	32	89	147	-6868132458697930110
4	91	145	91	146	2523334802757858205	plt.plot(target[:,0], kmm2q.predict(target[:,0:1]), color='cyan',lw=3,label='KMM-weighted quadratic, B=2',zorder=4)	91	32	91	147	1868897371205960727
4	92	37	92	38	2927035340732871754	plt.plot(k, accuracy_list, linewidth=4)	92	0	92	39	-5846370973363760158
4	98	98	98	99	1539426051341181376	plt.plot(pressure/1.e9,vs/1.e3,color='b',linestyle='-',marker='o', markerfacecolor='b',markersize=4,label='computation')	98	0	98	120	-4469593124110304323
4	99	103	99	104	-7057475281767213039	plt.plot(pressure/1.e9,seis_vs/1.e3,color='k',linestyle='-',marker='o', markerfacecolor='k',markersize=4,label='reference')	99	0	99	123	-2976631682708528952
4	108	53	108	54	5339060090906780030	make_blobs(n_samples=1000, n_features=2, centers=4)	108	4	108	55	-5635320266443073427
4	108	69	108	70	-2187513216114551186	plt.plot(k_Nb, np.array(acc_T).mean(axis=0), label='Test', c='r', lw=4)	108	0	108	71	4276302840771646692
4	109	70	109	71	2147491195228626850	plt.plot(k_Nb, np.array(acc_V).mean(axis=0), label='Train', c='b', lw=4)	109	0	109	72	-6596910433964498322
4	109	97	109	98	1712181622259627124	plt.plot(pressure/1.e9,vp/1.e3,color='b',linestyle='-',marker='o',markerfacecolor='b',markersize=4)	109	0	109	99	5950106896190775351
4	110	102	110	103	6580173162877446769	plt.plot(pressure/1.e9,seis_vp/1.e3,color='k',linestyle='-',marker='o',markerfacecolor='k',markersize=4)	110	0	110	104	8372135656964054391
4	118	103	118	104	2741217326368397289	plt.plot(pressure/1.e9,density/1.e3,color='b',linestyle='-',marker='o', markerfacecolor='b',markersize=4)	118	0	118	105	3327558604290174201
4	119	104	119	105	1155746365660227684	plt.plot(pressure/1.e9,seis_rho/1.e3,color='k',linestyle='-',marker='o', markerfacecolor='k',markersize=4)	119	0	119	106	1854136117877220181
4	121	53	121	54	-8104553901137188827	plt.legend(bbox_to_anchor=(-5, 6, 3.5, 1.5),ncol=4, mode="expand", borderaxespad=0.)	121	4	121	88	-2373022517841298875
4	123	81	123	82	1347162722372152853	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	123	53	123	113	2358917832902972433
4	124	81	124	82	-7661380960162082074	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	124	53	124	113	-3955764760833604143
4	135	36	135	37	-6052994978863900757	KernelPCA(n_components=4, degree=2, gamma=.000001, coef0=120)	135	13	135	74	-2535834234939777556
4	137	64	137	65	-7346283966101748363	cv2.connectedComponentsWithStats(~edge, connectivity = 4)	137	9	137	66	2985725355316647609
4	140	35	140	36	-5147015236820368190	trianglegroup(4,p=3,q=3,r=4)	140	9	140	37	-1830910437260675342
4	141	38	141	39	5734541393149187281	processor(vtpredict, model, nprocessor=1, timeslice='auto', vis_slices=31,\n                         oversampling=4, facets=8, wstep=advice['w_sampling_primary_beam'])	140	15	141	91	8017141038555901416
4	144	24	144	25	6802459859458344409	ax.xaxis.grid(linewidth=4)	144	0	144	26	1205228243945239735
4	151	21	151	22	2252278495334202046	plota.legend(loc=4)	151	4	151	23	7968561637657315992
4	151	53	151	54	-1088164159482664717	plt.legend(bbox_to_anchor=(-5, 6, 3.5, 1.5),ncol=4, mode="expand", borderaxespad=0.)	151	4	151	88	6781133173526459696
4	153	38	153	39	-6097638700355845473	json.dump(lump_counts, fp, indent=4)	153	4	153	40	6999711816211232399
4	156	15	156	16	2692219141298917201	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
4	159	40	159	41	-4991036637483340432	sns.diverging_palette(260, 20, n=4)	159	7	159	42	8743693172664272305
4	162	81	162	82	8268792981542049009	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	162	53	162	113	-8908195277355693520
4	163	81	163	82	-453856964888818452	plt.subplots(nrows=2, ncols=4, sharey=True, figsize=(16, 8))	163	53	163	113	4686635607745070422
4	163	84	163	85	3730340121354592374	processor(vt, targetimage, timeslice='auto', padding=2, oversampling=4,\n                         facets=4, wstack=advice['w_sampling_primary_beam'], vis_slices=31,\n                         wstep=advice['w_sampling_primary_beam'])	163	15	165	65	618035739375703242
4	164	32	164	33	5860390847125014059	processor(vt, targetimage, timeslice='auto', padding=2, oversampling=4,\n                         facets=4, wstack=advice['w_sampling_primary_beam'], vis_slices=31,\n                         wstep=advice['w_sampling_primary_beam'])	163	15	165	65	618035739375703242
4	165	15	165	16	-6006266493049041753	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
4	167	64	167	65	2644437937408826603	sns.lmplot(x = 'r_seed', y = 'r_1adjrpi',  hue='result', size = 4, data = season_f, palette = 'Set2')	167	0	167	101	7303046639293241966
4	169	25	169	26	-5789819174196105126	P.rc('lines', markersize=4, linewidth=1, markeredgewidth=0.2)	169	0	169	61	8891696031833531130
4	172	66	172	67	5873405148093310780	sns.lmplot(x = 'r_ascore', y = 'r_agscore',  hue='result', size = 4, data = season_f, palette = 'Set2')	172	0	172	103	1058789307296907667
4	177	30	177	31	1883021779003481556	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=['o', 'o']),\n           size = 8, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	176	4	177	83	4015445777837850583
4	180	48	180	49	-5610959878995927207	plt.plot(sa, ct, color=polarity, zorder=4)	180	8	180	50	-3826894694374647858
4	182	48	182	49	2496188992895219734	plt.plot(sa, ct, color=polarity, zorder=4)	182	8	182	50	-5784081886815790624
4	185	23	185	24	1578460685432508696	KMeans(n_clusters=4, n_init=100)	185	5	185	37	6104743429927288181
4	186	26	186	27	2856497345451236908	plt.legend(loc = 4)	186	9	186	28	-5422662338354045909
4	189	15	189	16	-5095189803726729691	plt.legend(loc=4, frameon=False, title='Legend')	189	0	189	48	-3490943320266401757
4	192	100	192	101	5514525220019285485	timedelta(hours=4)	192	84	192	102	-2078840806957045910
4	193	24	193	25	4020194803399210851	ax.xaxis.grid(linewidth=4)	193	0	193	26	5766057546452982679
4	195	82	195	83	409725029546080016	plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)	195	0	195	84	2480201862431312080
4	196	42	196	43	2101710106822279746	plt.plot([0, 1], [0, 1], 'k--', linewidth=4)	196	0	196	44	-4369275712814713234
4	205	30	205	31	-4817254010420829308	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=["o", 'o']),\n           size = 8, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	204	4	205	83	-2212431255073768163
4	210	46	210	47	7735949852573300244	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=4)	210	0	210	48	6513579083717035187
4	213	47	213	48	-3902830873290619870	plt.plot(ct, d, color=polarity, zorder=4)	213	8	213	49	1296397481839648615
4	215	47	215	48	37243952679491350	plt.plot(ct, d, color=polarity, zorder=4)	215	8	215	49	-2314780459514558051
4	220	102	220	103	-1908783358098314864	plt.axvline(x=wiki['length'][wiki['name'] == 'Barack Obama'][0], color='k', linestyle='--', linewidth=4,\n           label='Length of Barack Obama', zorder=2)	220	0	221	52	-3909111957945218711
4	222	99	222	100	-1720441837305375451	plt.axvline(x=wiki['length'][wiki['name'] == 'Joe Biden'][0], color='g', linestyle='--', linewidth=4,\n           label='Length of Joe Biden', zorder=1)	222	0	223	49	2222904614420149584
4	232	15	232	16	7825647312572420488	plt.legend(loc=4, framealpha=0.3, fontsize=10)	232	0	232	46	-6219394705429567535
4	238	46	238	47	-2749849424961645511	json.dumps(comp_final, indent=4)	238	16	238	48	5150746363760374231
4	239	36	239	37	-3421304643588759329	loglog(2**bins, var_rat1, 'b-o', lw=4, ms=8, label="F469N / F547M")	239	0	239	67	-7540245251168728170
4	240	36	240	37	2556466856126123939	loglog(2**bins, var_rat2, 'g-o', lw=4, ms=8, label="FQ575N / F547M")	240	0	240	68	8296523403322069540
4	241	46	241	47	494906002606611400	loglog(2**bins, np.array(var_rat3), 'r-o', lw=4, ms=8, label="FQ575N' / FQ575N")	241	0	241	80	-5534447510283819778
4	242	62	242	63	6074114497395998326	loglog(2**bins, var_rat2 - 0.5*np.array(var_rat3), 'g--o', lw=4, ms=8, label="Noise-subtracted")	242	0	242	96	3544779426463737851
4	243	74	243	75	-5133324234908762220	loglog(2**bins, var_rat1 - 0.542*(20./18.)*np.array(var_rat3), 'b--o', lw=4, ms=8, label="Noise-subtracted")	243	0	243	108	-1022494361570411340
4	245	47	245	48	1147421916362323338	plt.plot(sa, d, color=polarity, zorder=4)	245	8	245	49	-3001355766701782545
4	247	47	247	48	-4010264848416653463	plt.plot(sa, d, color=polarity, zorder=4)	247	8	247	49	-2292508065914439259
4	251	24	251	25	-6264387553380142298	ax.xaxis.grid(linewidth=4)	251	0	251	26	7088299185702015421
4	259	31	259	32	5963327434013257746	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=["o", '+']),\n           size = 12, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	258	4	259	84	8458077030235441750
4	261	102	261	103	7155061779200584870	plt.axvline(x=wiki['length'][wiki['name'] == 'Barack Obama'][0], color='k', linestyle='--', linewidth=4,\n           label='Length of Barack Obama', zorder=2)	261	0	262	52	-1815223556735027941
4	263	99	263	100	-7724965803725490847	plt.axvline(x=wiki['length'][wiki['name'] == 'Joe Biden'][0], color='g', linestyle='--', linewidth=4,\n           label='Length of Joe Biden', zorder=1)	263	0	264	49	6364673904392404084
4	274	46	274	47	-7487856385834285231	plt.plot(o, d, color=polarity, zorder=4)	274	8	274	48	-3260704855307044214
4	276	46	276	47	-2398032916839899818	plt.plot(o, d, color=polarity, zorder=4)	276	8	276	48	-7177977978864718721
4	277	24	277	25	4011260910070878436	ax.xaxis.grid(linewidth=4)	277	0	277	26	1719313294938274437
4	287	65	287	66	-3598317506227109141	s.light_curve(timeLC, texp=tKep, tol=1e-08, maxdepth=4)	287	12	287	67	4047015788807936403
4	288	24	288	25	-1901989535390617010	ax.xaxis.grid(linewidth=4)	288	0	288	26	-7919815295134319238
4	297	70	297	71	-2836764306087429062	ax.plot(x, x+14, color="purple", lw=1, ls='-', marker='o', markersize=4)	297	0	297	72	-4549189668428020519
4	298	65	298	66	5143011946602068128	sns.lmplot(x = 'r_adjoe', y = 'r_1adjrpi',  hue='result', size = 4, data = x1)	298	0	298	78	-1105776869378378836
4	299	24	299	25	-5867012502998434426	ax.xaxis.grid(linewidth=4)	299	0	299	26	-7954253396688471166
4	310	24	310	25	3102692328820934302	ax.xaxis.grid(linewidth=4)	310	0	310	26	2468271525100222840
4	311	91	311	92	-3327872868659322743	ax2.legend(('$a_0$','$a_0$ w/o plasma','$n_e$',),fontsize=16,fancybox=True,shadow=True,loc=4)	311	0	311	93	-6389299561856119965
4	352	70	352	71	-4821851508175236107	s.light_curve(t_theory, texp=tKep, tol=1e-08, maxdepth=4)	352	15	352	72	6920140943748951495
4	363	15	363	16	-4050324620717865889	plt.legend(loc=4, framealpha=0.3, fontsize=10)	363	0	363	46	5875386820789535258
4	363	36	363	37	6407737076686928875	loglog(2**bins, var_rat1, 'b-o', lw=4, ms=8, label="F487N / F547M")	363	0	363	67	7290680850656380248
4	364	36	364	37	-6933015409044360444	loglog(2**bins, var_rat2, 'g-o', lw=4, ms=8, label="FQ575N / F547M")	364	0	364	68	7582873215992508395
4	365	46	365	47	-1800428420094308808	loglog(2**bins, np.array(var_rat3), 'r-o', lw=4, ms=8, label="FQ575N' / FQ575N")	365	0	365	80	4538333058581162755
4	366	64	366	65	-8969728314641883286	loglog(2**bins, var_rat2 - 0.542*np.array(var_rat3), 'g--o', lw=4, ms=8, label="Noise-subtracted")	366	0	366	98	-7715590813676572399
4	367	66	367	67	2291433390875358759	loglog(2**bins, var_rat1 - (0.5/8)*np.array(var_rat3), 'b--o', lw=4, ms=8, label="Noise-subtracted")	367	0	367	100	-7948134963923945720
4	375	77	375	78	8319056360150117856	ExtraTreesClassifier(n_estimators=3, criterion = 'entropy',max_depth = 4)	375	6	375	79	1526768990013221878
4	379	53	379	54	-558853888566206273	plt.legend(bbox_to_anchor=(-5, 6, 3.5, 1.5),ncol=4, mode="expand", borderaxespad=0.)	379	4	379	88	3628006365627935369
4	383	14	383	15	-3613011479242430701	ax.legend(loc=4, frameon=False)	383	0	383	31	427135270493267508
4	394	80	394	81	1368373608525726356	DecisionTreeClassifier(criterion = 'entropy',max_depth=4)	394	25	394	82	9093871777875429413
4	394	112	394	113	1977829839730247364	AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy',max_depth=4),n_estimators=1,learning_rate=4)	394	6	394	114	5316529189215550691
4	414	53	414	54	4228516626501586115	plt.legend(bbox_to_anchor=(-5, 6, 3.5, 1.5),ncol=4, mode="expand", borderaxespad=0.)	414	4	414	88	-5165087574249455816
4	420	45	420	46	-774807480981717515	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'mlog10val', fit_reg=False, hue = 'plinkLG', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	419	4	420	90	5651046864926794521
4	423	14	423	15	-5997376513600853519	ax.legend(loc=4, frameon=False)	423	0	423	31	2978597761053153102
4	428	45	428	46	8830001952313036257	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'FST', fit_reg=False, hue = 'plinkLG', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	427	4	428	90	-3366008978527894879
4	434	23	434	24	-1768077330775485101	plt.setp(zc, linewidth=4)	434	0	434	25	3272230508743784761
4	436	45	436	46	-8292487950671475520	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'mlog10val', fit_reg=False, hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	435	4	436	90	8259840265607257131
4	476	40	476	41	-1359662657233190141	sns.diverging_palette(260, 20, n=4)	476	7	476	42	-827157442682215426
4	519	53	519	54	-1220460323926585306	plt.legend(bbox_to_anchor=(-5, 6, 3.5, 1.5),ncol=4, mode="expand", borderaxespad=0.)	519	4	519	88	-3049158137513209784
4	528	36	528	37	-4402195977279740846	plt.contour(x,y,V,levels,linewidths=4,cmap=cm.coolwarm)	528	0	528	55	6790083566067106396
4	557	37	557	38	4263816349937003360	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, linewidth=0)	557	4	557	63	-3944673553284533801
4	557	48	557	49	3770649491387949920	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, linewidth=0)	557	4	557	63	-3944673553284533801
4	562	37	562	38	4432474811552205883	pprint.PrettyPrinter(indent=4)	562	9	562	39	-7782548023138898888
4	573	39	573	40	-3869271323774618619	ax.plot_wireframe(X, Y, Z, rstride=4, cstride=4)	573	4	573	52	-3782633922863776009
4	573	50	573	51	7756520558434355995	ax.plot_wireframe(X, Y, Z, rstride=4, cstride=4)	573	4	573	52	-3782633922863776009
4	577	37	577	38	7200736964281705517	pprint.PrettyPrinter(indent=4)	577	9	577	39	1302948858514242302
4	583	33	583	34	603175264125776075	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha=0.25)	583	0	583	58	8335065080296670118
4	583	44	583	45	6533804061739977559	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha=0.25)	583	0	583	58	8335065080296670118
4	591	71	591	72	5929865015158442785	interpolate.approximate_taylor_polynomial(f, x=1, degree=4, scale=0.01)	591	14	591	85	3009300424948878630
4	604	33	604	34	-5740909374291170009	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha = 0.25)	604	0	604	60	7838352424008196169
4	604	44	604	45	5613911300213536738	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha = 0.25)	604	0	604	60	7838352424008196169
4	608	33	608	34	-3079384325912623014	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha=0.25)	608	0	608	58	141874269594240411
4	608	44	608	45	2297284050766066033	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, alpha=0.25)	608	0	608	58	141874269594240411
4	682	63	682	64	6220838693437669601	set_avg_params(['model_1_best.pkl'], model_base_2, layer_start=4)	682	0	682	65	3042618541960056334
4	714	162	714	163	-6439516354543716808	ax.annotate('{},{}'.format(hash_dict_inv[id1],idx2 ), (np.log(v['ts'][idx2][0]/v['ts'][idx2][1]), np.log(v['std'][idx2][0]/ v['std'][idx2][1])), fontsize=4)	714	8	714	164	-3500524962056145742
4	783	68	783	69	1488907093673807817	set_avg_params(['model_base_2_best.pkl'], model_base_2, layer_start=4)	783	0	783	70	-3407962605266912689
4	838	68	838	69	5078232009830168466	set_avg_params(['model_base_2_best.pkl'], model_base_2, layer_start=4)	838	0	838	70	-4149358201432442806
4	986	24	986	25	-4563070277245538374	KMeans(n_clusters=4)	986	6	986	26	-1142066865913007823
4	989	23	989	24	-2990371402974794326	NMF(n_components=4)	989	6	989	25	-8795711481095602687
4	993	43	993	44	-5892241541451557910	LatentDirichletAllocation(n_topics = 4, learning_method='batch')	993	6	993	70	1743131887092505152
4	1000	70	1000	71	7348803313430000274	sns.lmplot(x = 'r_seed', y = 'r_1adjrpi',  hue='\ufeffResult', size = 4, data = stat)	1000	0	1000	85	-4434830129803230630
4	1173	65	1173	66	2611880208912956145	set_avg_params(['model_1_best.pkl'], model_merged_1, layer_start=4)	1173	0	1173	67	-3013369052491399709
4	1301	72	1301	73	2201380964928251460	set_avg_params(['model_merged_1_best.pkl'], model_merged_2, layer_start=4)	1301	0	1301	74	8346466970183975154
4	1434	72	1434	73	-8869283364514074765	set_avg_params(['model_merged_2_best.pkl'], model_merged_3, layer_start=4)	1434	0	1434	74	-4642061602883335140
4	1591	85	1591	86	-2773897937251588602	set_avg_params(['model_1_best.pkl', 'model_2_best.pkl'], model_merged_1, layer_start=4)	1591	0	1591	87	-8119707116791014906
4	1797	43	1797	44	-6201732691842935863	plt.subplots(ncols=3,nrows=4,sharex=True)	1797	16	1797	57	-2631877016661537494
4	1901	24	1901	25	-7233554325037296127	plt.legend(bbox_to_anchor=(-1.2, 1.02, 1., 1.5),\n                   ncol=4, mode="expand", borderaxespad=0.)	1900	12	1901	59	4626297862589183298
0	10	66	10	67	377973444238573172	pd.read_csv('../proteins/protein0_data.csv', index_col=0)	10	11	10	68	-4757670540532188532
0	11	30	11	31	-7080191713442735404	np.min(X,axis=0)	11	16	11	32	-3310802304374365709
0	11	48	11	49	4829420699997826994	np.max(X,axis=0)	11	34	11	50	6863063522667063727
0	12	43	12	44	6000939424085560586	pd.read_csv('train.csv', header=0)	12	11	12	45	-5988654607947945629
0	12	52	12	53	2120372845186609919	pd.read_csv('crimescleaned.csv', index_col=0)	12	9	12	54	8570371917101244871
0	13	52	13	53	-110689488197597813	pd.read_csv('../datasets/polls.csv', index_col=0)	13	5	13	54	-814150059817015252
0	14	33	14	34	4376593168747686954	pd.read_csv(path, index_col=0)	14	5	14	35	856201718682660738
0	14	38	14	39	6067476609520861964	pd.read_csv(data_dir,header=0,sep=',')	14	10	14	48	-8093221491915080896
0	14	41	14	42	589813666591811364	pd.read_csv('test.csv', header=0)	14	10	14	43	4788157767577519914
0	15	33	15	34	196216901559323038	stats.uniform.pdf( x,loc=0, scale = 5)	15	8	15	46	-7235083382690971715
0	15	47	15	48	2072761281677479018	pd.read_excel(file_i, u'Sheet1', header=0, parse_cols="A:K", skip_footer=1)	15	7	15	82	371090447531890935
0	15	50	15	51	5574372310356457537	Axis(format='%Y', labelAngle=0)	15	21	15	52	5364006781824104827
0	16	33	16	34	-5798935421548553955	stats.uniform.pdf(x, loc=0, scale = 5)	16	8	16	46	367723389087243007
0	16	75	16	76	-2217615367082250889	pd.read_csv('../proteins/protein0_labels.csv', index_col=0)	16	18	16	77	5357748991895899098
0	17	76	17	77	7027411523140197268	read_data_sets("data", one_hot=True, reshape=False, validation_size=0)	17	8	17	78	-8875949534842684971
0	18	113	18	114	-9152747875328084336	pd.read_csv('C:/Users/isle132/Documents/CompChemTools/bgg/board-game-data/bgg_db_2017_04.csv', header=0, encoding='latin1', index_col=0)	18	11	18	147	-3610275637579340993
0	18	145	18	146	-3619967008209155748	pd.read_csv('C:/Users/isle132/Documents/CompChemTools/bgg/board-game-data/bgg_db_2017_04.csv', header=0, encoding='latin1', index_col=0)	18	11	18	147	-3610275637579340993
0	19	42	19	43	-1502489361688660889	scale(alexnet_train, axis=0, with_mean=True, with_std=True, copy=True)	19	16	19	86	5275371787202577888
0	19	96	19	97	1344792923821602332	pd.read_csv(os.path.join(results_dir, 'perplexity_topic.csv'), index_col=0)	19	23	19	98	1657388873634823295
0	20	46	20	47	4252191972699196896	scale(alexnet_test, axis=0, with_mean=True, with_std=True, copy=True)	20	21	20	90	1914667360322041500
0	20	49	20	50	3715832944318513166	np.sum(h1[0].data, axis=0)	20	25	20	51	-7615476494001845634
0	20	51	20	52	-6943510440057599074	np.concatenate((c1data, c3data), axis=0)	20	13	20	53	5814208211415320613
0	20	63	20	64	-1647110658751936527	pd.read_csv("../files/hw2_out.csv", sep="\t", header=0, index_col="user_id")	20	10	20	86	6287362908848686142
0	20	64	20	65	-7124058343184214578	np.sum(diff * (m_j / mag3)[:,np.newaxis], axis=0)	20	17	20	66	-6088185445541619008
0	20	79	20	80	-3890319882671239510	pd.read_table(DATA_FOLDER + "/laa_2011_april.txt", sep = "\t", header=0, index_col=None)	20	9	20	97	8067476031139583820
0	20	100	20	101	2610367058926338638	pd.read_csv(os.path.join(results_dir, 'perplexity_opinion.csv'), index_col=0)	20	25	20	102	-8278684915626739237
0	22	19	22	20	-7155882932149982802	data_mat.sort(axis=0)	22	0	22	21	-8088464057845528181
0	23	49	23	50	-6707450704385400995	np.sum(h2[0].data, axis=0)	23	25	23	51	-4846974592963738076
0	24	50	24	51	-3601894564009554241	sales.random_split(.8,seed=0)	24	23	24	52	-4003886966015499461
0	25	22	25	23	6779450852737051937	FloatProgress(min=0, max=100)	25	4	25	33	-966105580900459449
0	25	40	25	41	-1555172678310473728	Axis(format='%Y', labelAngle=0, title='year')	25	11	25	56	-2787110881035630215
0	26	27	26	28	7392519508112859609	data.mean(axis=0)	26	12	26	29	-821230063660700908
0	26	36	26	37	-8790397157095936179	plt.scatter(X[:,0], X[:,1], c=y, lw=0, s=40)	26	0	26	44	3236529668444922772
0	26	63	26	64	-1542439800398879873	Point.frompolar(radius=b,angle=0)	26	32	26	65	-7666721074673851344
0	28	23	28	24	-1723510186442301258	df.unstack(level=0)	28	6	28	25	861558148802604102
0	30	108	30	109	-8296226310537578522	distort.gen_warp_transform(file_tocorrect, file_reference, topo_channel, topo_channel, progress=0, debug=0, tftype='polynomial', islog=True)	30	12	30	152	3362535544927188860
0	30	117	30	118	-6263478156969108031	distort.gen_warp_transform(file_tocorrect, file_reference, topo_channel, topo_channel, progress=0, debug=0, tftype='polynomial', islog=True)	30	12	30	152	3362535544927188860
0	31	65	31	66	-1431892183832702630	pd.read_excel(in_xls, sheetname='hydro_indic', index_col=0)	31	8	31	67	-6639087523739079394
0	32	85	32	86	-1435260464383389301	distort.get_channel_for_warp(file_reference, topo_channel, progress=0, debug=0)	32	17	32	96	40433110324642370
0	32	94	32	95	6363254653848630499	distort.get_channel_for_warp(file_reference, topo_channel, progress=0, debug=0)	32	17	32	96	40433110324642370
0	32	211	32	212	-1969807789228342545	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=c, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	32	13	32	241	-6282894579066499134
0	33	48	33	49	4614046395766590481	pd.read_csv(pardir+f, index_col=0)	33	16	33	50	8386351848840266099
0	33	49	33	50	-2258489908129700388	SimplePolicyNetwork(hidden_dim=5,reg=0)	33	12	33	51	9190507902451454594
0	33	85	33	86	-6999565810332561783	distort.get_channel_for_warp(file_tocorrect, topo_channel, progress=0, debug=0)	33	17	33	96	-6841912895248513334
0	33	94	33	95	8825024074379140858	distort.get_channel_for_warp(file_tocorrect, topo_channel, progress=0, debug=0)	33	17	33	96	-6841912895248513334
0	34	76	34	77	-7376874903299726307	simpleBox(mode="pro_only",length=50000,block_size=30,random_range=0,trial_per_episode=5,\n                    repeat = True, reward_ratio = 5)	34	10	35	52	-6114426729519423264
0	35	40	35	41	-4481949527372597219	Axis(format='%Y', labelAngle=0, title='year')	35	11	35	56	6249933323751112057
0	35	69	35	70	3934745512313555652	pd.read_csv("../data/04_01_16_8_U_init.csv", index_col = 0)	35	12	35	71	-5683206733642863531
0	35	82	35	83	433921450505150557	distort.apply_warp_transform(topo_tocorrect, transform, progress=0, debug=0)	35	17	35	93	7608220300676032997
0	35	91	35	92	-2494578944082931596	distort.apply_warp_transform(topo_tocorrect, transform, progress=0, debug=0)	35	17	35	93	7608220300676032997
0	36	59	36	60	-6704780220672305908	okCupidFrame.apply(numMissing,axis = 0)	36	22	36	61	-4304565216173013910
0	36	66	36	67	638842351126422918	pd.read_excel(in_xls, sheetname='site_props', index_col=0)	36	10	36	68	3457968874328529758
0	37	108	37	109	-4026958434824365730	train_test_split(cancer.data, cancer.target, test_size=0.4, random_state=0)	37	35	37	110	-1752269758220326272
0	39	49	39	50	-2831429955733649010	targetData.min(axis=0)	39	29	39	51	-7947847783402533667
0	39	211	39	212	-7608767416618577205	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.005, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	39	9	39	241	3476444751173404693
0	40	49	40	50	4393357623328745997	targetData.max(axis=0)	40	29	40	51	-3695184208408047769
0	40	62	40	63	-1365974322641508918	RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)	40	6	40	75	-3743061046454617844
0	40	63	40	64	-4036790020259004758	pd.read_excel(in_xls, sheetname='mzb_data', index_col=0)	40	9	40	65	-1736346081003096473
0	40	65	40	66	-3242925941718555806	TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')	40	5	40	89	2290147078785331299
0	40	77	40	78	4248809294327354969	pd.read_table(DATA_FOLDER + "/laa_2011_full.txt", sep = "\t", header=0, index_col=None)	40	8	40	95	-3938328611887316391
0	44	61	44	62	-2268451729158579740	pd.read_excel(in_xls, sheetname='pb_data', index_col=0)	44	8	44	63	5324198120830384588
0	45	40	45	41	8399090667933159973	Axis(format='%Y', labelAngle=0, title='year')	45	11	45	56	-5290452251135493878
0	45	66	45	67	-3278480098314353028	pd.read_csv('../proteins/protein107_data.csv', index_col=0)	45	9	45	68	5942728374632034256
0	46	29	46	30	-8568551274658372949	data.rank(axis=0, pct=True)	46	14	46	41	-48336031365682703
0	47	27	47	28	5108799485672415400	data.mean(axis=0)	47	12	47	29	5487099552137183144
0	47	43	47	44	5579666101395150731	Basemap(projection='ortho', lat_0=0, lon_0=-20,\n              resolution='l', area_thresh=1000.0)	47	9	48	49	-8343999726826227587
0	50	23	50	24	-6668729077470755472	data.idxmax(axis=0, skipna=True)	50	6	50	38	-5899698601660280872
0	50	42	50	43	7289685395547488139	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	50	0	50	73	-3788675041583091273
0	50	53	50	54	8429097568689554543	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	50	0	50	73	-3788675041583091273
0	51	39	51	40	-1577880911267352969	np.mean(X_train, axis = 0)	51	15	51	41	1078022984346668290
0	55	33	55	34	6807981643163540542	np.var(x, axis=0, ddof=1)	55	18	55	43	5528576446472848983
0	55	56	55	57	1250479985448642072	input_data['labels'].replace(to_replace = "NG", value = 0, inplace = True)	55	0	55	74	1963169582787602803
0	59	69	59	70	2215781555247061043	c.search_reads(read_group_ids=[read_group.id], start=0, end=1000000, reference_id=reference.id)	59	16	59	111	710237981902430416
0	62	18	62	19	4749430693365136235	Basemap(llcrnrlon=0,llcrnrlat=-50,urcrnrlon=360,urcrnrlat=50,projection='mill')	62	0	62	79	4758132665796981063
0	62	22	62	23	-448873168844244032	FloatSlider(min=0, max=1000, step=5, value = 0)	62	6	62	53	-8305853719096747478
0	62	43	62	44	-5635769428005473168	Basemap(projection='robin', lat_0=0, lon_0=-20,\n              resolution='l', area_thresh=1000.0)	62	9	63	49	-1837877385539966569
0	62	51	62	52	-1552196425250120477	FloatSlider(min=0, max=1000, step=5, value = 0)	62	6	62	53	-8305853719096747478
0	62	112	62	113	2808393900962725506	graphlab.linear_regression.create(training,target='price',features=all_features,\n                                                   validation_set=None,l1_penalty=l1_penalty_list[i],l2_penalty=0)	61	17	62	114	8851680787948142687
0	64	27	64	28	-6353015949056319013	data.mean(axis=0)	64	12	64	29	5499289129492859202
0	65	50	65	51	-6526908292711818153	TruncatedSVD(n_components=50, random_state=0)	65	7	65	52	-4300682596563219482
0	66	50	66	51	3422290447350489389	rects[:,2].argmax(axis=0)	66	27	66	52	-7552338130139331308
0	66	52	66	53	-5124519000863268793	pandas.read_table(path, index_col=0)	66	18	66	54	-162258567674148608
0	67	15	67	16	-176634206897894259	plt.legend(loc=0)	67	0	67	17	563959809093429770
0	67	68	67	69	8421901928925563219	datasets.make_classification(n_features = 2, n_informative = 2, n_classes = 4,\n                                                      n_redundant = 0, n_clusters_per_class = 1, random_state = 1)	66	25	67	114	-4262636933383093953
0	67	105	67	106	5253213851050786378	train_test_split(new_data, y_target, test_size=0.25, random_state=0)	67	39	67	107	-4128954543139563472
0	69	50	69	51	5467208699625798107	np.mean(predictions, axis=0)	69	24	69	52	1542671147011119923
0	71	51	71	52	8087773138516167873	DecisionTreeRegressor(random_state=0)	71	16	71	53	-4009389522104726917
0	73	44	73	45	-8869989835933020313	np.expand_dims(x, axis=0)	73	21	73	46	6163301715676569493
0	73	93	73	94	9049607388303277037	pd.read_csv(os.path.join(results_dir, 'theta_{}.csv'.format(nTopics)), index_col=0)	73	12	73	95	7535057242787350875
0	74	44	74	45	-1075134923646287976	ax.plot_surface(L, C, utility, rstride=1, cstride=1, cmap=mpl.cm.terrain,\n                                  linewidth=0, vmin=-10, vmax=np.max(utility),\n                                  antialiased=False)	73	18	75	52	2684203492910617269
0	76	43	76	44	-7195433075559585607	np.array(acc_T).mean(axis=0)	76	17	76	45	-8222423648793180301
0	76	67	76	68	6924620324191784519	Point.frompolar(radius=b,angle=0)	76	36	76	69	-7538763189497531739
0	76	100	76	101	-1463152518912104783	pd.read_csv(os.path.join(results_dir, 'topics_{}.csv'.format(nTopics)), index_col=0, encoding='utf-8')	76	18	76	120	1644506747806080865
0	77	39	77	40	-2688785070580811362	scale(alexMerged, axis=0, with_mean=True, with_std=True, copy=True)	77	16	77	83	-3600572228682170517
0	77	43	77	44	5998273587812364367	np.array(acc_V).mean(axis=0)	77	17	77	45	5071592806553580752
0	77	54	77	55	-2737680321944505568	gamma.fit(g60df.G60, floc=0)	77	28	77	56	-8390512767627495120
0	77	56	77	57	7410764245169880451	input_data['labels'].replace(to_replace = "NG", value = 0, inplace = True)	77	0	77	74	4753153069320644895
0	78	26	78	27	-241780144073857474	pd.read_csv(\n                file_names['train'][file_name],\n                index_col=0,\n                header=None,\n                names=train_columns[file_name],\n                nrows=chunksize,\n                skiprows=i,\n                dtype=train_types[file_name]\n                )	76	42	84	17	2543586398382091175
0	78	40	78	41	-7646003853634417106	x.std(ddof=0)	78	29	78	42	5237212871812675422
0	78	46	78	47	6330181309668609156	scale(alexnet_test, axis=0, with_mean=True, with_std=True, copy=True)	78	21	78	90	702680244865169359
0	79	40	79	41	4028547134616339397	y.std(ddof=0)	79	29	79	42	6824831292881034701
0	80	59	80	60	-217071617878816969	graphlab.linear_regression.create(training,target='price',features=all_features,\n                                                   validation_set=None,l1_penalty=l1_penalty_list[np.argmin(RSS_list)]\n                                               ,l2_penalty=0)	78	13	80	61	3924332891328694442
0	82	14	82	15	-5437277338311341081	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'l', area_thresh = 1000,\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	79	9	82	32	8596503024335138880
0	84	51	84	52	-4742045649464692673	np.random.standard_normal((20, 2)).cumsum(axis=0)	84	4	84	53	-8788758444317117055
0	84	56	84	57	5603655467108030347	pd.read_csv(f, index_col=0, encoding='utf-8')	84	31	84	76	-3788947451198721612
0	86	28	86	29	7057520122681600825	sh.cell_value(rowx=8,colx = 0)	86	0	86	30	6805192037892254588
0	86	33	86	34	-3937997548480506992	stats.uniform.pdf( x,loc=0, scale = 5)	86	8	86	46	-3877296495755511966
0	86	41	86	42	-3408202444231803862	hdu.data[93:360, :].mean(axis=0)	86	11	86	43	3714129566742779951
0	87	33	87	34	1551747480778373680	stats.uniform.pdf(x, loc=0, scale = 5)	87	8	87	46	-7018674264575432691
0	87	42	87	43	-8060327048420933849	hdu.data[378:579, :].mean(axis=0)	87	11	87	44	-3573655578630321894
0	88	42	88	43	-3041623831171234381	hdu.data[617:823, :].mean(axis=0)	88	11	88	44	5494811591596412537
0	89	43	89	44	3958557842789932061	hdu.data[845:1089, :].mean(axis=0)	89	11	89	45	3891715377501952315
0	89	50	89	51	-8143506098814330558	rects[:,2].argmax(axis=0)	89	27	89	52	498375444172692815
0	91	19	91	20	-913916634191511447	sh.cell_value(rowx=0,colx = 0)	91	0	91	30	-7638998412995955749
0	91	28	91	29	-1682954513390305348	sh.cell_value(rowx=0,colx = 0)	91	0	91	30	-7638998412995955749
0	92	55	92	56	-8966576122071112097	pd.concat([to_merge1,to_merge2],axis=0)	92	18	92	57	-8073463766303976077
0	93	90	93	91	-1973185233985945946	tf.one_hot(indices=index, depth=env.observation_space.n, on_value=1, off_value=0, axis=None, name=name)	93	11	93	114	4199278662275588280
0	94	60	94	61	-474747825546124506	beta.fit(shpdf.ShP, floc=0, fscale=1)	94	35	94	72	-7421513146166607205
0	94	64	94	65	7246293426826674941	plt.scatter(dat['Teff'], dat['log(g)'], c=dat['R_H'], vmin=0, vmax=2, s=35, cmap=cmap, alpha=0.5)	94	5	94	102	3057921789789673490
0	94	75	94	76	5387421949940454834	simpleBox(mode="alternative",length=10000,block_size=30,random_range=0,trial_per_episode=5, repeat = True)	94	6	94	112	-4980187008601103576
0	96	19	96	20	2860732876012592508	sh.cell_value(rowx=0,colx = 0)	96	0	96	30	-6525632987028134962
0	96	26	96	27	184860616298150291	plt.ylabel('Y',rotation=0)	96	2	96	28	1957514675685273679
0	96	28	96	29	-6000480155269680791	sh.cell_value(rowx=0,colx = 0)	96	0	96	30	-6525632987028134962
0	96	29	96	30	-3946744215036166144	T.argmax(axis=0)	96	15	96	31	7702505011562964728
0	96	54	96	55	-7080836944285044353	np.average(x, axis=0, weights=prob[j])	96	35	96	73	6606312580193802402
0	96	75	96	76	8639562204446889483	RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)	96	19	96	88	2756579958262133220
0	97	47	97	48	-3361534516631182323	model.evaluate(X_test, y_test, verbose=0)	97	8	97	49	-58119983065446806
0	98	45	98	46	-3640821702892843342	CIFAR10(which_set='train', start=0, stop=45000)	98	12	98	59	-4460895166963593108
0	98	50	98	51	-2241403052495393049	clean_data.dropna(how="any", axis=0)	98	16	98	52	-533681722175868328
0	99	93	99	94	-3159401908552072094	graphlab.linear_regression.create(training,target='price',features=all_features,validation_set=None,\n                                                  l1_penalty=l1_penalty_values[i],l2_penalty=0,verbose=False)	98	17	99	109	-1423433680877419074
0	100	14	100	15	-2656623157424286896	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'l', area_thresh = 0.1,\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	97	9	100	32	-3005191117477244044
0	101	28	101	29	6544641100250520279	sh.cell_value(rowx=9,colx = 0)	101	0	101	30	-3942147808169811469
0	101	49	101	50	6304054837181388592	SimplePolicyNetwork(hidden_dim=5,reg=0)	101	12	101	51	2706081769804296807
0	102	15	102	16	3332558601784875660	df.dropna(axis=0, how='any', inplace=1)	102	0	102	39	458813632100446278
0	102	54	102	55	-7688168698843100028	pd.read_csv('../data/train.csv', index_col=0)	102	11	102	56	6040144267235883115
0	102	76	102	77	-6661272411755162113	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 1)	102	10	103	73	2934476473305307850
0	103	52	103	53	-6544975701630406494	pd.read_csv('../data/test.csv', index_col=0)	103	10	103	54	59683780014531451
0	103	67	103	68	6691515706928310579	np.mean(np.load('stage1/%s.npy' % str(id)), axis=0)	103	18	103	69	3458774764456594850
0	106	29	106	30	6460152088754021736	sh.cell_value(rowx=10,colx = 0)	106	0	106	31	8541017035171007974
0	106	31	106	32	-591275819910662595	stats.expon.pdf( x,loc=0, scale = 3)	106	8	106	44	5729776740074333081
0	107	31	107	32	7671547362633844846	stats.expon.pdf(x, loc=0, scale = 10)	107	8	107	45	-7820479375097189532
0	107	88	107	89	-4769909314532951578	ax[iclass].bar(bins,event,zs=sum_events+ievent\n                           ,zdir='y',width=bins_width,color=m_colors[iclass], linewidth=0)	106	12	107	90	-6342461309880339300
0	108	41	108	42	-1549059521045239055	np.array(acc_T).mean(axis=0)	108	15	108	43	-6444798510763765640
0	108	56	108	57	8158866255955423104	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	108	8	108	67	-8196014401503633222
0	108	65	108	66	-6569293426779829974	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	108	8	108	67	-8196014401503633222
0	109	41	109	42	-1454673735854316479	np.array(acc_V).mean(axis=0)	109	15	109	43	-5600176439756277461
0	109	45	109	46	-1383380453724192574	self.model.predict(X, verbose=0)	109	15	109	47	-8314375844150893976
0	110	15	110	16	-9162951023636739964	plt.legend(loc=0)	110	0	110	17	-1875119281498201702
0	113	31	113	32	-7416463999052418396	display2.plot_ppi('RhoHV',vmin=0,vmax=1)	113	0	113	40	1996020670462510767
0	116	18	116	19	-1592991493633963398	plt.axhline(y=0, color='r')	116	4	116	31	-7584628765455696527
0	116	29	116	30	-7223610913625480463	fig.subplots_adjust(left=0, right=1, bottom=0)	116	4	116	50	-7290039311198501800
0	116	48	116	49	-5957762358900010000	fig.subplots_adjust(left=0, right=1, bottom=0)	116	4	116	50	-7290039311198501800
0	117	31	117	32	-6135299145779883969	display2.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	117	0	117	50	7160287107557398832
0	117	66	117	67	-707608892285782831	skimage.morphology.label(closed, background=0,\n                                               connectivity=2,\n                                               return_num=True)	117	22	119	63	1190605743947185684
0	117	120	117	121	4544609970930804530	clf.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=1000, batch_size=X_train.shape[0], verbose=0)	117	8	117	122	-6564175486574836798
0	118	14	118	15	2261720755348782815	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	115	9	118	32	-4093210978899430732
0	118	15	118	16	6317296571974299076	ax2.legend(loc=0, frameon=False, prop={'family':'serif'})	118	0	118	57	1607653011756550055
0	119	27	119	28	-27041019763220416	np.expand_dims(x, axis=0)	119	4	119	29	888482430208453425
0	119	32	119	33	-5252733957666511809	display1.plot_ppi('sPhiDP',vmin=0,vmax=360)	119	0	119	43	886474461644079658
0	120	52	120	53	6358842388194153747	clf.predict_classes(X_test, verbose=0)	120	16	120	54	-8925843955571623779
0	123	28	123	29	5928358154538495510	group_1.sum(axis=0)	123	11	123	30	-6569131142589223503
0	123	84	123	85	-8692715169694376222	group_2.sum(axis=0)	123	67	123	86	4122423756758790536
0	123	93	123	94	-2633411590913503434	graphlab.linear_regression.create(training,target='price',features=all_features,validation_set=None,\n                                                  l1_penalty=l1_penalty_values[i],l2_penalty=0,verbose=False)	122	17	123	109	3632745790278310210
0	125	47	125	48	5123978924638908241	model.evaluate(X_test, y_test, verbose=0)	125	8	125	49	2624620749244174584
0	127	15	127	16	7790778457619623265	plt.legend(loc=0)	127	0	127	17	9006995282985903484
0	130	35	130	36	-335378756364895501	sns.heatmap(correlations, vmin=0, vmax=1, annot=True)	130	4	130	57	-3579592535373262786
0	133	63	133	64	1410958888329320343	Point.frompolar(radius=b,angle=0)	133	32	133	65	4575336735470822803
0	134	35	134	36	5793654895907047622	faces_images.mean(axis=0)	134	12	134	37	5236692009122783906
0	136	14	136	15	2773282888270559308	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	133	9	136	32	5557992257497168085
0	136	30	136	31	4964073009897890730	pd.read_csv(\n                    file_names['test'][file_name],\n                    index_col=0,\n                    header=None,\n                    names=test_columns[file_name],\n                    nrows=chunksize,\n                    skiprows=i,\n                    dtype=test_types[file_name]\n                    )	134	41	142	21	3363208879182492977
0	136	50	136	51	-5655631200888247516	plt.imshow(solid_gray_img, cmap=plt.cm.gray, vmin=0, vmax=255)	136	0	136	62	-8064750085561427835
0	136	52	136	53	2318313006900684820	np.append(X_train, copy, axis=0)	136	22	136	54	-5192471648233799666
0	138	67	138	68	3699776589256788126	np.mean(np.load('stage1/%s.npy' % str(id)), axis=0)	138	18	138	69	7402918399867616717
0	139	34	139	35	-8349877560127956000	data.apply(np.log,axis=0)	139	11	139	36	-1046753820162538401
0	140	27	140	28	8685126088307928993	df_t.reset_index(level=0, inplace=True)	140	4	140	43	-1784316071959734337
0	142	40	142	41	3863102170311846300	samples.apply(np.log,axis=0)	142	14	142	42	527842466268979579
0	142	94	142	95	5060812578696225051	graphlab.linear_regression.create(training,target='price',features=all_features,validation_set=None,\n                                                  l1_penalty=l1_penalty_values[11],l2_penalty=0,verbose=False)	141	13	142	110	-285446961805017457
0	143	48	143	49	4642740926313644226	np.percentile(lines, [16, 84], axis=0)	143	12	143	50	-6807290128848799264
0	144	49	144	50	8003559459743349215	SimplePolicyNetwork(hidden_dim=5,reg=0)	144	12	144	51	-4718273022800335828
0	145	23	145	24	-5803228755552087305	plt.imshow(img, zorder=0, extent=[-1300, 72000, -24000, 41000])	145	0	145	63	1635271981002033409
0	145	76	145	77	4384398727237252558	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 5)	145	10	146	73	-3269178071910035111
0	147	19	147	20	-7114847268301236220	laliga.dropna(axis=0, how='any',inplace=True)	147	0	147	45	-7133711218324955037
0	147	42	147	43	4189704266281556829	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	147	0	147	73	4460889049567238131
0	147	53	147	54	8161017025861303390	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	147	0	147	73	4460889049567238131
0	147	69	147	70	-2750784969573297430	ax.bar(center, hist, align='center', width=width, edgecolor=None, lw=0, label='D = $3\\times 10^{{15}}$ \n Max = {0:0.1f}'.format(df['Flux with catalysis'].max()), color=cmap[0])	147	0	147	178	-3097740860615548609
0	149	60	149	61	-9031644774572904440	ax[1].hist2d(vx,vy,bins=70,alpha=0,range=[[-120,120],[-120,60]])	149	27	149	91	-4634810491605689203
0	150	15	150	16	-6194666014667455608	plt.legend(loc=0)	150	0	150	17	6621756919813188398
0	150	31	150	32	2139164016821576443	df_o.reset_index(level=0, inplace=True)	150	8	150	47	-5338891112707230351
0	152	69	152	70	4726298131127902807	ax.scatter(x_iris[:, 0], x_iris[:, 1], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	152	0	152	77	-6259104832034614547
0	155	15	155	16	4711397981295280100	ax2.legend(loc=0, frameon=False, prop={'family':'serif'})	155	0	155	57	-7332540173050369383
0	157	69	157	70	6323766239213368570	ax.scatter(x_iris[:, 0], x_iris[:, 1], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	157	0	157	77	-9122185221937297140
0	157	96	157	97	-3545568891695239268	np.linalg.norm(r,axis=0)	157	74	157	98	391311219535590294
0	158	14	158	15	1821917308345636837	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	155	9	158	32	8658093629239907608
0	158	34	158	35	-7722955674429324329	plt.imshow(modis_sent*0.001, vmin=0, vmax=0.20)	158	0	158	47	-3897718182967934831
0	158	40	158	41	6516106526367665645	pd.concat(CustFlight, axis=0)	158	13	158	42	472196863408461649
0	161	34	161	35	-6843238555760669920	cumtrapz(f, R, initial=0)	161	11	161	36	2686683257514351749
0	161	53	161	54	6723073624213009753	pd.read_csv("bike_count_interim.csv", index_col=0, parse_dates=True)	161	5	161	73	8752751009286933011
0	161	69	161	70	-6311353504160400150	ax.bar(center, hist, align='center', width=width, edgecolor=None, lw=0, label=r'D = $3\times 10^{12}$', color=cmap[1])	161	0	161	118	-7934687987077072191
0	162	45	162	46	4961087103368894834	pd.read_csv(jsdFile, index_col=0)	162	14	162	47	3808031086240653309
0	163	15	163	16	-1179913468762004802	plt.legend(loc=0)	163	0	163	17	5057744586982331102
0	168	31	168	32	5571060190186502947	np.mean(normX,axis=0)	168	12	168	33	930151115760910724
0	168	37	168	38	3039660599671449226	np.max(logPosteriors, axis = 0)	168	8	168	39	-3440095858270972981
0	168	92	168	93	8971098285591733484	model.fit(x_train, y_train, batch_size = batch_size, nb_epoch = num_epochs, verbose=0,validation_split=0.05)	168	8	168	116	-5374100509290395991
0	169	30	169	31	8375616200619482897	display.plot_ppi('RhoHV',vmin=0,vmax=1)	169	0	169	39	-632152990807473823
0	170	29	170	30	354050516942000025	np.std(normX,axis=0,ddof=1)	170	11	170	38	-4093332258538542831
0	171	15	171	16	-4189375352901036588	plt.legend(loc=0)	171	0	171	17	-7274681855650603002
0	171	17	171	18	5764430382748157253	AdaBoostClassifier(base_estimator=None,\n    n_estimators=100,\n    learning_rate=1.0,\n    algorithm='SAMME.R',\n    random_state=0)	167	6	171	19	6217791255254211484
0	171	69	171	70	-7018052075250270863	ax.scatter(x_iris[:, 2], x_iris[:, 3], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	171	0	171	77	4076265054361232790
0	173	30	173	31	991743568820494384	display.plot_ppi('PhiDP',vmin=0,vmax=360)	173	0	173	41	4168859209340830449
0	175	64	175	65	2394361426200084418	model.predict(img, batch_size=32, verbose=0)	175	22	175	66	-3275354214630588475
0	175	69	175	70	8194828014615182478	ax.bar(center, hist, align='center', width=width, edgecolor=None, lw=0, label=r'D = $3\times 10^{12}$')	175	0	175	103	-2581941539874655842
0	176	69	176	70	6813440856381046762	ax.scatter(x_iris[:, 2], x_iris[:, 3], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	176	0	176	77	7728321624954925774
0	178	78	178	79	2108224625935854589	hough_line_peaks(hspace=h, angles=theta,\n                                             dists=d, num_peaks=20, threshold=0)	177	28	178	80	3227342998954488761
0	179	46	179	47	-3417034797442244456	np.nanmean(day_station_table,axis=0)	179	12	179	48	4135001830449162628
0	180	14	180	15	-8132149878227969136	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	177	9	180	32	7793756400611613911
0	182	17	182	18	6723906138392340346	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	181	9	183	37	1022489683466815085
0	182	42	182	43	8222733344333469076	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	182	0	182	73	-1931039812533034310
0	182	53	182	54	6319856632374900604	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	182	0	182	73	-1931039812533034310
0	183	64	183	65	6721409199685444208	ax.imshow(dS[i,::-1], aspect='auto', vmax=ek, vmin=0, cmap='RdYlGn_r')	183	13	183	83	1799158280604875502
0	184	89	184	90	-3168314308177033140	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c=post_prob[m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	184	0	184	112	-1889501870135959898
0	186	15	186	16	-946220044374773781	plt.legend(loc=0)	186	0	186	17	-1806542291941141953
0	186	18	186	19	7696861115499268139	plt.axhline(y=0, color='r')	186	4	186	31	6460586347347846984
0	186	42	186	43	6054311555468016486	df.sort("rssiAdj", ascending=0)	186	13	186	44	6598931942770365839
0	186	92	186	93	-8349844519550929690	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c=post_prob[~m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	186	0	186	115	8655850365270254544
0	187	30	187	31	4232937582322530644	display.plot_ppi('RhoHV',vmin=0,vmax=1,sweep=1)	187	0	187	47	-2512975019501053407
0	189	69	189	70	8626601718724474031	ax.bar(center, hist, align='center', width=width, edgecolor=None, lw=0, label=r'D = $3\times 10^{15}$', color=cmap[0])	189	0	189	118	-3825257599115996629
0	190	76	190	77	-1627356255661203194	stats['red'].std(ddof=0)	190	54	190	78	-8884228157164592455
0	191	30	191	31	-8547879656733947946	display.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	191	0	191	49	9188366317665067491
0	191	84	191	85	2060564980449202166	stats['green'].std(ddof=0)	191	60	191	86	8273697896969041261
0	192	15	192	16	-6710141243549459643	ax2.legend(loc=0, frameon=False, prop={'family':'serif'})	192	0	192	57	-7611502868154258457
0	192	33	192	34	2973568303276171024	np.cov(pre.all_dat, rowvar=0)	192	6	192	35	-2973712634906539639
0	193	33	193	34	-7591040122359990879	display1.plot_ppi('sdPhiDP',vmin=0,vmax=360)	193	0	193	44	-6190453704109777063
0	195	15	195	16	3906527839337397156	plt.legend(loc=0)	195	0	195	17	6001906221620861227
0	195	51	195	52	-182880644784944317	np.sum(P, axis=0)	195	36	195	53	2328621262061073046
0	196	18	196	19	-9159177928424967331	ax.view_init(elev=0, azim=0)	196	0	196	28	520921687627569551
0	196	26	196	27	2571135582520055245	ax.view_init(elev=0, azim=0)	196	0	196	28	520921687627569551
0	197	31	197	32	-3114674369260628281	np.expand_dims(img, axis=0)	197	6	197	33	4852083421966139140
0	197	68	197	69	2761097928687347545	poor_people.sample(n=n_poor_new, random_state=0)	197	22	197	70	-5871511396308078227
0	199	23	199	24	-8987680509851695399	ax.set_ylim(bottom=0)	199	4	199	25	2322495823649344367
0	201	18	201	19	-6408226481240663857	ax.view_init(elev=0, azim=0)	201	0	201	28	-6352554912726223134
0	201	26	201	27	-3354135842052384370	ax.view_init(elev=0, azim=0)	201	0	201	28	-6352554912726223134
0	202	46	202	47	5987260644210606998	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=0)	202	0	202	48	-1078832887598625434
0	203	56	203	57	1570081446185811433	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	203	8	203	67	2907022186646627746
0	203	65	203	66	-2598163768588481799	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	203	8	203	67	2907022186646627746
0	203	69	203	70	-9081921062422899978	ax.bar(center, hist, align='center', width=width, edgecolor=None, lw=0, label=r'D = $3\times 10^{12}$', color=cmap[1])	203	0	203	118	-5961761514570272238
0	203	141	203	142	5215596047605058586	plt.Rectangle((-1, min(water_porewidth)), len(water_porewidth)+1, max(water_porewidth)-min(water_porewidth), color='0.9', zorder=0)	203	12	203	143	-8940869790833232050
0	205	14	205	15	-5223855480711971959	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	202	9	205	32	940559479158808541
0	207	52	207	53	5741519246957553503	ax.imshow(dS[i,::-1] * 130816. / len( arange(len(Gclus['512u']))[Gclus['512u'] == i] ),\n                       aspect='auto', vmax=ek, vmin=0, cmap='RdYlGn_r')	206	13	207	71	-146912827189362317
0	207	74	207	75	7662749198256041108	sns.load_dataset("brain_networks", header=[0, 1, 2], index_col=0)	207	11	207	76	-4610429786979466251
0	210	41	210	42	-4361826014872884988	pm.Normal("beta", 0, 0.001, value=0)	210	7	210	43	-8127978521387731786
0	211	43	211	44	-7951753905669174908	pm.Normal("alpha", 0, 0.001, value=0)	211	8	211	45	-6816121238577696064
0	215	32	215	33	5238841954233280884	np.random.normal(loc=0, scale=1, size=(1,2))	215	11	215	55	7094165938103852895
0	215	153	215	154	860499646121540472	plt.Rectangle((-1, min(camphene_porewidth)), len(camphene_porewidth)+1, max(camphene_porewidth)-min(camphene_porewidth), color='0.9', zorder=0)	215	12	215	155	-1523356804474080811
0	216	47	216	48	-6883189036689246801	KMeans(n_clusters = 5, random_state = 0,init='k-means++',max_iter = 100)	216	9	216	81	-93560221250628329
0	225	29	225	30	6158678289191035811	np.std(Xpca, axis = 0)	225	9	225	31	-1426877304788829563
0	227	42	227	43	5333778113895087938	COMM_WORLD.recv(source=0, tag=MPI.ANY_TAG, status=status)	227	19	227	76	1126139883089167639
0	227	133	227	134	-5229427103743986043	plt.Rectangle((-1, min(tba_porewidth)), len(tba_porewidth)+1, max(tba_porewidth)-min(tba_porewidth), color='0.9', zorder=0)	227	12	227	135	-967682669176122788
0	228	18	228	19	-1843607758148908839	ax[i].legend([dealer[miles][0] for miles in lifetime_mileages],\n               ['For %dk Mile Lifetime'%(miles/1000) for miles in lifetime_mileages],\n              fontsize=textheight,\n              loc=0)	225	4	228	20	4557554998658123436
0	228	54	228	55	2458272277561831502	nouns_sparse_matrix.sum(axis=0)	228	25	228	56	1478950016425286524
0	229	65	229	66	8628832919861029856	arr.sum(axis=0)	229	52	229	67	-4220359379317650263
0	229	70	229	71	-5740722441040533463	ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n                                       max_depth=5)	229	9	230	51	1279645807566090493
0	233	27	233	28	-8291520046122723325	fig.subplots_adjust(wspace=0)	233	0	233	29	7004855519841540701
0	234	42	234	43	-3116992771649550626	COMM_WORLD.isend(result, dest=0, tag=status.tag)	234	12	234	60	-7922651390626309993
0	235	50	235	51	3829988238936714123	mcmc.trace("centers", chain = 0)	235	20	235	52	988698487772844651
0	236	33	236	34	943144554460863515	ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n                       linewidth=0, antialiased=False)	235	7	236	54	-7386960939680423698
0	237	102	237	103	5993214448555468311	np.nanmean(hflux.GAD['ADVx_TH'][0:12,:,58*kk:80*kk,76*kk],axis=0)	237	39	237	104	-2839503170580947931
0	238	103	238	104	-8526850437481637429	np.nanmean(hflux.GAD['DFxE_TH'][0:12,:,58*kk:80*kk,76*kk],axis=0)	238	40	238	105	-2613278029680975246
0	239	105	239	106	-4851096968127236762	np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,113*kk:135*kk,75*kk],axis=0)	239	40	239	107	3817884897975893964
0	240	106	240	107	3262022173498156991	np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,113*kk:135*kk,75*kk],axis=0)	240	41	240	108	5871492257984278256
0	241	27	241	28	3291823347927215254	plt.imshow(img, zorder=0, extent=[-1300, 72000, -24000, 41000])	241	4	241	67	8102628621526682074
0	241	56	241	57	-3107858982780272792	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	241	8	241	67	-1558394873680959889
0	241	65	241	66	-2191288574179105893	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	241	8	241	67	-1558394873680959889
0	241	106	241	107	-7538982406359422662	np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,100*kk,37*kk:48*kk],axis=0)	241	42	241	108	8157820877416143804
0	241	170	241	171	-5511642751492496416	np.all([np.power((np.abs((-(dataframe['z']*10)-152)/126.8)),2.7) + np.power(((((dataframe['x']*10)**2)+((dataframe['y']*10)**2))/17500.),2.7) < 1], axis=0)	241	17	241	172	-6569981700298373920
0	242	107	242	108	2594374290315665035	np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,100*kk,37*kk:48*kk],axis=0)	242	43	242	109	607343333386903711
0	243	105	243	106	-5825027433053448329	np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,80*kk:89*kk,178*kk],axis=0)	243	41	243	107	-4419868444171300098
0	244	106	244	107	-1354833352880150845	np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,80*kk:89*kk,178*kk],axis=0)	244	42	244	108	-6872767708374343110
0	245	57	245	58	5189296516378098798	np.take(X, added_indexes, axis=0)	245	26	245	59	3209880547188005466
0	245	165	245	166	-8672377138215543448	np.all([np.power((np.abs((-(dataframe['z']*10)-150)/146.)),4) + np.power(((((dataframe['x']*10)**2)+((dataframe['y']*10)**2))/20000.),4) < 1], axis=0)	245	17	245	167	814008104248760020
0	246	67	246	68	-4407888853562247921	manifold.SpectralEmbedding(n_components=2, random_state=0,\n                                      eigen_solver="arpack")	246	11	247	60	-1502557477349364256
0	246	91	246	92	-306032434559795933	np.nanmean(hflux.GAD['ADVx_TH'][0:12,:,40*kk,53*kk:68*kk],axis=0)	246	28	246	93	534062941223780653
0	247	91	247	92	-8244519299608366377	np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,40*kk:58*kk,68*kk],axis=0)	247	28	247	93	-7667456529958104227
0	249	65	249	66	2718518740822564834	np.all([dataframe['s1_coincidence'] > 1], axis=0)	249	18	249	67	6001637518031235287
0	249	91	249	92	7681396912107581419	np.nanmean(hflux.GAD['DFxE_TH'][0:12,:,40*kk,53*kk:68*kk],axis=0)	249	28	249	93	2262054099537645488
0	250	91	250	92	1750615513515197799	np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,40*kk:58*kk,68*kk],axis=0)	250	28	250	93	2920067166840754072
0	252	91	252	92	7505584429098590714	np.nanmean(hflux.GAD['ADVx_TH'][0:12,:,60*kk:95*kk,15*kk],axis=0)	252	28	252	93	3464683130877115813
0	253	91	253	92	-8727741503725138379	np.nanmean(hflux.GAD['ADVy_TH'][0:12,:,95*kk,15*kk:30*kk],axis=0)	253	28	253	93	-5780533124933723566
0	255	55	255	56	8714170616452040318	np.delete(X, removed_indexes, axis=0)	255	20	255	57	-4877091687596979971
0	255	91	255	92	1739785879913900313	np.nanmean(hflux.GAD['DFxE_TH'][0:12,:,60*kk:95*kk,15*kk],axis=0)	255	28	255	93	6210611284147700240
0	256	15	256	16	-4203121040856351100	plt.legend(loc=0)	256	0	256	17	-3095614055627121919
0	256	16	256	17	-3744673242454498434	plt.axhline(y=0, color='r')	256	2	256	29	3120449544221092657
0	256	55	256	56	-8686668558490735583	np.delete(y, removed_indexes, axis=0)	256	20	256	57	-7042130955180964061
0	256	68	256	69	-5286550627870171158	decade_agg_ap.sort_values(by=['percent on-time gate arrivals'],axis=0, inplace=1)	256	0	256	81	392970596219725254
0	256	91	256	92	-7571620626959045965	np.nanmean(hflux.GAD['DFyE_TH'][0:12,:,95*kk,15*kk:30*kk],axis=0)	256	28	256	93	-1083986493550847234
0	257	104	257	105	2734207802193830166	np.all([dataframe['number_of_interactions']==1, dataframe['s2'] > 0], axis=0)	257	29	257	106	7591317782210876124
0	259	33	259	34	-6506620125631445694	np.any([np.all([dataframe['number_of_interactions']==1, dataframe['s2'] > 0], axis=0),\n                            dataframe['largest_other_s2'] < 70 + np.divide((dataframe['s2']-300.0),100.0)],\n                            axis=0)	257	21	259	35	-7735910079822658857
0	260	73	260	74	-1532227822351228075	newyear.plot(ax=ax, color=['LightGreen', 'LightBlue'], legend=False, rot=0)	260	0	260	75	1485754717281340530
0	261	102	261	103	-3549719659475707771	newyear.rolling(10, center=True).mean().plot(linewidth=2, ax=ax, color=['DarkGreen', 'DarkBlue'], rot=0)	261	0	261	104	4079559634740617041
0	262	62	262	63	-7544811674273819005	manifold.TSNE(n_components=2, init='pca', random_state=0,  method='exact')	262	7	262	81	-1265851058584896373
0	265	70	265	71	-8582667996357628151	np.all([dataframe['passes_xs1single4']==1], axis=0)	265	21	265	72	2379678197450289064
0	268	40	268	41	-90748428228459469	np.mean( X_train, axis = 0)	268	15	268	42	-830787543426822384
0	269	38	269	39	4450754800350303217	np.std( X_train, axis = 0)	269	14	269	40	5826357392361991043
0	270	15	270	16	-1136689875945231874	plt.legend(loc=0)	270	0	270	17	-1349474610485734029
0	271	62	271	63	5688456288007315120	np.all([dataframe['s1_width'] > 26], axis=0)	271	20	271	64	-8619235459341012388
0	273	72	273	73	-5083431121275920739	patches.PathPatch(_path, fill=True, color=color, linewidth=0, alpha=.3)	273	13	273	84	7942106266842694554
0	274	73	274	74	5950183391931950163	gamma.fit(top_offenses.G60, floc=0)	274	40	274	75	2078908890148305221
0	275	71	275	72	7214766030795060962	np.all([dataframe['s2_area_fraction_top'] > 0], axis=0)	275	18	275	73	8097762241356799734
0	277	63	277	64	4957102537363916011	m.scatter(x,y,c=np.array(color),marker='.', lw=0, alpha=alpha)	277	16	277	78	8857175617892696937
0	279	57	279	58	3148224241919657349	np.all([dataframe['s2'] > 150], axis=0)	279	20	279	59	-7105561312610450299
0	280	95	280	96	4846556390338109776	ax2.scatter(reduced_data['Dimension 1'], reduced_data['Dimension 2'], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	280	4	281	25	4793996401955718291
0	283	65	283	66	-8716444106225810254	np.all([dataframe['largest_veto'] < 0.35], axis=0)	283	17	283	67	2014270231231373764
0	285	14	285	15	-8154595109804940797	plt.axhline(y=0,linestyle='--',color='gray')	285	0	285	44	6612270392940564622
0	287	115	287	116	-2234646296019317842	np.all([dataframe['posrec_goodness_of_fit']/(dataframe['s2_top_coincidence']-1) < 7], axis=0)	287	24	287	117	5245801527061994110
0	290	39	290	40	3047211248187367996	assign_trace.mean(axis=0)	290	16	290	41	-2367296100298842902
0	291	33	291	34	7879065101830027767	assign_trace.mean(axis=0)	291	10	291	35	3326152709966579462
0	291	103	291	104	-4813261919943798976	np.nanmean((data_pert.GAD['ADVx_TH'] - data_diff.GAD['ADVx_TH'])[t,:,0:192,0:210],axis=0)	291	16	291	105	-7849809357888306121
0	291	133	291	134	-9147075877477080512	np.all([(2*dataframe['s2_area_fraction_top'])-1 > -0.2, (2*dataframe['s2_area_fraction_top'])-1 < 0.25], axis=0)	291	23	291	135	-5611153666123870555
0	292	14	292	15	1193907598354094694	ax.legend([dealer[2013][0],\n            dealer[2014][0],\n            dealer[2015][0],\n            dealer[2016][0],\n            private[2013][0],\n            private[2014][0],\n            private[2015][0],\n            private[2016][0]],\n           ['2013 from Dealer',\n            '2014 from Dealer',\n            '2015 from Dealer',\n            '2016 from Dealer',\n            '2013 from Private Party',\n            '2014 from Private Party',\n            '2015 from Private Party',\n            '2016 from Private Party'],\n          fontsize=textheight,\n          loc=0)	275	0	292	16	5568863873990761064
0	292	14	292	15	4638626099328082401	plt.axhline(y=0,linestyle='--',color='gray')	292	0	292	44	3651635727794504439
0	292	29	292	30	-8750737785811405362	np.cov(new_dat, rowvar=0)	292	6	292	31	-6061584791225818620
0	292	104	292	105	-8050449712493925555	np.nanmean((data_pert.GAD['ADVy_TH'] - data_diff.GAD['ADVy_TH'])[t,:,0:192,0:210],axis=0)	292	17	292	106	-398204369951831307
0	294	56	294	57	-2989616907928808043	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	294	8	294	67	5873897550386037069
0	294	65	294	66	5373645074985561678	smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)	294	8	294	67	5873897550386037069
0	295	17	295	18	-6178624219398459126	AdaBoostClassifier(base_estimator=None,\n    n_estimators=100,\n    learning_rate=1.0,\n    algorithm='SAMME.R',\n    random_state=0)	291	6	295	19	3879847835911676645
0	295	81	295	82	-6896337264860990337	np.all([dataframe['s2_area_midpoint']/1000.0 > 178], axis=0)	295	23	295	83	3098404680249418302
0	296	18	296	19	-6229150637960326272	plt.axhline(y=0, color='r')	296	4	296	31	-5482986403716416681
0	300	91	300	92	2145681077984604311	np.all([np.log10(dataframe['cs2bottom']/dataframe['cs1']) < 3.1], axis=0)	300	20	300	93	5324322553156445593
0	302	30	302	31	8475422003659653091	display.plot_ppi('RhoHV',vmin=0,vmax=1)	302	0	302	39	-7308457324732210457
0	302	48	302	49	-2121573591677503416	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	301	23	302	74	1050147934945543584
0	304	14	304	15	7685752587725586740	plt.ylim(ymin=0)	304	0	304	16	-3234258199947035334
0	304	48	304	49	8890070201523506517	center_trace.mean(axis=0)	304	25	304	50	4564651856496665886
0	305	42	305	43	8870431778288059937	std_trace.mean(axis=0)	305	22	305	44	3692919906612621061
0	305	59	305	60	1606377894976952280	np.all([dataframe['posdiff'] < 7], axis=0)	305	19	305	61	3477917152895372970
0	306	17	306	18	-3766518182140445493	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	305	9	307	37	-4441842696448961912
0	306	31	306	32	2691888307016028754	display.plot_ppi('uPhiDP',vmin=0,vmax=360)	306	0	306	42	-1274873083979653313
0	308	29	308	30	5208460913103713872	x_c.mean(axis=0)	308	15	308	31	-1970748190227058079
0	308	34	308	35	700207877281976877	display1.plot_ppi('stdPhiDP',vmin=0,vmax=200)	308	0	308	45	-4634317673501684318
0	309	357	309	358	6405148469693822499	np.all([np.log10(dataframe['area_tot']) > 0, np.log10((dataframe['s1']+dataframe['s2'])/np.maximum(dataframe['area_tot']-(dataframe['s1']+dataframe['s2']),0.00001)) > np.maximum(np.minimum(0.284*np.power(np.log10(dataframe['s2']),3)-2.81*np.power(np.log10(dataframe['s2']),2)+10.1*np.log10(dataframe['s2'])-12.3,1.0),0.0)], axis=0)	309	28	309	359	6516180536406604909
0	310	36	310	37	-3521362434463383378	lfmm_assess.sum(axis = 0)	310	13	310	38	-2200449405085716438
0	312	64	312	65	-3300260433679374746	nouns_sparse_matrix_final.sum(axis=0)	312	29	312	66	3575085865246179963
0	313	25	313	26	-1980642556051662471	vae.fit(S, S,\n        shuffle=True,\n        epochs=10000,\n        batch_size=batch_size,\n        validation_split=0, verbose=False)	309	0	313	42	191792115908829916
0	314	920	314	921	-7943703236786791849	np.all([(dataframe['s2_width']/10. < ((5.246563e+00 + (1.048045e+04 - 5.246563e+00)/(1.0 + np.exp(9.375352e-01*(np.log10(dataframe['s2']) + 6.034534e-01)))) + ((3.222950e-01 - 6.061705e-02*(np.log10(dataframe['s2']) - 7.219447e+00)**2)/(1.0 + np.exp(-6.980844e+00*(np.log10(dataframe['s2'])-np.log10(200)))) + (0.178816605647 - (3.222950e-01 - 6.061705e-02*(np.log10(dataframe['s2']) - 7.219447e+00)**2)/(1.0 + np.exp(-6.980844e+00*(np.log10(dataframe['s2'])-np.log10(200)))))/(1.0 + np.exp(-3.490422e+00*(np.log10(dataframe['s2'])-7.219447e+00))))*(dataframe['drift_time']/1000.))), (dataframe['s2_width']/10. > ((-3.989964e+01 + (-3.744929e+00 + 3.989964e+01)/(1.0 + np.exp(-9.570615e-01*(np.log10(dataframe['s2'])-5.419056e+00)))) + (-1.452032e+01 + (-8.802433e-02 + 1.452032e+01)/(1.0 + np.exp(-5.609087e-01*(np.log10(dataframe['s2']) + 2.261099e+00))))*(dataframe['drift_time']/1000.))) ], axis=0)	314	20	314	922	6875219828568654314
0	319	28	319	29	-2590735120121125911	p_t.mean(axis=0)	319	14	319	30	-7000765980223963930
0	320	24	320	25	8390149418041235612	lfmm_assess.sum(axis = 0)	320	1	320	26	5060766471516976944
0	320	43	320	44	5611928687043026822	Td.mapMatrices([DDD[k] for k in range(len(DDD))], lTitl=range(len(DDD)),\n               fs=(13,15), ncl=(4,3), vmin=0, vmax=1, cmap="seismic", cbar=1)	319	0	320	77	-1927851544002136358
0	320	64	320	65	3071322542411341987	lfmm_assess.sum(axis = 0)	320	41	320	66	1369758307826002013
0	321	517	321	518	-7881325127916180602	np.all([dataframe['s2_width']/10. > 1.00022*100-1.09687/100.*(dataframe['drift_time']/1000.)+9.73935/1000.*(dataframe['drift_time']/1000.)**2-6.45108/100000.*(dataframe['drift_time']/1000.)**3+1.41045/10000000.*(dataframe['drift_time']/1000.)**4, dataframe['s2_width']/10. < 1.22744*100+1.03964*(dataframe['drift_time']/1000.)-1.49149/1000.*(dataframe['drift_time']/1000.)**2-4.39044/10000000.*(dataframe['drift_time']/1000.)**3+7.96577/1000000000.*(dataframe['drift_time']/1000.)**4], axis=0)	321	26	321	519	-3320160155786387195
0	326	29	326	30	-2090285491687238912	Tk.Radiobutton(kernel_group, text="Linear", variable=controller.kernel,\n                       value=0, command=controller.refit)	325	8	326	57	-6786582601531914669
0	326	51	326	52	5280972794153275949	np.all([dataframe['cs1'] > 0], axis=0)	326	15	326	53	6977445425605019141
0	326	91	326	92	-8475597578753546705	predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)	326	24	326	93	9105438506696990582
0	330	110	330	111	5800783881046573669	np.all([(dataframe['largest_other_s2'])/(dataframe['s2']) < 0.001], axis=0)	330	37	330	112	-6419185354651325462
0	332	33	332	34	189018636539234687	Td.triToMat(512, tri=0)	332	12	332	35	4749626502693696517
0	334	96	334	97	-7686902227603138198	np.all([np.log10(dataframe['largest_other_s2']) < 4], axis=0)	334	37	334	98	3266195349255516534
0	335	29	335	30	9149200570361823191	data.rank(axis=0, pct=True)	335	14	335	41	-4383993078324665353
0	338	85	338	86	2449086072664232849	np.nanmean((data_pert.data['S'] - data_diff.data['S'])[t,:,:,:],axis=0)	338	16	338	87	-1191957001209452061
0	338	94	338	95	6230180547838046203	np.all([(dataframe['largest_other_s1'])/(dataframe['cs1']) < 0.01], axis=0)	338	21	338	96	-7813358897699093841
0	339	13	339	14	-3327033418159501844	arr.sum(axis=0)	339	0	339	15	8493843768463034626
0	339	28	339	29	9137044888376412513	p_t.mean(axis=0)	339	14	339	30	2663437416193452057
0	340	42	340	43	8392711059416529292	mquantiles(p_t, [0.025, 0.975], axis=0)	340	5	340	44	7993095609609981809
0	341	58	341	59	-7109116223468731989	np.all([-dataframe['z'] < tpc_length], axis=0)	341	14	341	60	-4889362600286096830
0	343	36	343	37	2979358432508880529	pd.read_html(html_text,header=0)	343	6	343	38	-5918913084895621754
0	345	23	345	24	3407131569054004577	ax.set_ylim(bottom=0)	345	4	345	25	-6175996251085005968
0	345	69	345	70	-414977106079987987	np.all([dataframe['s2_width'] < 5000], axis = 0)	345	23	345	71	-3652977594115850236
0	349	15	349	16	8872590379581746116	plt.hlines(y = 0, xmin=0, xmax = 50)	349	0	349	36	-6257640178602341443
0	349	20	349	21	-8239281472360906062	arr.mean(axis=0)	349	6	349	22	387963530347062053
0	349	23	349	24	-6671230966097689861	plt.hlines(y = 0, xmin=0, xmax = 50)	349	0	349	36	-6257640178602341443
0	349	182	349	183	-156048958969569752	np.all([(0.1 * tpc_length < -dataframe['z']), (0.9 * tpc_length > -dataframe['z']), (dataframe['x']**2 + dataframe['y']**2)**0.5 < tpc_radius * 0.67], axis=0)	349	26	349	184	8513767603148007833
0	353	247	353	248	-4047305937899650522	np.all([(0.1 * tpc_length < -dataframe['z']), (0.9 * tpc_length > -dataframe['z']), (dataframe['x']**2 + dataframe['y']**2)**0.5 < tpc_radius * 0.95, (dataframe['x']**2 + dataframe['y']**2)**0.5 > tpc_radius * 0.8], axis=0)	353	26	353	249	-3993114572615816127
0	354	69	354	70	-8589851157173570536	svm.SVC(kernel='linear', probability=True, random_state=0)	354	13	354	71	-2962608603322769895
0	355	36	355	37	3030474000752756536	pd.read_html(html_text,header=0)	355	6	355	38	-7472779673264430961
0	356	15	356	16	-1230329002334680986	plt.legend(loc=0)	356	0	356	17	-4853459283981579482
0	357	193	357	194	8702097344020628053	np.all([(0.1 * tpc_length < -dataframe['z']), (0.9 * tpc_length > -dataframe['z']), (dataframe['x']**2 + dataframe['y']**2)**0.5 < tpc_radius * 0.95], axis=0)	357	37	357	195	2468592498615103940
0	365	53	365	54	4071887688578167881	plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=255, cmap="gray")	365	8	365	78	4707507146001975366
0	366	63	366	64	6519391573453825210	Tk.Radiobutton(cmap_group, text="Hyperplanes",\n                       variable=controller.surface_type, value=0,\n                       command=controller.refit)	365	8	367	48	4204428375612544659
0	368	351	368	352	-4233380224749287996	np.all([(dataframe['s2_width']/10. < (141.21619 + 16.205825 * np.power((dataframe['drift_time']/1000.),0.5) - 0.35909207 * np.power((dataframe['drift_time']/1000.),1.0) + 0.0020441952 * np.power((dataframe['drift_time']/1000.),2.0)), dataframe['s2_width']/10. > (67.0 + 11.0 * np.log10((dataframe['drift_time']/1000.))))], axis=0)	368	23	368	353	278458342295848648
0	370	58	370	59	978315891523354865	plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=255, cmap="gray")	370	8	370	83	6852027473834083322
0	373	48	373	49	-7634531363559484281	decision_tree_create(train_data, features, 'safe_loans', max_depth = 2,\n                                min_node_size = 0, min_error_reduction=-1)	372	10	373	74	-1270068233323247426
0	375	48	375	49	-1962717262715739874	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	374	10	375	74	-7955337623711844079
0	377	48	377	49	5192217454835011015	decision_tree_create(train_data, features, 'safe_loans', max_depth = 14,\n                                min_node_size = 0, min_error_reduction=-1)	376	10	377	74	-8440472025689625761
0	379	80	379	81	3427933039747616050	np.concatenate((norm128_X_train, [new_img]), axis=0)	379	30	379	82	-7765924171851474106
0	380	64	380	65	1705441577133425357	np.concatenate((y_train, [class_n]), axis=0)	380	22	380	66	8792610514600970468
0	388	91	388	92	-5871628178258881120	predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)	388	24	388	93	-1910403474197192727
0	392	18	392	19	-2850762383060416007	np.sort(arr, axis=0)	392	0	392	20	-1878778039145263177
0	398	33	398	34	-7920654308695968518	np.random.normal(loc=0, scale=1, size=(num_samples, latent_dim))	398	12	398	76	-5962730334803913938
0	403	43	403	44	4483565329912677066	plt.imshow(x_gen.reshape(28, 28), vmin=0, vmax=1, cmap="gray")	403	4	403	66	-6570058676893075456
0	407	32	407	33	372806279101542692	pymc.Normal('alpha', mu=0, tau=.01)	407	8	407	43	70706318919953977
0	407	55	407	56	157589580648809130	ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	407	4	408	25	-7141654245981384788
0	408	30	408	31	1876396649637858217	pymc.Normal('beta', mu=0, tau=.01)	408	7	408	41	1150926310980712369
0	410	23	410	24	-4651428670014311134	plt.imshow(img, zorder=0, extent=[-1300, 72000, -24000, 41000])	410	0	410	63	-8484665634726859232
0	412	48	412	49	2296765788670135608	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	411	10	412	74	-5003792675163524159
0	414	48	414	49	5057153654866839791	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=0)	413	10	414	73	1900755815827259209
0	414	71	414	72	-2082756779936071827	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=0)	413	10	414	73	1900755815827259209
0	415	63	415	64	1285606158227638033	nouns_adj_sparse_matrix.sum(axis=0)	415	30	415	65	105201878389522968
0	416	48	416	49	-2983611211796056809	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=5)	415	10	416	73	2702664891864765545
0	419	62	419	63	-2840624524554352861	manifold.TSNE(n_components=2, init='pca', random_state=0, method = 'exact')	419	7	419	82	102417139704355305
0	419	94	419	95	-8889738423600735038	np.concatenate((X_train_normalized,[train_new_image]),axis = 0)	419	33	419	96	-3059255857735766711
0	420	48	420	49	5351616069794196750	RandomForestClassifier(max_depth = None,\n                                 class_weight = 'balanced',\n                                 min_samples_split = 2,\n                                 n_estimators = 1000,\n                                 max_features = int(np.sqrt(X_train.shape[1])),\n                                 random_state = 0,\n                                 n_jobs = -1, # to parallelize jobs across all processors\n                                 oob_score = True)	415	11	422	50	3624182513612562906
0	420	55	420	56	-5584056849424628657	ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	420	4	421	25	6988696462127109826
0	420	61	420	62	-4137312589577673993	np.concatenate((y_train,[cls]), axis = 0)	420	22	420	63	2497456969416784826
0	421	11	421	12	-4029720475961154403	g.set(xlim=0)	421	0	421	13	6661183310635996040
0	423	70	423	71	-6676319920867879006	np.percentile(samples[:,0], [15.84, 50, 84.16], axis=0)	423	17	423	72	-4904454509711384773
0	425	24	425	25	-3468141286688189166	plt.imshow(im, vmin=0, vmax=255, cmap="gray")	425	4	425	49	-6725333441163896584
0	428	70	428	71	5504088018179480924	np.percentile(samples[:,1], [15.84, 50, 84.16], axis=0)	428	17	428	72	1746356870513172037
0	429	11	429	12	-4064296529034377049	g.set(xlim=0)	429	0	429	13	-4119976318288120276
0	430	23	430	24	4206550240192341440	ax.set_ylim(bottom=0)	430	4	430	25	-5287744674312379131
0	433	31	433	32	4121138177742906400	sns.heatmap(Kd_koff, vmin=0, vmax=41.6722040671)	433	5	433	53	3612251553751888633
0	433	69	433	70	21762283451040388	np.percentile(samples[:,2],[15.84, 50, 84.16], axis=0)	433	17	433	71	6396821696921400457
0	433	79	433	80	8098615705920131952	nouns_adj_trigram_sparse_matrix.sum(axis=0)	433	38	433	81	2864468463181456497
0	435	36	435	37	831034408099876254	ax.set_xticklabels(xticks, rotation=0)	435	0	435	38	6902878628684267063
0	437	36	437	37	-2800745060773223942	ax.set_yticklabels(yticks, rotation=0)	437	0	437	38	2532446927411340742
0	438	69	438	70	5992708905447636303	np.percentile(samples[:,3],[15.84, 50, 84.16], axis=0)	438	17	438	71	-1775203438785904691
0	439	48	439	49	228421598690382418	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	438	10	439	74	-1611280358084874290
0	439	94	439	95	8201835900972993322	np.concatenate((X_valid_normalized,[valid_new_image]),axis = 0)	439	33	439	96	-2628319965565005662
0	440	61	440	62	2163286321542328347	np.concatenate((y_valid,[cls]), axis = 0)	440	22	440	63	-2987416313037765959
0	448	21	448	22	8245019298487671630	np.mean(X, axis=0)	448	5	448	23	-110065372039474238
0	449	20	449	21	-3197187462185834198	np.std(X, axis=0)	449	5	449	22	-6999845481393541948
0	449	33	449	34	-1310271694156983717	plt.imshow(spectra_out[:,:],vmin=0,vmax=1e-8)	449	0	449	45	7911636859343948117
0	454	70	454	71	-4294892625916445823	np.percentile(samples[:,0], [15.84, 50, 84.16], axis=0)	454	17	454	72	-8415626978852881850
0	457	101	457	102	-7367851710837969696	plt.scatter(water['Porosity'], water['Normalized strength (compression)'], s=water['Pore width'], lw=0, alpha=0.3, color='#3778bf')	457	0	457	131	-7280523206196135057
0	458	18	458	19	7084402981703018962	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,\n        linewidth=0, antialiased=False)	457	7	458	39	4002728354256283703
0	459	70	459	71	8440063904189924225	np.percentile(samples[:,1], [15.84, 50, 84.16], axis=0)	459	17	459	72	-4559342355089123021
0	464	69	464	70	8641411509688835521	np.percentile(samples[:,2],[15.84, 50, 84.16], axis=0)	464	17	464	71	-1893095248832248612
0	466	65	466	66	5079332275518906748	df_arrests.plot.scatter(x='RDI', y='PER_STDT_TOTAL_ARREST', ylim=0)	466	0	466	67	-3290122982183678473
0	466	110	466	111	2754883159831045532	plt.scatter(camphene['Porosity'], camphene['Normalized strength (compression)'], s=camphene['Pore width'], lw=0, alpha=0.3, color='#3778bf')	466	0	466	140	-8559213888801532122
0	467	64	467	65	6544117615263332859	df_arrests.plot.scatter(x='RDI', y='PER_STDT_DRUG_ARREST', ylim=0)	467	0	467	66	-6815124027011765764
0	468	66	468	67	2034493931336064097	df_arrests.plot.scatter(x='RDI', y='PER_STDT_WEAPON_ARREST', ylim=0)	468	0	468	68	-3374653387330444344
0	469	63	469	64	7020869106639313800	df_arrests.plot.scatter(x='RDI', y='PER_STDT_LIQ_ARREST', ylim=0)	469	0	469	65	3596441791343759559
0	469	69	469	70	5268081792025832284	np.percentile(samples[:,3],[15.84, 50, 84.16], axis=0)	469	17	469	71	5336006624127226581
0	476	95	476	96	-7936886675228263437	plt.scatter(tba['Porosity'], tba['Normalized strength (compression)'], s=tba['Pore width'], lw=0, alpha=0.3, color='#3778bf')	476	0	476	125	-8943320836896900632
0	478	69	478	70	-7826849420032471802	df_arrests_pub.plot.scatter(x='RDI', y='PER_STDT_TOTAL_ARREST', ylim=0)	478	0	478	71	64249563763481725
0	479	68	479	69	8250735478516367872	df_arrests_pub.plot.scatter(x='RDI', y='PER_STDT_DRUG_ARREST', ylim=0)	479	0	479	70	2050893804199272492
0	480	70	480	71	-8888888072944107601	df_arrests_pub.plot.scatter(x='RDI', y='PER_STDT_WEAPON_ARREST', ylim=0)	480	0	480	72	-7196766185346823609
0	481	67	481	68	8153943022629087851	df_arrests_pub.plot.scatter(x='RDI', y='PER_STDT_LIQ_ARREST', ylim=0)	481	0	481	69	6881282395181392837
0	484	70	484	71	8386099007698573292	np.percentile(samples[:,0], [15.84, 50, 84.16], axis=0)	484	17	484	72	-2981793303971635041
0	484	83	484	84	8547288726833515123	beta.fit(top_offenses.ShP, floc=0, fscale=1)	484	51	484	95	6171820234266495213
0	489	70	489	71	-8885844467207137619	np.percentile(samples[:,1], [15.84, 50, 84.16], axis=0)	489	17	489	72	-4912267425119565834
0	491	30	491	31	-3281208664276746768	pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90,\n                       hspace=.35)	491	4	492	34	5221918855748501125
0	491	72	491	73	-1445545774414471772	ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=12, rotation=0)	491	4	491	74	-715771006684953716
0	492	111	492	112	2583162650399157221	get_images('train/digitStruct_train.csv', './train/', height=54, width=54, crop=0)	492	31	492	113	4949278090222586280
0	493	22	493	23	-933044896998319083	Basemap(projection='robin', resolution='l',area_thresh = 1000.0,\n                lat_0=0, lon_0=120)	492	9	493	35	8711651054332721735
0	493	107	493	108	-7291777673583676609	get_images('test/digitStruct_test.csv', './test/', height=54, width=54, crop=0)	493	30	493	109	7140907702625357988
0	494	69	494	70	5411548075388458344	np.percentile(samples[:,2],[15.84, 50, 84.16], axis=0)	494	17	494	71	-3821260959875292203
0	496	76	496	77	4796893499622191933	ax.plot_surface(X,Y,Z, rstride = 1,cstride=1, cmap=cm.jet, linewidth=0, antialiased=False)	496	7	496	97	-705707174207070820
0	497	39	497	40	4553223319956701271	np.mean(z_mu[idx], axis=0)	497	15	497	41	-8397344051974393005
0	499	69	499	70	-2041379088971053121	np.percentile(samples[:,3],[15.84, 50, 84.16], axis=0)	499	17	499	71	-5637039313818147846
0	504	72	504	73	5748728578652403133	ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14, rotation=0)	504	4	504	74	-2470977207986212554
0	509	23	509	24	-5827941315373133701	plt.imshow(img, zorder=0, extent=[-1300, 72000, -24000, 41000])	509	0	509	63	-8573976016433596140
0	513	55	513	56	7450414484104704649	ax.plot_surface(x,y,V,rstride=1,cstride=1,linewidth=0, cmap=cm.coolwarm)	513	3	513	75	-2205950612627632955
0	518	28	518	29	-1358321266596195247	p_t.mean(axis=0)	518	14	518	30	3478486263910871184
0	519	42	519	43	-4992216226939154367	mquantiles(p_t, [0.025, 0.975], axis=0)	519	5	519	44	7975314875905159595
0	533	22	533	23	-7247788818255726914	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
0	534	40	534	41	8593372617070859700	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
0	547	25	547	26	-7020409775737484330	f.subplots_adjust(hspace=0)	547	0	547	27	7038840923822448657
0	547	52	547	53	-290476639106474274	np.expand_dims( X_resized[0,:,:,:], axis = 0)	547	9	547	54	-3125530353294349106
0	550	24	550	25	7595383113255593793	plt.imshow(im, vmin=0, vmax=255, cmap="gray")	550	4	550	49	8707142656364543840
0	554	23	554	24	-3542672967359204219	ax.set_ylim(bottom=0)	554	4	554	25	7792728153418948826
0	557	61	557	62	8081701010075212050	ax.plot_surface(X, Y, Z, rstride=4, cstride=4, linewidth=0)	557	4	557	63	-3944673553284533801
0	558	39	558	40	9059745834543340796	ax.scatter(x[:,0], x[:,1], lw=0, s=40)	558	9	558	47	701772488629378913
0	562	29	562	30	-8243476418232437314	ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n                   linewidth=0, antialiased=False)	561	4	562	50	-3843361364894442248
0	565	68	565	69	8567852258209178892	pd.read_csv("qqdata.csv", delimiter=",", encoding=None, header=0)	565	5	565	70	6900424629004614305
0	686	14	686	15	2036953166256328614	ax.legend(loc=0)	686	0	686	16	1721637717123946149
0	715	28	715	29	1718376481093677840	p_t.mean(axis=0)	715	14	715	30	-4027364088166986217
0	716	42	716	43	-6979165676296053896	mquantiles(p_t, [0.025, 0.975], axis=0)	716	5	716	44	-972769799147766812
0	784	64	784	65	-6972975240623397039	np.nansum((1 - data[:,:,:]/34.8)*depth,axis=0)	784	20	784	66	-7413373635069745116
0	784	114	784	115	-7804460864772344925	np.nansum((1 - data1[:,:,:]/34.8)*depth,axis=0)	784	69	784	116	6691732868697410283
0	791	51	791	52	1778799542957924164	np.argmax(lda.components_, axis=0)	791	19	791	53	6402387461208669208
0	794	64	794	65	5279123396928556456	np.nansum((1 - data[:,:,:]/34.8)*depth,axis=0)	794	20	794	66	-1585238184922368959
0	794	114	794	115	4000673059299479119	np.nansum((1 - data1[:,:,:]/34.8)*depth,axis=0)	794	69	794	116	7353991600306181304
0	795	51	795	52	-4566046381435217707	np.argmax(nmf.components_, axis=0)	795	19	795	53	7178141200332902713
0	801	35	801	36	-6969080386588286212	fig.savefig(fileName, transparent=True, bbox_inches='tight', \\n                        pad_inches=0)	800	4	801	37	851934439035322189
0	817	47	817	48	833080500160531404	np.argmax(lda.components_, axis=0)	817	15	817	49	721105843926375877
0	838	73	838	74	-8592844712879703535	np.nansum((1 - data[0:29,:,:]/34.8)*depth[0:29,:,:],axis=0)	838	16	838	75	-2422365663397606735
0	839	74	839	75	-2459773497260703915	np.nansum((1 - data1[0:29,:,:]/34.8)*depth[0:29,:,:],axis=0)	839	16	839	76	1247111527796118497
0	852	47	852	48	2514812780085201430	np.argmax(nmf.components_, axis=0)	852	15	852	49	8416210480374072884
0	885	62	885	63	-4347531732174097354	np.nansum((1 - data[t,:,:,:]/34.8)*depth,axis=0)	885	16	885	64	-8005980349480067848
0	889	78	889	79	-4555757547634720504	minmax_scale(pred['nn_pred'], feature_range=(low,high),axis = 0, copy = True)	889	16	889	93	3197585063005909496
0	928	75	928	76	-1306517869978413460	np.nansum((1 - data[t,0:29,:,:]/34.8)*depth[0:29,:,:],axis=0)	928	16	928	77	4295086325440995969
0	946	28	946	29	8346860868501333932	p_t.mean(axis=0)	946	14	946	30	8530120085072261057
0	947	42	947	43	-7981166358654347419	mquantiles(p_t, [0.025, 0.975], axis=0)	947	5	947	44	8736890369705588320
0	991	49	991	50	-6504254535737395989	np.argmax(nmf.components_, axis=0)	991	17	991	51	-7032423046290490733
0	995	49	995	50	848312149868105673	np.argmax(lda.components_, axis=0)	995	17	995	51	-8160477309009629586
0	999	63	999	64	-689187957004962300	np.sum(cnf_matrix, axis=0)	999	39	999	65	991507734058288785
0	1132	31	1132	32	245982101728925339	np.take(X, index, axis=0)	1132	8	1132	33	4957370313672014062
0	1224	28	1224	29	-1675639819488258807	p_t.mean(axis=0)	1224	14	1224	30	-4632889645201970043
0	1225	42	1225	43	8578365755509834736	mquantiles(p_t, [0.025, 0.975], axis=0)	1225	5	1225	44	-7301375196771847145
0	1324	91	1324	92	5319851264230887012	interact(pert_const.ptracers['nordicseas_50m'][:,:,:,:],matplotlib.cm.hot,-1,0,0,100,time1=0,time2=50)	1324	0	1324	102	-4325125842083220493
0	1342	83	1342	84	7052745174314284154	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=0)	1342	35	1342	85	1888519599904717771
0	1343	97	1343	98	-415773520252175759	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=0)	1343	49	1343	99	-6599295351029931868
0	1432	65	1432	66	5331288591689781555	np.nanmean(diff[t,:,:,:],axis=0)	1432	35	1432	67	-2670103552076210423
0	1433	97	1433	98	2292804112966943442	np.nanmean(data.ptracers[ptracer][t,:,:,:],axis=0)	1433	49	1433	99	7333616367749707142
0	1733	43	1733	44	1143650309578131823	set_avg_params(['model_merged_1_best.pkl'],\n               model_merged_2, layer_start=0)	1732	0	1733	45	-686108965530940883
6	23	38	23	39	196850854366746486	datasets.load_digits(n_class=6)	23	9	23	40	8187741145939022407
6	31	19	31	20	-863618463664221702	self.plot.circle(\n            x = [],\n            y = [],\n            size = 6,\n            color = "navy",\n            alpha = 0.5,\n            name = "scatter"\n        )	28	8	35	9	-247369326692845166
6	45	60	45	61	1759667855059260100	sns.pairplot(train,hue='Cover_Type',x_vars='Elevation',size=6,y_vars='Horizontal_Distance_To_Roadways')	45	0	45	103	-8131177038993023762
6	51	57	51	58	-6194586680240455573	sns.pairplot(train,hue='Cover_Type',x_vars='Aspect',size=6,y_vars='Hillshade_9am')	51	0	51	82	-6772391356699539734
6	55	46	55	47	1154574804501804418	np.linspace(0,2*np.pi,endpoint=False, num=6)	55	4	55	48	-5149716788005976132
6	57	43	57	44	-7715032549598448144	mann_only_interactive(data, cut1, cut2,\n                                        chrs_plot=[str(i) for i in range(1,23)],\n                                        ms=6, # size of markers\n                                        color_sequence = colors, # any number of colors for M-plot\n                                       )	55	18	59	40	1132373210284945623
6	57	57	57	58	-2933258979663664059	sns.pairplot(train,hue='Cover_Type',x_vars='Aspect',size=6,y_vars='Hillshade_3pm')	57	0	57	82	-1972064688006609346
6	63	56	63	57	8234108831108184280	sns.pairplot(train,hue='Cover_Type',x_vars='Slope',size=6,y_vars='Hillshade_Noon')	63	0	63	82	5437446033658224659
6	69	81	69	82	-3068647462611412592	sns.pairplot(train,hue='Cover_Type',x_vars='Vertical_Distance_To_Hydrology',size=6,y_vars='Horizontal_Distance_To_Hydrology')	69	0	69	125	-2828335113641539257
6	75	64	75	65	-1232978116018764494	sns.pairplot(train,hue='Cover_Type',x_vars='Hillshade_3pm',size=6,y_vars='Hillshade_9am')	75	0	75	89	-8547551935735619657
6	81	64	81	65	8239534794886944278	sns.pairplot(train,hue='Cover_Type',x_vars='Hillshade_3pm',size=6,y_vars='Hillshade_Noon')	81	0	81	90	-5931761503101276940
6	82	38	82	39	-8396743377553459368	gridspec.GridSpec(nrows=2, ncols=6)	82	5	82	40	3299930594276570894
6	94	54	94	55	2297830846781196137	RandomForestRegressor(n_estimators=15, max_depth=6)	94	5	94	56	5545882175351523560
6	103	53	103	54	4813632618518902003	RandomForestRegressor(n_estimators=15,max_depth=6)	103	5	103	55	4028614024555475724
6	104	67	104	68	-1640659422611312638	my_display.plot_ppi('recalculated_diff_phase', tilt, vmin=-1, vmax=6)	104	0	104	69	-8194137636693805238
6	114	54	114	55	6269604643754318193	DecisionTreeRegressor(max_depth=6)	114	22	114	56	-699009213232243542
6	148	23	148	24	1353960081215837041	PCA(n_components=6)	148	6	148	25	-6390986412271606551
6	164	23	164	24	422349267919948604	PCA(n_components=6)	164	6	164	25	822790159220705036
6	188	52	188	53	-2173826567510263774	g.map_offdiag(sns.kdeplot, cmap="Blues_d", n_levels=6)	188	0	188	54	-6297939417292159213
6	195	23	195	24	-6631873955851439338	PCA(n_components=6)	195	6	195	25	3351272025059956126
6	199	23	199	24	2936338079885892866	PCA(n_components=6)	199	6	199	25	7923537573607019318
6	229	23	229	24	4604441909064096732	PCA(n_components=6)	229	6	229	25	-8232098094838166322
6	266	37	266	38	-7887533545695206685	mrds_map.plot(x, y, 'ro', markersize=6)	266	0	266	39	-5135078770740137950
6	295	92	295	93	-9013629547398989711	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 100, min_error_reduction=0.0)	295	23	296	77	7899162505430786056
6	301	92	301	93	8628085824155974193	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	301	23	302	74	1050147934945543584
6	326	37	326	38	2260474546427379485	mrds_map.plot(x, y, 'yo', markersize=6)	326	0	326	39	6175110758078016733
6	338	26	338	27	8354395691339491941	Tk.Entry(c, width=6, textvariable=controller.complexity)	338	8	338	64	8312617885979249523
6	346	26	346	27	8113558811772607753	Tk.Entry(g, width=6, textvariable=controller.gamma)	346	8	346	59	-3700736697684500738
6	346	37	346	38	-207221387646836764	mrds_map.plot(x, y, 'yo', markersize=6)	346	0	346	39	2878086740010272842
6	353	26	353	27	-7282464657633112100	Tk.Entry(d, width=6, textvariable=controller.degree)	353	8	353	60	6000324211799113066
6	360	26	360	27	5112759120921591769	Tk.Entry(r, width=6, textvariable=controller.coef0)	360	8	360	59	-1637889269055460898
6	374	79	374	80	5976951706955470372	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	374	10	375	74	-7955337623711844079
6	411	79	411	80	854783483648003903	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	411	10	412	74	-5003792675163524159
6	413	79	413	80	1346547664598079736	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=0)	413	10	414	73	1900755815827259209
6	415	79	415	80	-55373979088772647	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=5)	415	10	416	73	2702664891864765545
6	438	79	438	80	-467351699362272005	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=-1)	438	10	439	74	-1611280358084874290
6	440	32	440	33	7271020625050039851	plt.imshow(data['Lai_1km'],vmax=6)	440	0	440	34	6299816688498922507
6	440	79	440	80	-8690773481227221498	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 2000, min_error_reduction=-1)	440	10	441	77	6130476014748318774
6	442	79	442	80	3392999521429456005	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 50000, min_error_reduction=-1)	442	10	443	78	2101942890823207548
6	849	23	849	24	-4475404595374320737	NMF(n_components=6)	849	6	849	25	-8710983910116929984
5	15	44	15	45	7772651690369234223	stats.uniform.pdf( x,loc=0, scale = 5)	15	8	15	46	-7235083382690971715
5	16	44	16	45	-3092440826805462101	stats.uniform.pdf(x, loc=0, scale = 5)	16	8	16	46	367723389087243007
5	17	56	17	57	-2451656938995583913	ax.axvline(measured_diff, color='k', linestyle='--', lw=5)	17	0	17	58	769110454371584567
5	31	55	31	56	7344555753870937324	pd.period_range(start=tf.start, periods=5, freq='D')	31	15	31	67	368854995726922751
5	33	31	33	32	-2645508058501818276	plt.plot(x,y,'o', markersize = 5, color ='r')	33	0	33	45	8188892763820073459
5	33	43	33	44	-1368362275549087058	SimplePolicyNetwork(hidden_dim=5,reg=0)	33	12	33	51	9190507902451454594
5	33	88	33	89	-2140839295159229565	cross_validation.cross_val_score(logreg,scale_alexnet,train_label,cv=5)	33	19	33	90	-6802934374977157811
5	34	31	34	32	-8536284941272537747	plt.plot(x,y,'^', markersize = 5, color ='b')	34	0	34	45	2794783279657761192
5	34	96	34	97	3491598130477281544	simpleBox(mode="pro_only",length=50000,block_size=30,random_range=0,trial_per_episode=5,\n                    repeat = True, reward_ratio = 5)	34	10	35	52	-6114426729519423264
5	35	50	35	51	7715850739590740988	simpleBox(mode="pro_only",length=50000,block_size=30,random_range=0,trial_per_episode=5,\n                    repeat = True, reward_ratio = 5)	34	10	35	52	-6114426729519423264
5	39	39	39	40	8563792197546528056	dict(algorithm=1, trees=5)	39	15	39	41	6497931345568479978
5	41	45	41	46	-7198557411573604822	gl.recommender.item_similarity_recommender.create(pus,\n                                  user_id="INDP",\n                                  item_id="FOD1P",\n                                  target="EMPScore",\n                                  only_top_k=5,\n                                  similarity_type="cosine")	37	12	42	59	8548964789021656178
5	44	38	44	39	-7641818671536434582	plt.plot(nvnums, 'ro', markersize=5)	44	4	44	40	-5648990631894079560
5	49	49	49	50	4228744170561232755	np.random.choice(['a', 'b', 'c', 'd', 'e'], size=5, replace=False)	49	0	49	66	7290729358944094725
5	52	16	52	17	546682341832605550	interact(h, p = 5, q = 20)	52	0	52	26	-2221540293840295087
5	52	56	52	57	-2009090882845781022	army.interpolate(method='linear', axis=1, limit=5, inplace=False, limit_direction='both')	52	8	52	97	-2516046408702769049
5	54	28	54	29	-5074514917944802537	tabla_SML['Edad'].hist(bins=5)	54	0	54	30	8266978379337397974
5	55	49	55	50	8247791967458078461	np.random.choice(['a', 'b', 'c', 'd', 'e'], size=5, replace=True)	55	0	55	65	6901423224409191221
5	57	16	57	17	589386970004917138	interact(h, p = 5, q = fixed(20))	57	0	57	33	-1538708063330051378
5	58	51	58	52	9018498038768572375	skimage.filters.threshold_adaptive(image,\n                                            block_size=block_size,\n                                            offset=5,\n                                            method='mean',\n                                            mode='reflect')	56	9	60	59	-2255375274570248220
5	62	27	62	28	6991584786729036354	KFold(y.size, n_folds=5, shuffle=True, random_state=241)	62	5	62	61	4943645416325930024
5	62	40	62	41	282110627611742239	FloatSlider(min=0, max=1000, step=5, value = 0)	62	6	62	53	-8305853719096747478
5	62	49	62	50	-6998559239129290696	np.random.choice(['a', 'b', 'c', 'd', 'e'], size=5, replace=True, p=[0.4, 0.15, 0.15, 0.15, 0.15])	62	0	62	98	4172682963766752899
5	62	72	62	73	4333034537593721122	widgets.IntSlider(min = -10, max = 20,step = 2, value = 5)	62	16	62	74	-3704810155526715517
5	66	37	66	38	-8402440106567266412	DecisionTreeClassifier(max_depth=5)	66	4	66	39	8101530815211825228
5	67	37	67	38	6425528816264612506	RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)	67	4	67	72	4944537880148559078
5	67	45	67	46	-1135992453313481808	gl.recommender.item_similarity_recommender.create(train,\n                                  user_id="INDP",\n                                  item_id="FOD1P",\n                                  target="EMPScore",\n                                  only_top_k=5,\n                                  similarity_type="cosine")	63	12	68	59	-6040945310541091631
5	70	49	70	50	1738527327641391346	sns.pairplot(kobe, vars = ['lat', 'lon'], size = 5, hue = 'shot_made_flag')	70	0	70	75	-262286717439949895
5	72	65	72	66	9144444495319165460	plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=5)	72	0	72	67	-5280543553864848522
5	72	99	72	100	1561239733924024320	RandomizedSearchCV(model, paramDistribution, cv=10, scoring = 'precision', n_iter = 5)	72	15	72	101	2314207138524811725
5	75	26	75	27	-2625636849325253261	recommend(item_id=13, num=5)	75	0	75	28	1125451643776759403
5	76	36	76	37	6579599469278279138	R.sample(10000, burn = 5000, thin = 5)	76	0	76	38	1046007465089263218
5	77	44	77	45	4216210168468559508	FunctionApproximator(n_out=1, n_hidden=5)	77	5	77	46	1645432426196939550
5	84	65	84	66	-5796648509067272641	plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=5)	84	0	84	67	-3636291771813569197
5	85	18	85	19	1593801488480536078	SLP(h_units=5)	85	6	85	20	7021497833687990701
5	85	74	85	75	4154036136170635328	cross_validation.cross_val_score(knn,scale_alexnet,train_label,cv=5)	85	8	85	76	5049426412246881620
5	86	44	86	45	-3579548187897944732	stats.uniform.pdf( x,loc=0, scale = 5)	86	8	86	46	-3877296495755511966
5	87	44	87	45	6666913641483879297	stats.uniform.pdf(x, loc=0, scale = 5)	87	8	87	46	-7018674264575432691
5	92	105	92	106	175976951664013141	plt.plot(target[:,0], quadratic.predict(target[:,0:1]), color='black',lw=5,label='quadratic',zorder=5)	92	32	92	134	2963148063021739545
5	92	132	92	133	-4702364791305776302	plt.plot(target[:,0], quadratic.predict(target[:,0:1]), color='black',lw=5,label='quadratic',zorder=5)	92	32	92	134	2963148063021739545
5	93	127	93	128	-4099564875535778724	plt.plot(0.5+0.5*target[:,0], quadratic.predict(0.5+0.5*target[:,0:1]), color='black',lw=5,label='covariate shift',zorder=5)	93	38	93	162	-2573468898286770013
5	93	160	93	161	-8092907042070297180	plt.plot(0.5+0.5*target[:,0], quadratic.predict(0.5+0.5*target[:,0:1]), color='black',lw=5,label='covariate shift',zorder=5)	93	38	93	162	-2573468898286770013
5	94	95	94	96	7055511864794085879	simpleBox(mode="alternative",length=10000,block_size=30,random_range=0,trial_per_episode=5, repeat = True)	94	6	94	112	-4980187008601103576
5	94	123	94	124	8936376588820233561	plt.plot(0.5+0.5*target[:,0], quadratic.predict(target[:,0:1]), color='black',lw=5,label='covariate observation shift',zorder=5)	94	42	94	170	-7996247277399003867
5	94	168	94	169	2526187428991846547	plt.plot(0.5+0.5*target[:,0], quadratic.predict(target[:,0:1]), color='black',lw=5,label='covariate observation shift',zorder=5)	94	42	94	170	-7996247277399003867
5	96	65	96	66	-2522002411059692761	plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=5)	96	0	96	67	-4790935008290728945
5	97	93	97	94	5901070504291364796	cross_validation.cross_val_score(rf,train_data[predictors],train_data['relevance'],cv=5,scoring='mean_squared_error')	97	7	97	124	-111904462975191914
5	98	47	98	48	-2308546277926557453	cross_validation.cross_val_score(clf, X, y, cv=5)	98	0	98	49	6873005345176152517
5	101	43	101	44	8425298079498545008	SimplePolicyNetwork(hidden_dim=5,reg=0)	101	12	101	51	2706081769804296807
5	103	38	103	39	7053522372093899973	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 1)	102	10	103	73	2934476473305307850
5	105	56	105	57	723981155252779920	cross_validation.cross_val_score(clf, X, y, cv=5)	105	9	105	58	-4236381200132825213
5	106	97	106	98	-7589287646298156940	cross_validation.cross_val_score(rf,train_data[c_predictors],train_data['relevance'],cv=5,scoring='mean_squared_error')	106	9	106	128	-4133715562371044991
5	112	69	112	70	3079155742937652539	find_skycomponents(cmodel, fwhm=1.0, threshold=10.0, npixels=5)	112	8	112	71	-1034589455593786718
5	115	100	115	101	1451620187756115699	cross_validation.cross_val_score(abr,train_data[c_predictors],train_data['relevance'],cv=5,scoring='mean_squared_error')	115	11	115	131	-8568119319253045461
5	121	43	121	44	-1732644369322145486	dict(algorithm=1, trees=5)	121	19	121	45	-1827464983025561200
5	121	49	121	50	-2186982451768949591	cross_validation.KFold(len(labels), n_folds=5, indices=True, shuffle=True)	121	5	121	79	-7583958561381847909
5	126	38	126	39	-8599779746851957319	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
5	126	39	126	40	-4110280362132112641	oe_read_records(example, offset=5, count=1000)	126	7	126	53	-8502894914820369070
5	142	49	142	50	15725414973143549	neighbors.KNeighborsClassifier(n_neighbors=5)	142	6	142	51	-3589628492661359523
5	144	43	144	44	7169738225100498556	SimplePolicyNetwork(hidden_dim=5,reg=0)	144	12	144	51	-4718273022800335828
5	146	34	146	35	-1777970338982932652	ax[0].plot(vx,vy,'k.',alpha=.1,ms=5)	146	0	146	36	7558651535047614760
5	146	38	146	39	-7238946202807703285	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 5)	145	10	146	73	-3269178071910035111
5	146	71	146	72	-4423391893987547854	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 5)	145	10	146	73	-3269178071910035111
5	156	53	156	54	-2522664902970516282	neighbors.KNeighborsClassifier(n_neighbors=5)	156	10	156	55	-2973006684556165943
5	159	19	159	20	-4023052410923128104	gl.model_parameter_search.create( (train,test),\n        gl.recommender.ranking_factorization_recommender.create,\n        params,\n        max_models=5,\n        environment=None)	156	6	160	25	-2017563368766688345
5	164	32	164	33	-8403186595379726706	plt.plot(t, beta.pdf(t,a,b), lw=5, alpha=0.6, label='x:beta')	164	0	164	61	-4227897665833091657
5	165	35	165	36	4548514533582568345	plt.plot(t, lognorm.pdf(t, sc), lw=5, alpha=0.6, label='y:lognormal')	165	0	165	69	1764349161538855692
5	165	36	165	37	2418509048786982958	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
5	170	56	170	57	8319556630347367106	kernel_mean_matching(test, train, kern='rbf', B=5)	170	8	170	58	4412534184697797074
5	173	43	173	44	2327989762386509172	plt.locator_params(axis = 'x', nbins = 5)	173	4	173	45	7951216299744014621
5	175	17	175	18	-1929922207487213753	plt.axvline(x=(sim_genotypes.mean(0)/ploidy).values,\n            lw = 5, alpha = .3, color = 'green', label ='sample freq')	174	0	175	70	-7694106782462319824
5	178	17	178	18	-7938523968514600424	plt.axvline(x=allele_freqs,\n            lw = 5, alpha = .3, color = 'red', label ='pop freq')	177	0	178	65	-2959785267365754258
5	178	43	178	44	5652934210358146646	plt.locator_params(axis = 'x', nbins = 5)	178	4	178	45	-8606899983206963655
5	178	78	178	79	7668104444113166631	find_skycomponents(targetimage, fwhm=1.0, threshold=10.0, npixels=5)	178	12	178	80	6654992291135554101
5	179	26	179	27	7166837106447963065	GridSearchCV(RandomForestClassifier(),\n                       {'n_estimators': [100, 200, 500, 800], 'max_depth': [2, 3, 4, 5]},\n                       cv=5)	177	10	179	28	-1742786838631100747
5	179	43	179	44	-8818051664848436383	plt.locator_params(axis = 'x', nbins = 5)	179	4	179	45	236596333682952200
5	180	62	180	63	-2707860768431753324	cross_val_score(clf,X,masaPlanetastt,cv=5)	180	22	180	64	-4678424003307265618
5	181	17	181	18	-96319315861274840	plt.axvline(x=(a1_sim_depth/ depth_df).mean().values,\n            lw = 5, alpha=0.3, color = 'orange', label = 'read freq')	180	0	181	69	-5259099080155779163
5	183	35	183	36	6825022660679149625	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	181	9	183	37	1022489683466815085
5	186	43	186	44	1087156754064111033	plt.locator_params(axis = 'x', nbins = 5)	186	4	186	45	-6946932743393027368
5	199	29	199	30	-2518764131188468436	genBlobs(centers=5)	199	12	199	31	-3824468618535122640
5	216	29	216	30	-2175771448926724236	KMeans(n_clusters = 5, random_state = 0,init='k-means++',max_iter = 100)	216	9	216	81	-93560221250628329
5	220	30	220	31	7596299824134054800	model_exp.recommend([8560], k=5)	220	0	220	32	-6014547336538227459
5	220	44	220	45	6375960965884246840	sns.PairGrid(skin.sample(1000), vars=["R", "G"],\n                 hue="skin", aspect=1, size=5)	219	4	220	46	40169509588374986
5	223	52	223	53	3681179550138295686	KMeans(init='random',n_clusters=Kcents, n_init=5, n_jobs=8)	223	5	223	64	9029266415401378686
5	225	30	225	31	-3308088096189108644	model_exp.recommend([1180], k=5)	225	0	225	32	-4243857275213594750
5	227	44	227	45	-3063116892741137954	sns.PairGrid(skin.sample(1000), vars=["R", "B"],\n                 hue="skin", aspect=1, size=5)	226	4	227	46	-8115653986764091663
5	230	30	230	31	672893703590380494	model_exp.recommend([2090], k=5)	230	0	230	32	7243025217384773755
5	230	49	230	50	-4680957470423193525	ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n                                       max_depth=5)	229	9	230	51	1279645807566090493
5	235	30	235	31	438141548902687036	model_exp.recommend([2090], k=5, exclude_known = False)	235	0	235	55	-2929901547435237347
5	236	44	236	45	-3416403205886846162	cross_val_score(pipe, X, y, cv=5, scoring = 'f1_macro')	236	13	236	68	-6004507893232486138
5	264	48	264	49	-2201860476002968347	L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))	264	14	264	100	6406586362364781811
5	266	49	266	50	-1108806064422086707	L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))	266	14	266	101	-5946685312802678040
5	307	35	307	36	-3213497542306147328	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	305	9	307	37	-4441842696448961912
5	308	51	308	52	3324601431908993423	skimage.filters.threshold_adaptive(cell,\n                                            block_size=block_size,\n                                            offset=5,\n                                            method='mean',\n                                            mode='reflect')	306	13	310	59	-6807189593609525633
5	320	57	320	58	4614274863843735787	cross_val_score(lr, x_train, y_train, cv=5, scoring='roc_auc')	320	16	320	78	2391950428672635691
5	336	62	336	63	-7891670284586974367	sph.velocity_image(s.g, vector_color="cyan", qty="temp",width=5,cmap="viridis",\n                   denoise=True,approximate_fast=True, show_cbar = True)	336	0	337	72	-8530617659338904453
5	338	64	338	65	-6892905824318188439	testClassifier(dataset='iris',split=0.7,doboost=False,boostiter=5,covdiag=True)	338	0	338	79	3374448394382396815
5	339	62	339	63	-2556084338339943100	plotBoundary(dataset='iris',split=0.7,doboost=False,boostiter=5,covdiag=True)	339	0	339	77	-3505742960214304855
5	364	35	364	36	3686439248324355616	ax.set_xlabel('KBJD', fontsize=5)	364	4	364	37	-2233817954271800034
5	374	55	374	56	4548331281624438540	Tk.Button(fm, text='Fit', width=5,\n                                 command=controller.fit)	374	23	375	56	3812384011861735000
5	378	42	378	43	4771726917905747568	Tk.Button(fm, text='Clear', width=5,\n                  command=controller.clear_data)	378	8	379	48	-7283049447028601628
5	384	31	384	32	-1664456463039162754	plt.plot(x, y, 'o', markersize=5, color='r')	384	0	384	44	7639034091213588013
5	391	49	391	50	-6712987841076362414	plt.plot(x, beta.pdf(x, a, b),          'r-', lw=5, alpha=0.6, label='beta pdf')	391	0	391	80	4244824765503643823
5	416	71	416	72	2676071710785107444	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 0, min_error_reduction=5)	415	10	416	73	2702664891864765545
5	420	33	420	34	-3845960881215781689	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'mlog10val', fit_reg=False, hue = 'plinkLG', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	419	4	420	90	5651046864926794521
5	426	27	426	28	-6705487449164958887	KMeans(n_clusters=5)	426	9	426	29	-1973358569920040280
5	428	33	428	34	-7000841850048318329	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'FST', fit_reg=False, hue = 'plinkLG', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	427	4	428	90	-3366008978527894879
5	432	48	432	49	-4056787291585392503	tf.nn.top_k(tf.nn.softmax(logits), k=5)	432	11	432	50	-3167736285438811645
5	433	38	433	39	-347286849793915558	fig.colorbar(surf, shrink=0.5, aspect=5)	433	0	433	40	7835449737965025319
5	435	48	435	49	6957486176357452970	L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))	435	14	435	100	-1986598645007191746
5	436	33	436	34	3100530362772022004	sns.lmplot(data = mapped_lfmm, x = 'manhattan_order', y = 'mlog10val', fit_reg=False, hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 4, truncate = True,           palette="Set2")	435	4	436	90	8259840265607257131
5	441	49	441	50	4389722384025261257	L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))	441	14	441	101	-6045862827087451637
5	445	33	445	34	-4690190845873884601	sns.lmplot(data = mapped_lfmm, x = 'cM', y = 'mlog10val', fit_reg=False, row = 'plinkLG', hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 2,\n           palette="Set2")	444	4	446	26	2752353563991065084
5	454	31	454	32	-5517405488579746535	KMeans(n_clusters=5)	454	13	454	33	7705771027493733464
5	455	33	455	34	2554641579119579947	sns.lmplot(data = mapped_lfmm, x = 'cM', y = 'FST', fit_reg=False, row = 'plinkLG', hue = 'reject_null', sharex=False,\n           legend= False, size = 5, aspect = 2,\n           palette="Set2")	454	4	456	26	4356968802999137230
5	514	44	514	45	-1075199906935981403	TfidfVectorizer(min_df=5, token_pattern = r"\b\w\w+\b")	514	21	514	76	4353419910650227396
5	518	44	518	45	-1634992148054725125	GridSearchCV(pipe, param_grid, cv=5, scoring = 'f1_macro')	518	10	518	68	3883820229197094880
5	592	71	592	72	-3350896877889443996	interpolate.approximate_taylor_polynomial(f, x=1, degree=5, scale=0.01)	592	14	592	85	-3566665012894489271
5	611	62	611	63	-7160380669830265520	manifold.TSNE(n_components=2, init='pca', random_state=5)	611	7	611	64	1086470632391818103
5	625	60	625	61	-261671524312096988	gensim.models.ldamodel.LdaModel(corpus_gensim_final,\n                                                     alpha='auto',\n                                                     id2word=id2words_final,\n                                                     num_topics=eachtopic,\n                                                     update_every=1,\n                                                     chunksize=1000,\n                                                     passes=5)	619	38	625	62	-6551039708748265267
5	663	37	663	38	-9079223509606242445	TfidfVectorizer(min_df=5, ngram_range=(1, 3))	663	14	663	59	7761897271466577079
5	691	36	691	37	-4162156563282311300	DBSCAN(eps = 1, min_samples = 5)	691	6	691	38	4402771485680869828
5	709	36	709	37	6017361312928050791	DBSCAN(eps = 2, min_samples = 5)	709	6	709	38	3025703673947804797
5	722	19	722	20	3287766261867020355	DBSCAN(eps = 5, min_samples = 10)	722	6	722	39	1792822462505832833
5	733	36	733	37	-3747291008053550281	DBSCAN(eps = 1, min_samples = 5)	733	6	733	38	7101427547267369405
5	744	36	744	37	-5052181181813728896	DBSCAN(eps = 1, min_samples = 5)	744	6	744	38	-3963901331349930028
5	760	30	760	31	-7105121439828356531	TfidfVectorizer(min_df=5, ngram_range=(1, 3))	760	7	760	52	7678067447965335340
5	944	44	944	45	6595556050722920537	TfidfVectorizer(min_df=5, ngram_range = (1,2))	944	21	944	67	6480074668643138318
5	945	56	945	57	-2934120510635226932	cross_val_score(pipe, X_u_train, y_u_train, cv=5, scoring='f1_macro')	945	9	945	78	-278113354997553064
5	961	38	961	39	906996833826072539	tf.nn.top_k(softmax_logits, k=5)	961	8	961	40	-1513292899645398805
5	965	40	965	41	-8360292461141801789	TfidfVectorizer(min_df=5)	965	17	965	42	5137805018680925223
5	988	51	988	52	-7187827072216564913	sns.kdeplot(win['team1_adjtempo'], win['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False, size = 5, aspect = 10,n_levels=50)	987	0	988	78	-1208705493962606294
5	992	50	992	51	4886710088082931034	sns.kdeplot(loss['team1_adjtempo'], loss['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False,size = 5,aspect = 10,n_levels=50)	991	0	992	76	2187852039882625447
5	1205	64	1205	65	7977489724751068923	cross_val_score(lr, X_train_vector, y_train_labels, cv=5, scoring = 'f1_macro')	1205	9	1205	88	-5909147558193839733
500	30	50	30	53	5982208388710285090	ss_sat.compute(X=XX, f=f_sat, sstype='OLS', nboot=500)	30	0	30	54	8363136525875662975
500	31	54	31	57	192118607292855875	ss_unsat.compute(X=XX, f=f_unsat, sstype='OLS', nboot=500)	31	0	31	58	-7436967720847480679
500	33	38	33	41	8930990817964115183	Image("img/terminate_stop.png", width=500)	33	0	33	42	8184318514369217392
500	52	45	52	48	3512362815429581830	net.train( targetData, bal.T, epochs = 500, show = 50, goal =0.2)	52	6	52	71	-6876464549516138706
500	70	51	70	54	3381701910770364755	np.random.normal(loc=0.0, scale=1.0, size=500)	70	9	70	55	-4304126889860288536
500	101	44	101	47	2979807507184133690	bk.figure(title='LDA Projection - digits dataset',\n                x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=500)	99	6	101	48	-1507773890266659778
500	121	25	121	28	4159491843269734603	genres.sample(n=500)	121	9	121	29	-2854130035829981273
500	125	62	125	65	-1683298191012521453	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
500	166	26	166	29	-2255674212090112026	S.sample(iter=10000, burn=500)	166	0	166	30	3612413812353417828
500	169	54	169	57	3316594424242108861	rank.mean_bilateral(image, selem=selem, s0=500, s1=500)	169	11	169	66	-4246499054749998863
500	169	62	169	65	1488106737320890674	rank.mean_bilateral(image, selem=selem, s0=500, s1=500)	169	11	169	66	-4246499054749998863
500	173	54	173	57	-309563619526936989	rank.mean_bilateral(image, selem=selem, s0=500, s1=500)	173	11	173	66	1200351289429589504
500	173	62	173	65	8125018593487100377	rank.mean_bilateral(image, selem=selem, s0=500, s1=500)	173	11	173	66	1200351289429589504
500	178	43	178	46	-486524417097348161	bk.figure(title='PCA Projection - S-Curve',\n               x_axis_label='c1', y_axis_label='c2',\n               plot_width=750, plot_height=500)	176	6	178	47	-2557690135001772447
500	199	42	199	45	4293209584038341398	RandomForestClassifier(n_estimators= 500, n_jobs=-1)	199	5	199	57	3781399287961683604
500	211	44	211	47	7580200143860051683	manifold.TSNE(n_components=2, n_iter=500)	211	7	211	48	-32563930144533522
500	222	55	222	58	-2265384585597238756	np.random.choice(np.arange(10000), size=500)	222	15	222	59	-6132912602185729138
500	257	31	257	34	-7999443504855427124	VAE(784, n_latent, n_h=500, act_func=F.softplus)	257	8	257	56	6779168473683689677
500	268	49	268	52	4645754941316845332	L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))	268	14	268	88	7707436480492195070
500	297	27	297	30	7654658391564162159	S.sample(iter=100000, burn=500)	297	0	297	31	-8910952077814834253
500	439	49	439	52	5090678777320156317	L.InnerProduct(n.pool1, num_output=500, weight_filler=dict(type='xavier'))	439	14	439	88	-2645447333212312397
500	445	49	445	52	-7993336901848976695	L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))	445	14	445	88	-8547967906378843344
500	707	42	707	45	-164072118192027027	RandomForestClassifier(n_estimators= 500, n_jobs=-1,random_state=3)	707	5	707	72	-6349249037887375716
200	61	56	61	59	-3658108731152268825	widgets.Text(description="Domain to ping", width=200)	61	7	61	60	8914691165826426163
200	92	46	92	49	-5391549985817938689	model.fit(X_train, y_train, nb_epoch = 200, shuffle=True, validation_data = (X_val, y_val))	92	7	92	98	-4742296860466968539
200	133	53	133	56	-5799651830597158696	model.posterior_samples(xn, size=200, full_cov=True)	133	20	133	72	1837168768379597224
200	148	34	148	37	-1699187615089090321	fig.savefig('filename.png', dpi = 200)	148	0	148	38	3125489488348690937
200	164	54	164	57	-7014822527058582164	plt.subplots(1,2,figsize=(20,7),dpi=200)	164	18	164	58	-7354262843180724676
200	182	55	182	58	-410516627077680596	np.random.choice(np.arange(10000), size=200)	182	15	182	59	-7338199242617871394
200	188	53	188	56	3098299270888747680	model.posterior_samples(xn, size=200, full_cov=True)	188	20	188	72	715575504294571184
200	215	37	215	40	6029182064443285527	hist(user_ratings_byuser_local, bins=200, color='lightblue', normed=True)	215	0	215	73	5374508706604231356
200	229	52	229	55	-2293301962124609807	ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n                                       max_depth=5)	229	9	230	51	1279645807566090493
200	232	30	232	33	5185049545002099943	np.set_printoptions(linewidth=200)	232	0	232	34	-8540393282068176538
200	239	31	239	34	4290215736733426760	Clustering(k=k, max_iter=200, precision=5*k*k)	239	6	239	52	2298778837262218424
200	285	50	285	53	7198234253413735296	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	284	4	285	54	-8020422986165235269
200	308	41	308	44	4250167947183102576	display1.plot_ppi('stdPhiDP',vmin=0,vmax=200)	308	0	308	45	-4634317673501684318
200	311	47	311	50	6580671019181297460	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=200)	309	5	311	51	1806039752936675104
200	336	54	336	57	-2003511400766022561	plt.subplots(1,2,figsize=(12,6),dpi=200)	336	18	336	58	6820028425065866500
200	412	70	412	73	5371618476548040732	Image(filename=os.path.join('./practise/',m_image), width=200, height=200)	412	12	412	86	5791342270681196658
200	412	82	412	85	-1897157871505911412	Image(filename=os.path.join('./practise/',m_image), width=200, height=200)	412	12	412	86	5791342270681196658
200	414	50	414	53	1636219652158653529	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	413	4	414	54	6842099077418229338
200	427	50	427	53	-1321684209400171829	ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c="white", alpha=1, s=200)	426	4	427	54	6953547065135165108
200	619	43	619	46	-7778219223377991345	.translate(yoff=200)	619	15	619	47	7918392089830008791
200	723	108	723	111	4253212247072179527	plt.savefig('/gpfs01/bethge/home/oeberle/Results/Var_vs_TotSal_scatter/RGBvar_vs_totsal_scatter.png', dpi = 200)	723	0	723	112	-126991089044645255
32	41	43	41	45	8307532694638263994	ax.text(3,68,"$\int_{%d}^{%d}\!f(2x)\mathrm{d}x = %d$"\n            % (a,b, b**2 - a**2), fontsize=32)	40	4	41	46	-699823023701340213
32	44	56	44	58	-4781164723892776126	conv_layer(x, name='test', kernel_size=(3,3), n_filters=32)	44	0	44	59	5578459914215812509
32	82	38	82	40	105957108132740945	fc_layer(x, name='fc', n_output_units=32, activation_fn=tf.nn.relu)	82	0	82	67	-1075680767533139645
32	165	81	165	83	-4944051822447943388	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(5)], batch_size= 32, nb_epoch= 10,\\n          verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(5)]))	165	0	166	97	-2486106478044164558
32	175	52	175	54	4034954978680433245	model.predict(img, batch_size=32, verbose=0)	175	22	175	66	-3275354214630588475
32	586	84	586	86	5180527730849562613	bbmodel.fit(X_train_sample, [bbox_train_sample[:,i] for i in range(4)], batch_size= 32, nb_epoch= 50, verbose=2)	586	0	586	112	-7866280002810193536
1000	32	99	32	103	-2078548400438654562	es.search(index=index_name2,doc_type="article", q=query, analyzer=analyzer_name,size=1000)	32	14	32	104	-8576971182316935960
1000	43	54	43	58	-2459398493540864193	data_reduce_fast(data_m, data_w, N=1000)	43	19	43	59	-4672311351410673370
1000	51	63	51	67	-786474304073383102	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c="w", zorder=1000)	51	0	51	68	-5191555541517554530
1000	52	65	52	69	6925354698873058412	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c="k", zorder=1000)	52	0	52	70	7865546725860649455
1000	59	60	59	64	2520847137274278089	solver.change_settings(learning_rate=0.005,num_episodes=1000)	59	4	59	65	-4328441682832460447
1000	60	9	60	13	3296697161873387877	np.random.multivariate_normal(\n    mean=[0, 0],\n    cov=[[4, 0],\n         [0, 1]],\n    size=1000)	56	15	60	14	-6286844248294021924
1000	62	29	62	33	-5407373930621737078	FloatSlider(min=0, max=1000, step=5, value = 0)	62	6	62	53	-8305853719096747478
1000	70	20	70	24	8339969785563582337	eeg.sample(n=1000)	70	7	70	25	561641616137721839
1000	80	36	80	40	2180732705634417630	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'l', area_thresh = 1000,\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	79	9	82	32	8596503024335138880
1000	91	48	91	52	2820452441032927979	linspace(0.0, 1.0, num=1000)	91	25	91	53	4376475249593895134
1000	106	27	106	31	9184698806158974280	make_circles(n_samples=1000, factor=0.2, noise=0.1)	106	4	106	55	-2457728177391241849
1000	107	25	107	29	-1290222736979200528	make_moons(n_samples=1000, noise=0.1)	107	4	107	41	-2845942721544942115
1000	108	25	108	29	-8833783357427006098	make_blobs(n_samples=1000, n_features=2, centers=4)	108	4	108	55	-5635320266443073427
1000	113	13	113	17	-2585923098294976828	np.random.multivariate_normal(\n        mean=[0, 1.5],\n        cov=[[3, 1],\n             [1, 1]],\n        size=1000)	109	4	113	18	-1893287785636028833
1000	117	77	117	81	-3852152704360803722	clf.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=1000, batch_size=X_train.shape[0], verbose=0)	117	8	117	122	-6564175486574836798
1000	123	59	123	63	6933476850838594727	solver.change_settings(learning_rate=0.01,num_episodes=1000)	123	4	123	64	1764174067978562939
1000	126	48	126	52	-7294647500079807478	oe_read_records(example, offset=5, count=1000)	126	7	126	53	-8502894914820369070
1000	148	49	148	53	8543629340451594945	pl.scatter(x, y, marker="o", s=22, c="k", zorder=1000)	148	0	148	54	438307233042472985
1000	156	39	156	43	-455884645950428391	datasets.make_s_curve(n_samples=1000)	156	7	156	44	-5167099628295540621
1000	166	59	166	63	-5248027212146998457	solver.change_settings(learning_rate=0.01,num_episodes=1000)	166	4	166	64	6840493179890600106
1000	180	41	180	45	9075332726782357585	vgg16.vgg16(imgs, numClasses = 1000, isPreprocessed = False, fc_size=4096)	180	10	180	84	2527019013000777942
1000	184	107	184	111	-685825814514925279	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c=post_prob[m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	184	0	184	112	-1889501870135959898
1000	186	110	186	114	-4962280405303902692	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c=post_prob[~m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	186	0	186	115	8655850365270254544
1000	188	40	188	44	291487779412897726	generate_data(epsilon=1.0, num_episodes=1000, render=False)	188	0	188	59	-4532309969284958443
1000	237	56	237	60	4423681358391691020	np.random.choice(np.arange(10000), size=1000)	237	16	237	61	-743934250777434883
1000	246	49	246	53	-1958643136828995221	sm.TSNE(n_components=2, verbose=1, n_iter=1000)	246	7	246	54	-286395297359099334
1000	251	34	251	38	-1354392892112788188	make_circles(n_samples=1000, factor=0.2, noise=0.1)	251	11	251	62	107495301150646683
1000	257	32	257	36	5878151934190581483	make_moons(n_samples=1000, noise=0.1)	257	11	257	48	3639466551505490551
1000	282	23	282	27	4199367068614352388	PCA(n_components=1000)	282	6	282	28	7004585394580157942
1000	349	44	349	48	-7492772494131098557	RandomForestRegressor(n_estimators=1000)	349	9	349	49	1667106552466587283
1000	418	48	418	52	7352065301833350467	RandomForestClassifier(max_depth = None,\n                                 class_weight = 'balanced',\n                                 min_samples_split = 2,\n                                 n_estimators = 1000,\n                                 max_features = int(np.sqrt(X_train.shape[1])),\n                                 random_state = 0,\n                                 n_jobs = -1, # to parallelize jobs across all processors\n                                 oob_score = True)	415	11	422	50	3624182513612562906
1000	444	75	444	79	-4704938591853529508	np.chararray(shape=(len(students_HL)+len(students_LL)+1,6),itemsize=1000)	444	7	444	80	7955259303988709629
1000	467	75	467	79	-4106705440430420689	np.chararray(shape=(len(students_HL)+len(students_LL)+1,7),itemsize=1000)	467	7	467	80	-4167010640698663815
1000	541	77	541	81	-4558794312389340529	MDS(dissimilarity="precomputed", n_components=2, metric=True, max_iter=1000)	541	6	541	82	-2542147882667638429
1000	624	63	624	67	-6053294221747216373	gensim.models.ldamodel.LdaModel(corpus_gensim_final,\n                                                     alpha='auto',\n                                                     id2word=id2words_final,\n                                                     num_topics=eachtopic,\n                                                     update_every=1,\n                                                     chunksize=1000,\n                                                     passes=5)	619	38	625	62	-6551039708748265267
1000	1741	94	1741	98	-4854147720227443294	plt.hist(np.divide(np.subtract(df_ambe['linCES'],linCESerr(df_ambe)),df_ambe['linCES']), bins=1000, histtype='step', color='indigo', linewidth=2, range=erange, label="Linear CES")	1741	0	1741	179	-5501242117181297128
1000	1742	91	1742	95	-4775370409525116504	plt.hist(np.divide(np.subtract(df_ambe['CsCES'],CsCESerr(df_ambe)),df_ambe['CsCES']), bins=1000, histtype='step', color='royalblue', linewidth=2, range=erange, label="Single line CES")	1742	0	1742	184	2843532451055559970
22	51	45	51	47	3347279645059454908	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c="w", zorder=1000)	51	0	51	68	-5191555541517554530
22	52	47	52	49	3898030308652447655	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c="k", zorder=1000)	52	0	52	70	7865546725860649455
22	148	31	148	33	-3556696090894443632	pl.scatter(x, y, marker="o", s=22, c="k", zorder=1000)	148	0	148	54	438307233042472985
22	184	45	184	47	-8418073618178236611	pl.scatter(x[m_bkg], y[m_bkg], marker="s", s=22, c=post_prob[m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	184	0	184	112	-1889501870135959898
22	186	47	186	49	-7884132369670934243	pl.scatter(x[~m_bkg], y[~m_bkg], marker="o", s=22, c=post_prob[~m_bkg], cmap="gray_r", vmin=0, vmax=1, zorder=1000)	186	0	186	115	8655850365270254544
22	302	67	302	69	4294021029661688776	bblnrgdatacut.plot(kind='scatter',x='nrg',y='UnitsTotal', fontsize=22, colormap='gist_rainbow', alpha = 1, marker='o',  figsize=(16, 14), loglog=True,  xlim=(1000,1e11), ylim=(1,1000), c=bblnrgdatacut['YearBuilt']-1900, s=bblnrgdatacut['UnitsTotal']/bblnrgdatacut['UnitsRes']*100)	302	0	302	280	-1239077568165988674
22	343	47	343	49	1017883059011901202	pl.title ("log likelihood surface", fontsize = 22)	343	0	343	50	-6808527893646904995
22	345	30	345	32	940556156192286899	pl.xlabel('slope', fontsize = 22)	345	0	345	33	5563302930731900694
22	346	34	346	36	-6653190102831728940	pl.ylabel('intercept', fontsize = 22)	346	0	346	37	7763715582357780702
22	355	25	355	27	8989849935922069111	bblnrgdata.plot(kind='scatter',x='nrg',y='UnitsTotal',\n                fontsize=22, colormap='gist_rainbow', alpha = 1,\n                marker='o',  figsize=(16, 14), loglog=True,\n                xlim=(1000,1e11), ylim=(1,1000),\n                c=bblnrgdata['YearBuilt']-1900,\n                s=bblnrgdata['UnitsTotal']/bblnrgdata['UnitsRes']*100)	354	0	359	70	-8267963167352388908
22	361	44	361	46	-6597558701826691536	pl.ylabel("total number of units", fontsize=22)	361	0	361	47	1167576712293830312
22	362	54	362	56	-2226667076020481770	pl.xlabel("total energy consumption (kBtu)", fontsize=22)	362	0	362	57	6001352930875689841
22	1870	37	1870	39	-6711657358460996047	plt.ylabel('$\sigma/E$ [%]',fontsize=22)	1870	0	1870	40	-6531427972751019867
22	1871	39	1871	41	-14048924790379986	plt.xlabel('$E$ [keV$_{ee}$]',fontsize=22)	1871	0	1871	42	-2204953327367532090
22	1925	49	1925	51	-3234769059042651951	plt.ylabel('$E_{true}-E$ [keV$_{ee}$]', fontsize=22)	1925	0	1925	52	-585707010819295796
22	1926	40	1926	42	4805192380433298761	plt.xlabel('$E$ [keV$_{ee}$]', fontsize=22)	1926	0	1926	43	-8756491351109453399
20	19	27	19	29	-6783029565771047649	matplotlib.rc('font', size=20)	19	0	19	30	8457955348126106677
20	30	88	30	90	883222237674074392	plt.text(0.5 * (a + b), 30,r"$\int_a^b f(x)dx$", horizontalalignment='center', fontsize=20)	30	0	30	91	-4683139493566494268
20	41	43	41	45	-1547506212632300951	plt.legend(loc='upper right', fontsize=20)	41	4	41	46	-8977421767944142014
20	42	28	42	30	-2986701635400098103	tabla_SML['Edad'].hist(bins=20)	42	0	42	31	8841921734810717067
20	43	55	43	57	6329081814059552448	plt.ylabel('log probability density', fontsize=20)	43	8	43	58	8706810426139931460
20	45	51	45	53	7760151132175896587	plt.ylabel('probability density', fontsize=20)	45	8	45	54	1880705009139071022
20	46	59	46	61	4250952410378628990	plt.xlabel('%s for good cells in VISp'%index, fontsize=20)	46	4	46	62	-2878786966476779230
20	52	23	52	25	3002342811719270598	interact(h, p = 5, q = 20)	52	0	52	26	-2221540293840295087
20	52	49	52	51	1844851173563113488	ax.set_xlabel('$\lambda$ ($\mu$m)', fontsize=20)	52	4	52	52	5220896462242278572
20	53	35	53	37	-5455884671978798711	ax.set_ylabel('T, R', fontsize=20)	53	4	53	38	8115244032951217384
20	58	36	58	38	-4682597294239661543	TfidfVectorizer(min_df=20, max_df=0.5)	58	13	58	51	-3426155844756648300
20	62	51	62	53	8410559040153939464	widgets.IntSlider(min = -10, max = 20,step = 2, value = 5)	62	16	62	74	-3704810155526715517
20	70	41	70	43	869017472576444743	axis.set_xlabel('$T_{eff}$',fontsize=20)	70	4	70	44	2967208187047625000
20	71	37	71	39	-4654393966957506470	axis.set_ylabel('$M_G$',fontsize=20)	71	4	71	40	-5851091837569627692
20	73	16	73	18	-6353204143641115215	hist(ages, bins=20, color='lightblue', normed=True)	73	0	73	51	1076921006134459694
20	77	33	77	35	-114322687266834069	matplotlib.rc('xtick', labelsize=20)	77	0	77	36	-770594473324575853
20	78	33	78	35	7452842750346579419	matplotlib.rc('ytick', labelsize=20)	78	0	78	36	-4462603253915436179
20	83	22	83	24	-7124724028388960749	ax.set_title(r'$u(C,\ L)$ for $b=%.2f, \theta=%.2f, \omega=%.2f$' %(b, theta, omega),\n             fontsize=20, family='serif')	82	0	83	41	7913655224381150210
20	89	17	89	19	799532697485708329	difpor.hist(bins=20)	89	0	89	20	-8019338745419436953
20	91	43	91	45	1050896644425987998	np.logspace(8, 10, num=20)	91	20	91	46	-6892129739490930830
20	91	56	91	58	3852165978523246436	SingleIntervalTicker(interval=20)	91	26	91	59	-1937391587882362080
20	100	58	100	60	1864705107335740801	ot_mapping.fit(xs,xt,mu=mu,eta=eta,bias=bias,numItermax = 20,verbose=True)	100	0	100	74	4930226032715298120
20	111	27	111	29	-5307282578954851173	interactive(f, a = 10, b = 20)	111	0	111	30	-8115307443564119381
20	116	31	116	33	3828523031916525732	interactive(f, a = 10, b = 20)	116	4	116	34	8868400013529343130
20	117	53	117	55	-5491428994762777496	np.random.choice(np.arange(10000), size=20)	117	13	117	56	2292857643752053488
20	120	55	120	57	2459400496072158861	plt.suptitle('Distribution of ' + column, fontsize=20)	120	4	120	58	-6298044702227753150
20	122	64	122	66	2219299192637577198	plt.suptitle('Utility slices for various $b$', y=1.05, fontsize=20, family='serif')	122	0	122	83	-6359478849151219040
20	131	55	131	57	1965761090887671375	pl.title("Number of Businesses per ZIP code", fontsize=20)	131	0	131	58	-5078017447972504773
20	134	56	134	58	-2328914131729796821	test_data.topk('probability', k=20)	134	24	134	59	-7715090088200553338
20	134	57	134	59	7281683597543731369	my_map.plot(x_eddy, y_eddy, '.', color='#0080ff', zorder=20)	134	0	134	60	531708572771129997
20	135	42	135	44	477037421773393002	most_positive_reviews.print_rows(num_rows=20)	135	0	135	45	1312447518326238268
20	135	58	135	60	-8327194383756574757	TextGenerator(rnn_layer=SimpleRNN, epoch=20)	135	17	135	61	-6416747533361352737
20	136	19	136	21	3918613686123095644	hist( data, bins = 20,  color = "k" )	136	0	136	37	8492883618890875826
20	140	54	140	56	-3732032517576981114	ax.set_title('Number of movies per genre\n', fontsize=20)	140	0	140	57	-9047990034058721263
20	142	56	142	58	3248167661771448475	test_data.topk('probability', k=20, reverse=True)	142	24	142	73	8356330157629256886
20	143	42	143	44	9012806316203066358	most_negative_reviews.print_rows(num_rows=20)	143	0	143	45	1689852331053295722
20	147	47	147	49	8561262599834941866	plt.title('Shot Performance by Year', fontsize=20)	147	0	147	50	-6185468798657989571
20	147	52	147	54	8291909650207870703	TextGenerator(rnn_layer=GRU, epoch=20)	147	17	147	55	-7580946270103625407
20	157	17	157	19	-6406040730419894898	ax.hist(y1, bins=20 , histtype='bar', normed=True, color='BurlyWood')	157	0	157	69	-4936942087310440286
20	157	44	157	46	6794318402206374698	axis.set_xlabel('$v_x (km/s)$',fontsize=20)	157	4	157	47	-8757419094508519554
20	158	44	158	46	-3302419288748712668	axis.set_ylabel('$v_y (km/s)$',fontsize=20)	158	4	158	47	4201079148095362405
20	159	53	159	55	-5652714046057158343	TextGenerator(rnn_layer=LSTM, epoch=20)	159	17	159	56	8437881268175181684
20	159	70	159	72	4324314755651835629	plt.suptitle(r'Utility slices for various $\theta$', y=1.05, fontsize=20, family='serif')	159	0	159	89	-4472516784502215256
20	171	53	171	55	4674364804364567170	ax.set_title('Number of movies per year\n', fontsize=20)	171	0	171	56	3827169371916530148
20	173	46	173	48	1294101748772580564	plt.title('Shot Performance by Day', fontsize=20)	173	0	173	49	1775730410830519172
20	178	64	178	66	2074023260901427167	hough_line_peaks(hspace=h, angles=theta,\n                                             dists=d, num_peaks=20, threshold=0)	177	28	178	80	3227342998954488761
20	179	45	179	47	-7320720697164160299	pl.title("K-means Clusters, k = 3", fontsize=20)	179	0	179	48	-8812803798652171385
20	185	61	185	63	2179353784679845755	ax0.set_title('Electron longitudinal phase profile',fontsize=20)	185	0	185	64	-7026221823898081234
20	187	32	187	34	-7614264919344847979	ax1.set_title('zoom 1',fontsize=20)	187	0	187	35	998716041831009659
20	188	32	188	34	-3022851802355847929	ax2.set_title('zoom 2',fontsize=20)	188	0	188	35	-221931484880345978
20	188	46	188	48	6272049570724133222	plt.title('Shot Performance by Day', fontsize=20)	188	0	188	49	-293318613133203283
20	196	70	196	72	6460516058613128176	plt.suptitle(r'Utility slices for various $\omega$', y=1.05, fontsize=20, family='serif')	196	0	196	89	-2185896367121062471
20	197	64	197	66	-3823497943165682619	hough_line_peaks(hspace=h, angles=theta,\n                                             dists=d, num_peaks=20)	196	28	197	67	-617812727386191427
20	202	22	202	24	2145129526350650648	plt.xlabel('$x$',size=20)	202	0	202	25	5342905971376930172
20	203	22	203	24	6444023240019971269	plt.ylabel('$y$',size=20)	203	0	203	25	3933225666761701091
20	204	43	204	45	-4405483436255351734	plt.title('Temperature at time $t_0$',size=20)	204	0	204	46	7092517757782153512
20	208	50	208	52	-8677748912697460247	kde(kernel = 'epanechnikov', bandwidth = 20)	208	9	208	53	-8328280304335140463
20	209	64	209	66	2877401774680737124	plt.title('Shot Performance - Running 30 Day Average', fontsize=20)	209	0	209	67	669814443294034229
20	210	32	210	34	-3216804845252789951	label.pack(side="bottom", ipady=20)	210	0	210	35	150339401903100620
20	218	51	218	53	9196424740957819901	ax.set_title('Distribution of ratings\n', fontsize=20)	218	0	218	54	-3167354907622339937
20	219	22	219	24	1410433353788679736	plt.xlabel('$x$',size=20)	219	0	219	25	-4628929446975055694
20	220	22	220	24	-7619677342879645882	plt.ylabel('$y$',size=20)	220	0	220	25	8426332103620975969
20	221	43	221	45	-6289654191520838091	plt.title('Temperature at time $t_1$',size=20)	221	0	221	46	8829015468923945295
20	227	22	227	24	-1164169535828035737	ax.set_title(r'$u(C,\ L)$ for $b=%.2f, \theta=%.2f, \omega=%.2f$' %(b, theta, omega),\n             fontsize=20, family='serif')	226	0	227	41	924047053740122623
20	227	45	227	47	-1093313760339582965	pl.title("K-means Clusters, k = 4", fontsize=20)	227	0	227	48	8436797045061040756
20	233	72	233	74	-2415801124020030313	plt.title('Shot Performance - Running 30 Day Mean and Median', fontsize=20)	233	0	233	75	-2135702680949892825
20	236	22	236	24	-5961290166070163604	plt.xlabel('$x$',size=20)	236	0	236	25	8929930628676913226
20	237	22	237	24	2667386049114255240	plt.ylabel('$y$',size=20)	237	0	237	25	-596163933903322923
20	237	27	237	29	-348595401843396787	nx.draw_networkx(G, pos = spring_pos,  node_color = valuesC,\n                 font_size=20,node_size = 20, with_labels = False, cmap=plt.cm.Set1)	236	0	237	84	-6204270146225287606
20	237	42	237	44	933924992033793097	nx.draw_networkx(G, pos = spring_pos,  node_color = valuesC,\n                 font_size=20,node_size = 20, with_labels = False, cmap=plt.cm.Set1)	236	0	237	84	-6204270146225287606
20	238	43	238	45	4755044568130482564	plt.title('Temperature at time $t_1$',size=20)	238	0	238	46	4093220177701468940
20	249	22	249	24	949028739247371731	plt.xlabel('$x$',size=20)	249	0	249	25	6369218760664488287
20	250	22	250	24	-2170579018837506691	plt.ylabel('$y$',size=20)	250	0	250	25	5783859965401472033
20	253	43	253	45	521265885266778486	plt.title('Temperature at time $t_0$',size=20)	253	0	253	46	5114764085931281411
20	262	22	262	24	-8627841401757515883	plt.xlabel('$x$',size=20)	262	0	262	25	1464750410799462953
20	263	22	263	24	6425565625458139098	plt.ylabel('$y$',size=20)	263	0	263	25	-324825750817916066
20	264	62	264	64	654084350759078973	L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))	264	14	264	100	6406586362364781811
20	266	43	266	45	2718065642074888606	plt.title('Temperature at time $t_1$',size=20)	266	0	266	46	-586146433099457035
20	268	31	268	33	5969417259964031793	plt.hist(y, label=['1st', '2nd'], color=['b', 'g'],\n            stacked=True, bins=20)	267	0	268	34	-7652984793178029948
20	272	49	272	51	-7693700354540942108	Basemap(projection='merc',llcrnrlat=latsmin,urcrnrlat=latsmax,\\n        llcrnrlon=lonmin,urcrnrlon=lonmax,lat_ts=20,resolution='c',ax=axis)	271	8	272	75	6929293495289962837
20	275	40	275	42	5256880741544176772	pl.title("DBSCAN, 3 clusters", fontsize=20)	275	0	275	43	1962282345170630257
20	280	33	280	35	-8046133576432702706	acf(ts_log_diff, nlags=20)	280	10	280	36	-5573514416707189005
20	281	35	281	37	6278103297557428653	pacf(ts_log_diff, nlags=20, method='ols')	281	11	281	52	-8446562996546662352
20	283	48	283	50	-7465935493885362712	plt.title('Shot Performance by Month', fontsize=20)	283	0	283	51	-1415895698386130080
20	284	22	284	24	-8756402933314264077	ax.set_title(r'$u(C,\ L)$ for $b=%.2f, \theta=%.2f, \omega=%.2f$' %(b, theta, omega),\n             fontsize=20, family='serif')	283	0	284	41	-3080231174216152999
20	298	44	298	46	-4597228377560458883	plt.title('Shots Taken Per Month', fontsize=20)	298	0	298	47	4986551279552257200
20	302	41	302	43	808371715685391582	pl.title("K-means, 3 clusters", fontsize=20)	302	0	302	44	-5071911881723935836
20	308	19	308	21	-8192576205347280087	hist( data, bins = 20, histtype="step", normed = True, color = "k",\n    lw = 2, label = "histogram of data" )	308	0	309	41	5833219851132992370
20	308	48	308	50	8696822257805276287	plt.title('Shot Performance by Month', fontsize=20)	308	0	308	51	4582708679256079413
20	312	40	312	42	4342066241412872669	pl.title("DBSCAN, 3 clusters", fontsize=20)	312	0	312	43	-673721518317823542
20	315	48	315	50	-2541096811725774219	plt.text(0.5 * (a + b), 1, r"$\int_a^b f(x)\mathrm{d}x$",\n         horizontalalignment='center', fontsize=20)	314	0	315	51	1536282681088863100
20	316	29	316	31	-2829641674631337585	plt.xlabel('Smarts',fontsize=20)	316	0	316	32	3710259650354340811
20	317	34	317	36	-3438565301097810513	plt.ylabel('Probability',fontsize=20)	317	0	317	37	2126359787975477921
20	318	38	318	40	5424616907077483963	plt.title('Histogram of IQ', fontsize=20)	318	0	318	41	3880410332328077473
20	319	54	319	56	520310922006466323	plt.text(45,.027,r'$\mu=100,\ \sigma=15$', fontsize = 20)	319	0	319	57	7264012081741781391
20	321	20	321	22	-1616600400147938010	plt.xticks(fontsize=20)	321	0	321	23	-591325922740789937
20	322	20	322	22	-6223585270784579180	plt.yticks(fontsize=20)	322	0	322	23	3033870430918896228
20	340	65	340	67	-5987457892962380639	fig.suptitle('Transit Fits 201295312 (Vanderburg)', fontsize=20)	340	4	340	68	8798713517767848057
20	342	71	342	73	-5626098650592344441	fig.suptitle('Transit Fits 201295312 (Armstrong et al.)', fontsize=20)	342	4	342	74	-8055256649582573617
20	344	62	344	64	6928296797912004628	fig.suptitle('Transit Fits 201295312 (Vincent)', fontsize=20)	344	4	344	65	7053419378840941819
20	353	38	353	40	33503259922566274	ax1.set_xlabel('CPT Codes',fontsize = 20)	353	0	353	41	3296209318401741923
20	354	41	354	43	-3342743870173716694	ax1.set_ylabel('Frequencies', fontsize = 20)	354	0	354	44	-2620529444588665270
20	355	35	355	37	5721439087198906416	ax2.set_ylabel('Price', fontsize = 20)	355	0	355	38	1239316811203096442
20	414	27	414	29	-4260712474409852432	plt.xlabel(r'Triplet',size=20)	414	0	414	30	6540409173621423078
20	415	94	415	96	-6118600965201624245	plt.ylabel(r'$log(\frac{A}{B})$' + ' or ' + r'$log(\frac{A}{C} )+ log({ \frac{C}{B}})$', size=20)	415	0	415	97	-8124527821763509891
20	421	33	421	35	9205777656302394298	plt.xlabel(r'$\frac{A}{B}$',size=20)	421	0	421	36	1521270224634429272
20	422	54	422	56	-62107089715627824	plt.ylabel(r'$\frac{A}{C} \cdot{ \frac{C}{B}}$', size=20)	422	0	422	57	-5853853467132655430
20	423	92	423	94	7564133640325511024	plot_freq_chart(3,2,Sorted_Nouns_Adj_Freq, "Top Nouns & Adjectives - bigram", figw=16, figh=20)	423	0	423	95	-7984584743727850807
20	429	30	429	32	8361690460759497878	plt.xlabel(r'$log(A/B)$',size=20)	429	0	429	33	-8582564471709522389
20	430	42	430	44	4283526873770033034	plt.ylabel(r'$log(A/C) + log(C/B)$', size=20)	430	0	430	45	-8821790991409299837
20	435	62	435	64	7822652820445048575	L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))	435	14	435	100	-1986598645007191746
20	440	40	440	42	3796091579616218066	ax.text(0.15, 0.2, r'$y=x^2$', fontsize=20, color='blue')	440	0	440	57	-8218028349263325167
20	441	40	441	42	3719816834265772098	ax.text(0.65, 0.1, r'$y=x^3$', fontsize=20, color='green')	441	0	441	58	-588432943927635905
20	441	100	441	102	-1423674054249191933	plot_freq_chart(3,2,Sorted_Nouns_Adj_trigram_Freq, "Top Nouns & Adjectives - Trigram",figw=16, figh=20)	441	0	441	103	-938522552681499073
20	446	55	446	57	-3565529195089153380	plot.tick_params(axis='both', which='major', labelsize=20)	446	0	446	58	-6481518298664491368
20	447	55	447	57	-6967422612848567653	plot.tick_params(axis='both', which='minor', labelsize=20)	447	0	447	58	4259870444456909201
20	449	64	449	66	2424217880275167617	plt.xlabel('Average temperature (min-max normalized)', fontsize=20)	449	0	449	67	2584674392853653346
20	450	49	450	51	1731993598016787990	plt.ylabel('Number of persons injured', fontsize=20)	450	0	450	52	9217217751008842679
20	461	25	461	27	-4024771198961736618	plt.hist(deg, bins = 20)	461	4	461	28	7701438417791644275
20	469	34	469	36	-7520181333279253110	ax1.set_title('My Plot', fontsize=20)	469	0	469	37	-6053915938635495590
20	470	28	470	30	1117297178964500110	ax1.set_xlabel('x',fontsize=20)	470	0	470	31	7509292907944215725
20	471	28	471	30	-6338992908298844248	ax1.set_ylabel('y',fontsize=20)	471	0	471	31	2322342994806568227
20	503	38	503	40	7354739920953370108	fig6.suptitle(fig_title, fontsize=20)	503	4	503	41	-1670243475043275813
20	513	50	513	52	-154475440474148662	plt.text(m[0], m[1], "{}".format(i), fontsize=20)	513	4	513	53	-1912660806739840400
20	518	29	518	31	-7457539429464047912	sns.distplot(x,bins=20,hist_kws={'linewidth': 3,'alpha':0.5,\n                                          'facecolor':'#8b1a1a','edgecolor':'black'},\n                     kde_kws={'color':'black', 'linewidth':3})	518	9	520	62	3850608250961023241
20	586	39	586	41	5877367776398646486	plt.xlabel(r'$log(\frac{A}{X})$', size=20)	586	0	586	42	-396218266477153051
20	587	39	587	41	849109568435047375	plt.ylabel(r'$log(\frac{B}{X})$', size=20)	587	0	587	42	-7010374949767071683
20	614	87	614	89	8015504921853321145	ax1.set_title(r'Taylor series approximation of $f(x) = x^{\alpha}$ at $x=1$', fontsize=20, family='serif')	614	0	614	106	-8006936868036933771
20	644	61	644	63	6015775549908538317	plt.title('Residuals 201295312 (Vanderburg)', fontsize = 20)	644	4	644	64	1442255890203387734
20	648	60	648	62	-427845107211874560	plt.title('Residuals 201295312 (Armstrong)', fontsize = 20)	648	4	648	63	1407463268284122234
20	650	27	650	29	2109325196476094832	deque(maxlen=20)	650	14	650	30	2412318692084045920
20	652	58	652	60	3551760292921005689	plt.title('Residuals 201295312 (Vincent)', fontsize = 20)	652	4	652	61	-7584757697698911630
20	660	27	660	29	-4826744547291800384	deque(maxlen=20)	660	14	660	30	-3721666438792133861
20	679	46	679	48	7424041697671869579	plt.title("Output and capital IRFs", fontsize=20, family='serif')	679	0	679	65	-7211945465789430078
20	696	46	696	48	4742986191525921991	plt.title("Output and capital IRFs", fontsize=20, family='serif')	696	0	696	65	-8572150712058812425
20	713	55	713	57	6252280961073127578	plt.title("Output and capital negative IRFs", fontsize=20, family='serif')	713	0	713	74	9046738280549657177
20	731	63	731	65	-3108265657960579688	plt.title("Output, consumption, and investment IRFs", fontsize=20, family='serif')	731	0	731	82	4898631075881123970
20	758	66	758	68	2411622178533943332	plt.title("Output, real wage and the labor supply IRFs", fontsize=20, family='serif')	758	0	758	85	-2471875220704373590
20	775	42	775	44	-6491015322809387941	plt.title("Time path of output", fontsize=20, family='serif')	775	0	775	61	1745127718239204995
20	792	47	792	49	-7621896330260038890	plt.title("Time path of consumption", fontsize=20, family='serif')	792	0	792	66	-5154724825577147150
20	811	46	811	48	974326415890030054	plt.title("Time path of investment", fontsize=20, family='serif')	811	0	811	65	-806550042526749520
20	831	53	831	55	-8049281691782985792	plt.title('Euler residuals across time...', fontsize=20, family='serif')	831	0	831	72	-2208226616947940841
20	854	57	854	59	-1095413534502221714	plt.title('What is a low-discrepancy ellipse?', fontsize=20, family='serif')	854	0	854	76	-7835083508771565845
20	872	63	872	65	-3915433523844859305	plt.title('Euler residuals across space and time...', fontsize=20, family='serif')	872	0	872	82	8253333630417103129
20	946	49	946	51	-4834693319133610244	plt.title("IRFs for labor supply, $L$", fontsize=20, family='serif')	946	0	946	68	-510202686024595839
20	966	48	966	50	-7416280414524649099	plt.title("IRFs for consumption, $C$", fontsize=20, family='serif')	966	0	966	67	639472395763792168
15	37	44	37	46	5461411865411856346	plt.plot(1, 1, '*', markerfacecolor='r', ms=15)	37	0	37	47	-309302631631276974
15	38	55	38	57	5238180067247600915	plt.plot(.3, .5, marker='h', markerfacecolor='red', ms=15)	38	0	38	58	-1023107732470494088
15	39	51	39	53	-289153166111115888	plt.plot(.4, .5, '*', markerfacecolor='yellow', ms=15)	39	0	39	54	-1746536279816882548
15	40	46	40	48	3276937333862196304	plt.plot(.5, .5, '*', markerfacecolor='g', ms=15)	40	0	40	49	-202634064007520400
15	41	51	41	53	2043443134011663765	plt.plot(.6, .5, '*', markerfacecolor='orange', ms=15)	41	0	41	54	2613630737875878514
15	42	46	42	48	1074263065793664111	plt.plot(.7, .5, '*', markerfacecolor='b', ms=15)	42	0	42	49	2457221158394079753
15	43	49	43	51	-9183044370061631122	plt.plot(.8, .5, '*', markerfacecolor='cyan', ms=15)	43	0	43	52	8368049272494861848
15	44	46	44	48	-1849551028482741451	plt.plot(.9, .5, '*', markerfacecolor='m', ms=15)	44	0	44	49	5673113897618209873
15	67	26	67	28	3162370497440744487	LDA2Vec(n_documents=n_docs, n_document_topics=n_topics,\n                n_units=n_units, n_vocab=n_vocab, counts=term_frequency,\n                n_samples=15, power=power, temperature=temperature)	65	8	67	67	-5151049898594945271
15	80	42	80	44	6931405086752767320	ax.set_xlabel(r'Labor, $L_{t}$', fontsize=15, family='serif')	80	0	80	61	1586627992008274358
15	81	48	81	50	-3110564766404977606	ax.set_ylabel(r'Consumption, $C_{t}$', fontsize=15, family='serif')	81	0	81	67	-5698861387999121864
15	91	43	91	45	-9167825482273618866	plt.title('Temperature at time $t_1$',size=15)	91	0	91	46	4857460831957733833
15	94	40	94	42	-8988750013843619867	RandomForestRegressor(n_estimators=15, max_depth=6)	94	5	94	56	5545882175351523560
15	103	40	103	42	-8664578314848253738	RandomForestRegressor(n_estimators=15,max_depth=6)	103	5	103	55	4028614024555475724
15	114	51	114	53	5831661867985032496	plt.title('Light Curve (Vanderburg)', fontsize=15)	114	4	114	54	-2629135136338023046
15	114	70	114	72	-1776782708092698784	AdaBoostRegressor(DecisionTreeRegressor(max_depth=6),n_estimators=15)	114	4	114	73	-7032740351561242900
15	116	57	116	59	4618904298291002687	plt.title('Light Curve (Armstrong et al.)', fontsize=15)	116	4	116	60	-7448826574289409376
15	118	48	118	50	2502737315842658351	plt.title('Light Curve (Vincent)', fontsize=15)	118	4	118	51	1710421358811745843
15	129	27	129	29	6834948601317629444	pl.xlabel("Year", fontsize=15)	129	0	129	30	-9194747030635620285
15	130	43	130	45	2467730958164034061	pl.ylabel("Number of Businesses", fontsize=15)	130	0	130	46	-5013925359844401827
15	145	28	145	30	1360897037187080309	plt.xlabel('Year', fontsize=15)	145	0	145	31	-5547812621697752595
15	145	48	145	50	7042578962327133244	RandomForestRegressor(n_estimators=15, max_depth=3)	145	13	145	64	6159070962506976915
15	146	48	146	50	2226863253517042983	plt.ylabel('Proportion of Shots Made', fontsize=15)	146	0	146	51	2556396635052677304
15	159	29	159	31	6057676884259728411	axis.plot(0, 0, 'w*', ms=15)	159	4	159	32	-8222587105013734837
15	165	28	165	30	-1471853829306716251	plt.xlabel('date', fontsize=15)	165	0	165	31	-6871983872292205382
15	166	48	166	50	-5280499895888808732	plt.ylabel('Proportion of Shots Made', fontsize=15)	166	0	166	51	3683186132884791396
15	170	50	170	52	1444693827177454019	RandomForestRegressor(n_estimators=15, max_depth=3)	170	15	170	66	5911296475782386985
15	177	27	177	29	261797334980375028	pl.xlabel("Year", fontsize=15)	177	0	177	30	5085015330126928983
15	178	43	178	45	-6171503133337741829	pl.ylabel("Number of Businesses", fontsize=15)	178	0	178	46	4665561782119532476
15	180	27	180	29	7915343325935044071	plt.xlabel('Day', fontsize=15)	180	0	180	30	-4131987049155826879
15	181	48	181	50	-3503468670300916692	plt.ylabel('Proportion of Shots Made', fontsize=15)	181	0	181	51	-3922457078266678568
15	198	50	198	52	1114854327202561197	manifold.LocallyLinearEmbedding(n_neighbors=15, n_components=2, method='modified')	198	6	198	88	5226607276166827305
15	201	27	201	29	-6139745720950033180	ax.hist((y1, y2, y3), bins=15 , histtype='bar', normed=True, \\n        color=('BurlyWood', 'IndianRed', 'DeepSkyBlue'), label=('Type A', 'Type B', 'Type C'))	201	0	202	94	6494612768888079931
15	201	27	201	29	8146853498320557987	plt.xlabel('Day', fontsize=15)	201	0	201	30	3997286373291051166
15	202	48	202	50	-7538815637305563445	plt.ylabel('Proportion of Shots Made', fontsize=15)	202	0	202	51	-2123009075373635832
15	222	44	222	46	7472883216034045548	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                 r"Grass-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                 r"Grass-CG ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                                 fontsize = 15, loc='upper center', frameon=True)	219	8	222	81	690599586808114104
15	224	27	224	29	-4768238428061464949	plt.xlabel('Day', fontsize=15)	224	0	224	30	789344604960310245
15	224	42	224	44	2047062926952283196	ax.set_xlabel(r'Labor, $L_{t}$', fontsize=15, family='serif')	224	0	224	61	3221175955647034270
15	225	27	225	29	-8549284316050252148	pl.xlabel("Year", fontsize=15)	225	0	225	30	-3282967336529406730
15	225	48	225	50	-8429049476283622498	ax.set_ylabel(r'Consumption, $C_{t}$', fontsize=15, family='serif')	225	0	225	67	-8401753236277619695
15	225	48	225	50	-3016869847031079294	plt.ylabel('Proportion of Shots Made', fontsize=15)	225	0	225	51	5694230517494323060
15	226	43	226	45	-8773546774321943265	pl.ylabel("Number of Businesses", fontsize=15)	226	0	226	46	-1490671823879504987
15	229	40	229	42	7951120914786224926	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:6.5f})".format(eta), r"Grass-GD ($\eta$ = {0:6.5f})".format(eta), \\n                                 r"Grass-CG ($\eta$ = {0:6.5f})".format(eta)], \\n                             fontsize = 15, loc='upper center', frameon=True)	227	8	229	77	-437152428255931782
15	231	53	231	55	6242627790465246849	plt.ylabel('negative log-likelihood', fontsize = 15)	231	4	231	56	-3046511499448996966
15	232	40	232	42	-1786760516017164379	plt.xlabel('iterations', fontsize = 15)	232	4	232	43	-49476110511082187
15	233	24	233	26	5881093460408039221	plt.xticks(fontsize=15)	233	4	233	27	-8233935863703787703
15	233	27	233	29	-2959376575177801465	MaxNLocator(nbins=15)	233	9	233	30	384022233460727687
15	234	24	234	26	-5661105067373519667	plt.yticks(fontsize=15)	234	4	234	27	879649941007930767
15	263	40	263	42	1194436490875731611	ax.legend([h1, h2], [r"(Grass-GD) 1st singular value ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                             r"(Grass-GD) 2nd singular value ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='upper center', frameon=True)	261	8	263	77	9026398378559942236
15	266	40	266	42	4260194135734784343	ax.legend([h1, h2], [r"1st singular value ($\eta$ = {0:6.5f})".format(eta), r"2nd singular value ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='upper center', frameon=True)	265	8	266	77	-5892875097668624111
15	268	44	268	46	-2980238766552908667	plt.ylabel('singular value', fontsize = 15)	268	4	268	47	-7477935485146895638
15	269	40	269	42	-2854509228168530662	plt.xlabel('iterations', fontsize = 15)	269	4	269	43	4681637943330327146
15	270	24	270	26	-5304972958870954328	plt.xticks(fontsize=15)	270	4	270	27	-6109995706253257709
15	271	24	271	26	-6207989020736369746	plt.yticks(fontsize=15)	271	4	271	27	-6147334348486498364
15	273	27	273	29	-8544587920033680457	pl.xlabel("Year", fontsize=15)	273	0	273	30	-8024676240503493339
15	274	44	274	46	-5263847315205004165	pl.ylabel("Number of Businesses)", fontsize=15)	274	0	274	47	6967949412827267634
15	281	29	281	31	1483254816056273174	plt.xlabel('Month', fontsize=15)	281	0	281	32	4520982585095147443
15	281	42	281	44	7933598638160888120	ax.set_xlabel(r'Labor, $L_{t}$', fontsize=15, family='serif')	281	0	281	61	5665618828309213080
15	282	48	282	50	-1846600271849859327	ax.set_ylabel(r'Consumption, $C_{t}$', fontsize=15, family='serif')	282	0	282	67	7367592388056476915
15	282	48	282	50	3187580706744927	plt.ylabel('Proportion of Shots Made', fontsize=15)	282	0	282	51	-4746215995041776688
15	296	29	296	31	-4539053360947282657	plt.xlabel('Month', fontsize=15)	296	0	296	32	-2723687268262448000
15	297	49	297	51	-6030229473516133228	plt.ylabel('Proportion of Shots Taken', fontsize=15)	297	0	297	52	-687417384328016548
15	300	40	300	42	-3619319379954207915	ax.legend([h1, h2], [r"(Grass-CG) 1st singular value ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                             r"(Grass-CG) 2nd singular value ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='upper center', frameon=True)	298	8	300	77	-5819207884185032256
15	303	34	303	36	7372528608115539042	pl.xlabel('longitude', fontsize = 15)	303	0	303	37	-5716934396990728896
15	303	40	303	42	-4019710234164481585	ax.legend([h1, h2], [r"1st singular value ($\eta$ = {0:6.5f})".format(eta), r"2nd singular value ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='upper center', frameon=True)	302	8	303	77	-4023560189806312956
15	304	33	304	35	4458800056281486026	pl.ylabel('latitude', fontsize = 15)	304	0	304	36	4332565058332325977
15	305	44	305	46	8351654325776746323	plt.ylabel('singular value', fontsize = 15)	305	4	305	47	3967805462622817876
15	306	29	306	31	5774150535753607371	plt.xlabel('Month', fontsize=15)	306	0	306	32	6592186310382223332
15	306	40	306	42	-1627415709331615655	plt.xlabel('iterations', fontsize = 15)	306	4	306	43	-6286591541951291439
15	307	24	307	26	-239648731382724116	plt.xticks(fontsize=15)	307	4	307	27	-7846764301708179372
15	307	48	307	50	6185128658716112697	plt.ylabel('Proportion of Shots Made', fontsize=15)	307	0	307	51	464475173529618294
15	308	24	308	26	-9007165705094885755	plt.yticks(fontsize=15)	308	4	308	27	5543133466321711698
15	313	34	313	36	-1070968823074287787	pl.xlabel('longitude', fontsize = 15)	313	0	313	37	8573889919345351180
15	314	33	314	35	7081321536755921154	pl.ylabel('latitude', fontsize = 15)	314	0	314	36	-6779164733609442537
15	337	40	337	42	5375312486239282428	ax.legend([h1, h2], [r"(Grass-GD) G-norm ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                             r"(Grass-CG) G-norm ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='upper center', frameon=True)	335	8	337	77	-7595726911962209861
15	340	40	340	42	-2233906206376976012	ax.legend([h1, h2], [r"(Grass-GD) G-norm ($\eta$ = {0:6.5f})".format(eta), r"(Grass-CG) G-norm ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='upper center', frameon=True)	339	8	340	77	-5058606775174708900
15	342	40	342	42	5782766498938214423	plt.ylabel('norm value', fontsize = 15)	342	4	342	43	3642111449416173376
15	343	40	343	42	3367841058454172872	plt.xlabel('iterations', fontsize = 15)	343	4	343	43	6482240720187748941
15	344	24	344	26	-7838690425446782492	plt.xticks(fontsize=15)	344	4	344	27	-5828732422544061262
15	345	24	345	26	2919015345851690440	plt.yticks(fontsize=15)	345	4	345	27	-2591932151017691704
15	379	64	379	66	-1435275698353381980	ax.set_ylabel(r'Consumption, $C_{t}$', family='serif', fontsize=15)	379	0	379	67	-2906506458430421533
15	380	58	380	60	-7394135147397862206	ax.set_xlabel(r'Labor, $L_{t}$', family='serif', fontsize=15)	380	0	380	61	6141651288102328920
15	382	22	382	24	3623998895674104004	ax.set_title(r'Optimal bundle in period t=0 for $b=%.2f, \beta=%.2f$' %(b, beta),\n             fontsize=15, family='serif')	381	0	382	41	-3371377370064353319
15	382	40	382	42	2913737869251236673	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                  r"Grass-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                  r"Grass-CG ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='center left', frameon=True)	379	9	382	76	6715818022203902985
15	388	40	388	42	979540313925936958	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:6.5f})".format(eta), r"Grass-GD ($\eta$ = {0:6.5f})".format(eta), \\n                                 r"Grass-CG ($\eta$ = {0:6.5f})".format(eta)], \\n                             fontsize = 15, loc='upper left', frameon=True)	386	8	388	75	-5424663729848590582
15	390	51	390	53	-6628779092789336527	plt.ylabel('condition number of K', fontsize = 15)	390	4	390	54	7188387291072457078
15	391	40	391	42	5675653428091199326	plt.xlabel('iterations', fontsize = 15)	391	4	391	43	5744505686027414063
15	392	24	392	26	7824753937396406068	plt.xticks(fontsize=15)	392	4	392	27	2660113102301106925
15	393	24	393	26	-652106492130486593	plt.yticks(fontsize=15)	393	4	393	27	-6707548668757262472
15	419	64	419	66	-1018462182280460282	ax.set_ylabel(r'Consumption, $C_{t}$', family='serif', fontsize=15)	419	0	419	67	4397606454058805042
15	420	58	420	60	7246080717741710665	ax.set_xlabel(r'Labor, $L_{t}$', family='serif', fontsize=15)	420	0	420	61	-5357094262514101137
15	422	38	422	40	6028440420909364209	ax.set_title(r'Optimal bundle in period t=1 for $b=%.2f, \beta=%.2f$' %(b, beta),\n             family='serif', fontsize=15)	421	0	422	41	4744785229206795220
15	425	40	425	42	-7477627540821038648	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                  r"Grass-GD ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                                  r"Grass-CG ($\eta$ = {0:5.4f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='upper center', frameon=True)	422	9	425	77	5079520339381616053
15	431	40	431	42	6341431531556713275	ax.legend([h1, h2, h3], [r"Euclid-GD ($\eta$ = {0:6.5f})".format(eta), r"Grass-GD ($\eta$ = {0:6.5f})".format(eta), \\n                                 r"Grass-CG ($\eta$ = {0:6.5f})".format(eta)], \\n                             fontsize = 15, loc='upper center', frameon=True)	429	8	431	77	6873219593988632746
15	433	55	433	57	-8937317457094864942	plt.ylabel('condition number of dL/dK', fontsize = 15)	433	4	433	58	-8102769048874429936
15	434	40	434	42	-7791879135959378149	plt.xlabel('iterations', fontsize = 15)	434	4	434	43	-7564794088714272675
15	435	24	435	26	-7567320693820831955	plt.xticks(fontsize=15)	435	4	435	27	5554811788836686270
15	436	24	436	26	-7848381877481195688	plt.yticks(fontsize=15)	436	4	436	27	4918421383153096675
15	464	40	464	42	-509001526380910206	ax.legend([h1], [r"(Grass-CG) $\gamma$ ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='lower center', frameon=True)	463	8	464	77	3017027914831569246
15	470	40	470	42	-6530016649532940058	ax.legend([h1, h2], [r"(Grass-GD) G-norm ($\eta$ = {0:6.5f})".format(eta), r"(Grass-CG) G-norm ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='lower center', frameon=True)	469	8	470	77	-8020096390359370068
15	472	39	472	41	-7921342747653237770	plt.ylabel(r"$\gamma$", fontsize = 15)	472	4	472	42	3823502343194699346
15	473	40	473	42	-5267181090718221064	plt.xlabel('iterations', fontsize = 15)	473	4	473	43	-7123027192546181545
15	474	24	474	26	-2130232063794133191	plt.xticks(fontsize=15)	474	4	474	27	-590151062145274303
15	475	24	475	26	-7922986100968189878	plt.yticks(fontsize=15)	475	4	475	27	251029774860696063
15	503	40	503	42	-4268577959632087918	ax.legend([h1], [r"(Grass-CG) $<G - \tau G, G>$ ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='lower center', frameon=True)	502	8	503	77	1619679010701265797
15	509	40	509	42	6315168115156714508	ax.legend([h1, h2], [r"(Grass-GD) G-norm ($\eta$ = {0:6.5f})".format(eta), r"(Grass-CG) G-norm ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='lower center', frameon=True)	508	8	509	77	-4735768216197571828
15	511	41	511	43	-4494985793071422206	plt.ylabel(r"$\Delta G$", fontsize = 15)	511	4	511	44	-1348973937675843899
15	512	40	512	42	472054023184364470	plt.xlabel('iterations', fontsize = 15)	512	4	512	43	-2225955594623891231
15	513	24	513	26	-6679243006975148535	plt.xticks(fontsize=15)	513	4	513	27	-2847932410409405626
15	514	24	514	26	503691081833394312	plt.yticks(fontsize=15)	514	4	514	27	4734086308885715541
15	544	40	544	42	7273987208013553612	ax.legend([h1, h2], [r"(Grass-GD) $\beta$ ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i]), \\n                             r"(Grass-CG) $\beta$ ($\eta$ = {0:6.5f}, $\lambda$ = {1:5.3f})".format(eta, lambda_array[i])], \\n                             fontsize = 15, loc='lower center', frameon=True)	542	8	544	77	2616175571044343529
15	547	40	547	42	1910098053208500434	ax.legend([h1, h2], [r"(Grass-GD) $\beta$ ($\eta$ = {0:6.5f})".format(eta), r"(Grass-CG) $\beta$ ($\eta$ = {0:5.4f})".format(eta)], \\n                             fontsize = 15, loc='lower center', frameon=True)	546	8	547	77	-4454677222805116709
15	549	53	549	55	2049493106451466544	plt.ylabel(r"$\beta$ noise variance", fontsize = 15)	549	4	549	56	-3878144192939360958
15	550	40	550	42	8020066762274375180	plt.xlabel('iterations', fontsize = 15)	550	4	550	43	1952214172963054112
15	551	24	551	26	3983237550163290398	plt.xticks(fontsize=15)	551	4	551	27	-1593111212179861092
15	552	24	552	26	-2644175304003899187	plt.yticks(fontsize=15)	552	4	552	27	2135616291318436149
15	612	31	612	33	-5605476896173566006	ax1.set_xlabel('$x$', fontsize=15)	612	0	612	34	4688520536880361948
15	613	57	613	59	-5475515179567751583	ax1.set_ylabel('$f(x)$', rotation='horizontal', fontsize=15)	613	0	613	60	-622588554920039016
15	677	31	677	33	5324524976460732547	plt.xlabel('Periods', fontsize=15, family='serif')	677	0	677	50	-8192377360710533992
15	678	43	678	45	-4037174280756292954	plt.ylabel('Absolute deviations', fontsize=15, family='serif')	678	0	678	62	5039464895484479643
15	694	31	694	33	600025064719074084	plt.xlabel('Periods', fontsize=15, family='serif')	694	0	694	50	-2489812440294604648
15	695	36	695	38	-5669835560417212758	plt.ylabel('% deviations', fontsize=15, family='serif')	695	0	695	55	4938294930116966691
15	710	29	710	31	-4869720976696541967	p.set_xticklabels(rotation = 15,labels = mod.columns)	710	0	710	53	1418868567755445014
15	711	31	711	33	5239773787256332956	plt.xlabel('Periods', fontsize=15, family='serif')	711	0	711	50	8537035994928582652
15	712	36	712	38	2383713234224886409	plt.ylabel('% deviations', fontsize=15, family='serif')	712	0	712	55	-3106329701607797094
15	720	98	720	100	-8707782489181379209	plt.title('Image {} vs 463 images, {:.2%}'.format(c, np.sum(v['duel'])/len(v['duel'])), size= 15)	720	4	720	101	-6329509504311288353
15	729	31	729	33	-3654596685509907344	plt.xlabel('Periods', fontsize=15, family='serif')	729	0	729	50	-6226246269078444215
15	730	36	730	38	-8535568321669516044	plt.ylabel('% deviations', fontsize=15, family='serif')	730	0	730	55	2067401883829663051
15	750	64	750	66	5158046575334276224	axes[0].set_xlabel("Top ten IDs who Speaked most days",fontsize=15)	750	0	750	67	7336772745924520092
15	754	69	754	71	4281691526907232767	axes[1].set_xlabel("Top ten IDs who Speaked most messages", fontsize=15)	754	0	754	72	8865008248971564251
15	756	31	756	33	2831516477130706812	plt.xlabel('Periods', fontsize=15, family='serif')	756	0	756	50	-4487963774712389037
15	757	36	757	38	-233917642980155078	plt.ylabel('% deviations', fontsize=15, family='serif')	757	0	757	55	-1447175680233053760
15	773	31	773	33	7735193532481282566	plt.xlabel('Periods', fontsize=15, family='serif')	773	0	773	50	-7481153376514173641
15	774	37	774	39	6311011176811885032	plt.ylabel('Output, $Y_t$', fontsize=15, family='serif')	774	0	774	56	-3182026683756117671
15	790	31	790	33	-4144777883342135717	plt.xlabel('Periods', fontsize=15, family='serif')	790	0	790	50	3960852638470770641
15	791	42	791	44	-8348917059046965289	plt.ylabel('Consumption, $C_t$', fontsize=15, family='serif')	791	0	791	61	-1190360066541848600
15	809	31	809	33	-2454361316655945106	plt.xlabel('Periods', fontsize=15, family='serif')	809	0	809	50	3630596491055599399
15	810	41	810	43	-347734249910594543	plt.ylabel('investment, $I_t$', fontsize=15, family='serif')	810	0	810	60	-6888249557486749123
15	829	31	829	33	-8239532311877088206	plt.xlabel('Periods', fontsize=15, family='serif')	829	0	829	50	-152711595239385238
15	830	41	830	43	-118650483385167081	plt.ylabel('Squared residuals', fontsize=15, family='serif')	830	0	830	60	-3243027004236323684
15	852	38	852	40	267653123107709857	plt.xlabel('Capital, $K_t$', fontsize=15, family='serif')	852	0	852	57	1816733194260453802
15	853	47	853	49	-1340634206708109954	plt.ylabel('Productivity, $e^{Z_t}$', fontsize=15, family='serif')	853	0	853	66	6368327662475345118
15	870	31	870	33	-8993487688456905878	plt.xlabel('Periods', fontsize=15, family='serif')	870	0	870	50	5756676025360586190
15	871	41	871	43	8318965495321065763	plt.ylabel('Squared residuals', fontsize=15, family='serif')	871	0	871	60	-2099685770218641171
15	884	24	884	26	-5097435222573638445	KMeans(n_clusters=15)	884	6	884	27	-6118970410136677478
15	893	71	893	73	-5570774820925773363	axes[0].set_xlabel("Top ten IDs who Speaked most days (Days)",fontsize=15)	893	0	893	74	-7219252741389619324
15	897	82	897	84	1034573138029593327	axes[1].set_xlabel("Top ten IDs who Speaked most messages (Quantities)", fontsize=15)	897	0	897	85	-2964505629544160948
15	902	81	902	83	2558341478616920502	axes[2].set_xlabel("Top ten IDs who had most days Speaked most (Days)", fontsize=15)	902	0	902	84	7547560842705397644
15	944	31	944	33	-4965288872819351181	plt.xlabel('Periods', fontsize=15, family='serif')	944	0	944	50	2834804278314360241
15	945	36	945	38	496365939392480951	plt.ylabel('% deviations', fontsize=15, family='serif')	945	0	945	55	2541376468232078303
15	964	31	964	33	7945236933172248872	plt.xlabel('Periods', fontsize=15, family='serif')	964	0	964	50	-6983966529489861015
15	965	36	965	38	-46037990182945920	plt.ylabel('% deviations', fontsize=15, family='serif')	965	0	965	55	4159751664528344218
999	50	69	50	72	3309851159433673962	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	50	0	50	73	-3788675041583091273
999	147	69	147	72	5828928212479784779	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	147	0	147	73	4460889049567238131
999	182	69	182	72	-5776583426978060268	pl.errorbar(x, y, yerr=yerr, fmt=",k", ms=0, capsize=0, lw=1, zorder=999)	182	0	182	73	-1931039812533034310
16	32	55	32	57	-6842465452862493814	fig.suptitle("Cropped Face and Bounding box", fontsize=16)	32	0	32	58	4127605336494041858
16	42	39	42	41	8060575262932064689	plt.xlabel('Input Parameter', fontsize=16)	42	0	42	42	-2252506337200993496
16	43	40	43	42	-8394504292392258429	plt.ylabel('Component Weight', fontsize=16)	43	0	43	43	-3243352280792969582
16	46	87	46	89	3487453182355631413	plt.suptitle("Relationships Between Departure Diversions and Airport Operations", size=16)	46	0	46	90	7494798986308188339
16	47	87	47	89	-6190069560874332138	plt.suptitle("Relationships Between Departure Diversions and Airport Operations", size=16)	47	0	47	90	419386789658688741
16	52	39	52	41	6387029772582524445	plt.xlabel('Input Parameter', fontsize=16)	52	0	52	42	2460988685107464843
16	53	40	53	42	-8728696979433839036	plt.ylabel('Component Weight', fontsize=16)	53	0	53	43	8326542737438836636
16	60	82	60	84	-6483730326489385878	plt.title(r'  $y = x ^2 $  $y = 100 - x^2$', fontsize=16, y=1.05)	60	0	60	93	9132675190402002970
16	69	99	69	101	2602720147733500977	train_test_split(new_data, labels, test_size=0.25, random_state=16)	69	35	69	102	-3774481448518356870
16	72	47	72	49	-3382919202820772704	DecisionTreeRegressor(random_state=16)	72	12	72	50	4499035073607081567
16	77	44	77	46	-2140140642988389013	fig.suptitle(ThisPCA.__name__, fontsize=16)	77	4	77	47	3120928800745696394
16	85	90	85	92	-8692881080572821753	plt.suptitle("Relationships Between Departure Cancellations and Airport Operations", size=16)	85	0	85	93	8005830705460207803
16	86	90	86	92	3048949297845377787	plt.suptitle("Relationships Between Departure Cancellations and Airport Operations", size=16)	86	0	86	93	-844652451618528036
16	95	39	95	41	-5270523293718767080	plt.xlabel('Input Parameter', fontsize=16)	95	0	95	42	3982032447191149007
16	96	40	96	42	-439126502471152923	plt.ylabel('Component Weight', fontsize=16)	96	0	96	43	-1216375049420363505
16	105	39	105	41	-7374533959426695903	plt.xlabel('Input Parameter', fontsize=16)	105	0	105	42	3852622756880178562
16	106	40	106	42	-8738603035887122234	plt.ylabel('Component Weight', fontsize=16)	106	0	106	43	-2990376660601011774
16	106	64	106	66	678280563730969125	dist.set_title('Distribution of ' + column + '\n', fontsize=16)	106	4	106	67	-8125570862986974507
16	116	39	116	41	5830324133778814527	plt.xlabel('Input Parameter', fontsize=16)	116	0	116	42	4916964406417914472
16	117	51	117	53	4790746380508485254	plt.ylabel('Component Weight Difference', fontsize=16)	117	0	117	54	-6250006447486027982
16	121	32	121	34	6951251539165386869	plt.xlabel(column, fontsize=16)	121	4	121	35	-3077612407847077434
16	122	33	122	35	-4957756487615561818	plt.ylabel('Count', fontsize=16)	122	4	122	36	4971807365923627183
16	122	52	122	54	6309226455898253304	ax.set_title("SVC classification", fontsize=16)	122	8	122	55	-3732925388638703593
16	124	85	124	87	-1547534487413604739	plt.suptitle("Relationships Between Arrival Diversions and Airport Operations", size=16)	124	0	124	88	-6438303253562667357
16	125	46	125	48	4167682709873476656	gl.recommender.ranking_factorization_recommender.create(train,\n                                  user_id="INDP",\n                                  item_id="FOD1P",\n                                  target="EMPScore",\n                                  num_factors=16,                 # override the default value\n                                  regularization=1e-02,           # override the default value\n                                  linear_regularization = 1e-3)	121	7	127	63	2444198280881815181
16	125	85	125	87	-3990997049306457353	plt.suptitle("Relationships Between Arrival Diversions and Airport Operations", size=16)	125	0	125	88	1843308906445887832
16	126	39	126	41	1032015253036133982	plt.xlabel('Input Parameter', fontsize=16)	126	0	126	42	1818647627718160550
16	127	51	127	53	-7669024704957975361	plt.ylabel('Component Weight Difference', fontsize=16)	127	0	127	54	2907823603938997914
16	152	56	152	58	5268083753685269638	plt.text((len(train)/2)-25,7000,'Train Period',size=16)	152	4	152	59	-2148830972903803479
16	154	52	154	54	-8534456760139546230	plt.text(len(train)+100,7000,'Test Period',size=16)	154	4	154	55	7929800417373083268
16	163	88	163	90	5287034169744163808	plt.suptitle("Relationships Between Arrival Cancellations and Airport Operations", size=16)	163	0	163	91	-5400793845682777478
16	164	88	164	90	3194971464056923796	plt.suptitle("Relationships Between Arrival Cancellations and Airport Operations", size=16)	164	0	164	91	1151881192551490778
16	186	27	186	29	-1766706841994308531	plt.xlabel("$L$", fontsize=16)	186	0	186	30	2895633404710873564
16	186	41	186	43	-151108447289374227	ax0.legend(('zoom 1','zoom 2',),fontsize=16,fancybox=True,shadow=True)	186	0	186	70	9167486973932583939
16	187	28	187	30	8089727307376796936	plt.ylabel('Wage', fontsize=16)	187	0	187	31	-5067539844222138721
16	189	146	189	148	2996878227445381039	plt.annotate(r'$sin(\frac{2\pi}{3})=\frac{\sqrt{3}}{2}$', xy=(t,np.sin(t)),xycoords='data',xytext=(+10,+30),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	189	0	189	217	1724565809334578715
16	193	140	193	142	-8674489361569895874	plt.annotate(r'$sin(\frac{2\pi}{3})=-\frac{1}{2}$', xy=(t,np.cos(t)),xycoords='data',xytext=(-90,-50),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	193	0	193	211	-623909732672378965
16	204	46	204	48	3931636574015882438	gl.recommender.ranking_factorization_recommender.create(pus,\n                                  user_id="INDP",\n                                  item_id="FOD1P",\n                                  target="EMPScore",\n                                  num_factors=16,                 # override the default value\n                                  regularization=0.001,           # override the default value\n                                  linear_regularization = 0.001)	200	12	206	64	7215565083839277481
16	218	27	218	29	-7647052864209534864	plt.xlabel("$L$", fontsize=16)	218	0	218	30	1823888591706016945
16	219	28	219	30	423292151890325670	plt.ylabel('Wage', fontsize=16)	219	0	219	31	7294822933069392931
16	221	146	221	148	-4487211937943670981	plt.annotate(r'$sin(\frac{2\pi}{3})=\frac{\sqrt{3}}{2}$', xy=(t,np.sin(t)),xycoords='data',xytext=(+10,+30),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	221	0	221	217	-4392097322276565434
16	225	140	225	142	802339270271846843	plt.annotate(r'$sin(\frac{2\pi}{3})=-\frac{1}{2}$', xy=(t,np.cos(t)),xycoords='data',xytext=(-90,-50),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	225	0	225	211	5600066470333095731
16	256	146	256	148	-415320612989290502	plt.annotate(r'$sin(\frac{2\pi}{3})=\frac{\sqrt{3}}{2}$', xy=(t,np.sin(t)),xycoords='data',xytext=(+10,+30),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	256	0	256	217	-7751098395974560752
16	260	140	260	142	-1821528674020444669	plt.annotate(r'$sin(\frac{2\pi}{3})=-\frac{1}{2}$', xy=(t,np.cos(t)),xycoords='data',xytext=(-90,-50),textcoords= 'offset points', fontsize=16,arrowprops = dict(arrowstyle="->", connectionstyle = "arc3,rad=.2"))	260	0	260	211	-7080949671121429461
16	311	58	311	60	-1807495486059030400	ax2.legend(('$a_0$','$a_0$ w/o plasma','$n_e$',),fontsize=16,fancybox=True,shadow=True,loc=4)	311	0	311	93	-6389299561856119965
16	423	83	423	85	-2009554504036474359	plot_freq_chart(3,2,Sorted_Nouns_Adj_Freq, "Top Nouns & Adjectives - bigram", figw=16, figh=20)	423	0	423	95	-7984584743727850807
16	441	91	441	93	-2091460148965465587	plot_freq_chart(3,2,Sorted_Nouns_Adj_trigram_Freq, "Top Nouns & Adjectives - Trigram",figw=16, figh=20)	441	0	441	103	-938522552681499073
16	526	43	526	45	-1624778890168799301	plt.tick_params(axis='both', labelsize=16)	526	4	526	46	-3460824409164642137
16	565	43	565	45	1405113689996334834	plt.tick_params(axis='both', labelsize=16)	565	4	565	46	-7938345422926358808
35	70	46	70	48	-3067511459130997752	plt.hist(medians, histtype='stepfilled', bins=35, alpha=0.85)	70	0	70	61	5347133581485171066
35	79	45	79	47	3477109610016666622	plt.hist(beta_t, histtype='stepfilled', bins=35, alpha=0.85,\n         label=r"posterior of $\beta$", color="#7A68A6", normed=True)	79	0	80	69	-4554262106742791095
35	81	46	81	48	2524323843996771280	plt.hist(alpha_t, histtype='stepfilled', bins=35, alpha=0.85,\n         label=r"posterior of $\alpha$", color="#A60628", normed=True)	81	0	82	70	-6282276928900819135
35	94	77	94	79	4671175456263377900	plt.scatter(dat['Teff'], dat['log(g)'], c=dat['R_H'], vmin=0, vmax=2, s=35, cmap=cmap, alpha=0.5)	94	5	94	102	3057921789789673490
35	97	19	97	21	-3886311591735708325	Text(x=2, y=35, text='year', text_font_size='150pt', text_color='#EEEEEE')	97	7	97	81	6910983217275782025
35	135	40	135	42	-3459038304835111329	triangle.corner(sampler.flatchain, bins=35, extents=bounds, labels=labels, truths=truths)	135	0	135	89	-5713944896996622740
35	171	13	171	15	3025953320522927230	dict(s=35, linewidth=.5, alpha = .5)	171	6	171	42	-5628082646798469772
35	300	51	300	53	6385239972487752187	plt.hist(alpha_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\alpha$", color="#7A68A6", normed=True)	300	0	300	128	970649140750148340
35	303	50	303	52	828402421048843148	plt.hist(beta_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\beta$", color="#A60628", normed=True)	303	0	303	126	-1737454168816159541
35	309	50	309	52	5437047416336658115	plt.hist(Pr66_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $Pr(66.0|data)$", color="#A04538", normed=True)	309	0	309	134	-4736367557396558248
35	499	51	499	53	-2722876813754409673	plt.hist(alpha_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\alpha$", color="#7A68A6", normed=True)	499	0	499	128	4812958144372116799
35	502	50	502	52	-2885668432521290769	plt.hist(beta_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\beta$", color="#A60628", normed=True)	502	0	502	126	-5191773012555387721
35	508	50	508	52	-8131379722411844719	plt.hist(Pr66_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $Pr(66.0|data)$", color="#A04538", normed=True)	508	0	508	134	-4461790600079792152
35	696	51	696	53	7040449386893604845	plt.hist(alpha_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\alpha$", color="#7A68A6", normed=True)	696	0	696	128	-2484457515862363525
35	699	50	699	52	679865081445940861	plt.hist(beta_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\beta$", color="#A60628", normed=True)	699	0	699	126	6934575964290570404
35	705	50	705	52	-1199384247316989832	plt.hist(Pr66_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $Pr(66.0|data)$", color="#A04538", normed=True)	705	0	705	134	-5986654161596142502
35	927	51	927	53	-4199860431641492843	plt.hist(alpha_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\alpha$", color="#7A68A6", normed=True)	927	0	927	128	-4480194281734102982
35	930	50	930	52	-3358980259602772425	plt.hist(beta_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\beta$", color="#A60628", normed=True)	930	0	930	126	-1283803738348910437
35	936	50	936	52	1017602170030278472	plt.hist(Pr66_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $Pr(66.0|data)$", color="#A04538", normed=True)	936	0	936	134	-1298500247108438367
35	1205	51	1205	53	7540714264880008908	plt.hist(alpha_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\alpha$", color="#7A68A6", normed=True)	1205	0	1205	128	-4147746421593674087
35	1208	50	1208	52	-8603902926365552874	plt.hist(beta_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $\beta$", color="#A60628", normed=True)	1208	0	1208	126	4670596421001176903
35	1214	50	1214	52	-3135354061822467453	plt.hist(Pr66_sample, histtype='stepfilled', bins=35, alpha=0.85, label=r"posterior of $Pr(66.0|data)$", color="#A04538", normed=True)	1214	0	1214	134	-2070430122498225073
12	105	17	105	19	5793669163934878188	gen_text(x=12, y="temperature", z=22.4)	105	6	105	45	6975154245907624210
12	120	35	120	37	3371245782296896226	plt.xlabel('BJD-2454833', fontsize=12)	120	0	120	38	-4053169867257715560
12	121	28	121	30	3291115185400053715	plt.ylabel('Flux', fontsize=12)	121	0	121	31	8375892733103574877
12	149	35	149	37	-6731933380011680980	my_map.plot(x, y, 'bo', markersize=12)	149	0	149	38	-7399533105313510817
12	157	35	157	37	-1759621309622556075	plt.xlabel('BJD-2454833', fontsize=12)	157	0	157	38	-6188181486217057252
12	158	28	158	30	2087250533634771820	plt.ylabel('Flux', fontsize=12)	158	0	158	31	-3670944212622722847
12	158	35	158	37	-8790513344567556032	my_map.plot(x, y, 'ro', markersize=12)	158	0	158	38	1113656340780867179
12	159	37	159	39	-6525729684147012383	plt.title('Raw Light Curve',fontsize=12)	159	0	159	40	8610937023694274242
12	186	49	186	51	-7120139445277075462	pd.rolling_mean(timeseries, window=12)	186	14	186	52	1402020691560112968
12	187	47	187	49	-8995120027776412301	pd.rolling_std(timeseries, window=12)	187	13	187	50	3745611005630231065
12	231	42	231	44	930083301582186530	pd.ewma(ts_log, halflife=12)	231	17	231	45	-3184027086592655047
12	241	64	241	66	5510422792054682704	plt.yticks(range(len(indices)), df.columns[indices], fontsize = 12)	241	0	241	67	370389445928062450
12	259	18	259	20	5421971454300040061	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=["o", '+']),\n           size = 12, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	258	4	259	84	8458077030235441750
12	293	30	293	32	-8534598087983618890	ax.set_xlabel("Open",fontsize=12)	293	0	293	33	-5587280573940748562
12	294	42	294	44	855082954394567385	ax.set_ylabel("Volume (Million)",fontsize=12)	294	0	294	45	-3115061631970009881
12	304	74	304	76	1758565768537975947	new_colors(ncdc_data, level=12)	304	46	304	77	1328017148088644128
12	305	74	305	76	-3769559302891947822	new_colors(ghnc_data, level=12)	305	46	305	77	5555062530681822547
12	352	35	352	37	6793127579681444682	plt.xticks(rotation=60, fontsize = 12)	352	0	352	38	8024096565987094916
12	443	73	443	75	5483762738909060747	anim.save('vae_{}to{}.gif'.format(start, end), writer='imagemagick', fps=12, dpi=64)	443	0	443	84	-6256341000573797089
12	479	36	479	38	-7317259596088438564	ax1.annotate('(a)',(0.01,0.96),size=12,xycoords='figure fraction')	479	0	479	66	6068984141297133235
12	490	59	490	61	-5992879392918188995	ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=12, rotation=90)	490	4	490	75	-9220869846897449587
12	491	59	491	61	-7106788035254045635	ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=12, rotation=0)	491	4	491	74	-715771006684953716
12	496	33	496	35	1737563714727894409	pl.title(titles[i], size=12)	496	8	496	36	7829754506532284029
12	568	89	568	91	1363217926925144203	anim.save('vae_{}to{}_dim{}.gif'.format(start, end, n_latent), writer='imagemagick', fps=12, dpi=64)	568	0	568	100	-1459748535430917866
12	598	43	598	45	-463971834748820981	plt.tick_params(axis='both', labelsize=12)	598	4	598	46	3007646869560249531
12	735	64	735	66	-2837307464389660603	plt.yticks(range(len(indices)), df.columns[indices], fontsize = 12)	735	0	735	67	1030638028504669755
100	25	29	25	32	-3532522936065273354	FloatProgress(min=0, max=100)	25	4	25	33	-966105580900459449
100	32	179	32	182	7402288598166673678	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=c, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	32	13	32	241	-6282894579066499134
100	37	22	37	25	-706784157509329061	ax.scatter(this.C_intersurface, np.mean(this.flux_u + this.flux_b),\n         c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	36	4	37	85	4430386413245571164
100	37	63	37	66	-2632716968288975487	GradientBoostingClassifier(n_estimators=100, verbose=1)	37	23	37	78	-5667541124086464248
100	38	65	38	68	9188971967803152872	GradientBoostingClassifier(n_estimators=100, verbose=1)	38	25	38	80	-653183788370041305
100	39	179	39	182	-4754231403494172365	LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.005, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)	39	9	39	241	3476444751173404693
100	46	28	46	31	-883521548250622350	tabla_SML['Edad'].hist(bins=100)	46	0	46	32	-4678823958977169653
100	46	45	46	48	6723442882084270526	net.train( targetData, bal.T, epochs = 100, show = 10, goal =0.2)	46	6	46	71	-6743005386240515941
100	46	52	46	55	7644799919555656248	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	36	13	46	56	-4609451283332274812
100	47	72	47	75	-4317713889620261484	RandomForestRegressor(n_estimators=100, max_depth=3)	47	37	47	89	5911423604566722113
100	52	66	52	69	-5607488891662114531	gl.recommender.util.random_split_by_user(pus,\n                                                    user_id="INDP", item_id="FOD1P",\n                                                    max_num_users=100, item_test_proportion=0.2)	50	14	52	96	-4314672082493085040
100	57	27	57	30	-8166149915275476670	plot_dist('osi_dg', bins = 100, plot_range = [-2, 5],log=False)	57	0	57	63	7445197577251866121
100	60	53	60	56	6809555527453415447	plt.subplots(3, 3, figsize=(5, 5), dpi=100)	60	14	60	57	-7377294794255123346
100	60	81	60	84	3485256067794551187	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query="txid45351[ORGN]")	60	16	60	151	7141005060581959987
100	60	99	60	102	8559632274337796449	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query="txid45351[ORGN]")	60	16	60	151	7141005060581959987
100	66	22	66	25	-3702523286647249554	ax.scatter(this.offset_factor, np.mean(this.flux_u + this.flux_b),\n         c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	65	4	66	85	6857355029285897634
100	67	50	67	53	-8661175278393860478	sample_probabilities(probs, ratname, sample = 100)	67	4	67	54	4007137570463991026
100	68	38	68	41	3174328962164093981	sample_correct_rate(rat, sample = 100)	68	4	68	42	-2091479621313019654
100	68	53	68	56	850990968825388176	plt.subplots(3, 3, figsize=(9, 9), dpi=100)	68	14	68	57	7298268446457044956
100	72	32	72	35	-6996180339770471794	plt.figure(figsize=(18,12), dpi=100)	72	0	72	36	2715872133338491223
100	73	32	73	35	-4393481411757152311	ax.hist(self.data, bins=100)	73	8	73	36	8792641272021105372
100	88	32	88	35	3179452514871285916	plt.figure(figsize=(18,12), dpi=100)	88	0	88	36	1112419033219712922
100	90	26	90	29	-8013657111328734483	ax.scatter(this.D, np.mean(this.flux_u + this.flux_b),\n             c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	89	4	90	89	5170701653189178144
100	90	81	90	84	4116407739491998880	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query="txid45351[ORGN]")	90	16	90	151	2555694037615411260
100	90	99	90	102	-7211514035902221022	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query="txid45351[ORGN]")	90	16	90	151	2555694037615411260
100	108	44	108	47	2873738567960885427	Solver(model, small_data,\n                  num_epochs=25, batch_size=100,\n                  update_rule='adam',\n                  optim_config={\n                    'learning_rate': 5e-4,\n                  },\n                  verbose=True, print_every=100)	107	11	113	48	6160983272379773386
100	109	44	109	47	2759432914607691108	RandomForestClassifier(n_estimators=100)	109	8	109	48	734243797859335587
100	112	89	112	92	827329458494622471	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query=str(i))	112	24	112	148	8087710078479582594
100	112	107	112	110	-5520382156826752130	NCBIWWW.qblast("blastp", "refseq_protein", sequences, alignments=100, descriptions=100, expect=0.00001, entrez_query=str(i))	112	24	112	148	8087710078479582594
100	113	44	113	47	1874044903647402016	Solver(model, small_data,\n                  num_epochs=25, batch_size=100,\n                  update_rule='adam',\n                  optim_config={\n                    'learning_rate': 5e-4,\n                  },\n                  verbose=True, print_every=100)	107	11	113	48	6160983272379773386
100	114	52	114	55	5119083475637836582	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	104	13	114	56	-4357225614281537730
100	124	20	124	23	3144371512132687623	plt.scatter(x, y, s=100, c=colors)	124	0	124	34	-4358924819460908084
100	131	38	131	41	6379210760709903805	plt.figure(figsize=(8,4), dpi = 100)	131	6	131	42	-2919840305520394550
100	132	34	132	37	-1644301803730297023	puzzle.create_board(moves=100)	132	8	132	38	-7768776528596661064
100	133	50	133	53	6911101772531012197	sample_probabilities(probs, ratname, sample = 100)	133	4	133	54	3103953253416682855
100	134	38	134	41	-4598464306481495332	sample_correct_rate(rat, sample = 100)	134	4	134	42	-4257240072435408020
100	137	33	137	36	-70620945570289210	KMeans(n_clusters=3, n_init=100)	137	5	137	37	5820437045395883845
100	141	15	141	18	-8596778542876514358	vae.fit(x_train, x_train,\n        shuffle=True,\n        epochs=100,\n        batch_size=100,\n        validation_split=0.0, verbose=False)	139	0	143	44	253312701683917496
100	142	19	142	22	8443296663161681221	vae.fit(x_train, x_train,\n        shuffle=True,\n        epochs=100,\n        batch_size=100,\n        validation_split=0.0, verbose=False)	139	0	143	44	253312701683917496
100	144	58	144	61	-4137412634015134702	np.histogram(df['Flux with catalysis'], bins=100, range=(-10,10), weights=np.ones_like(df['Mean diff'])/float(len(df['Mean diff'])))	144	13	144	145	-3106068673657521411
100	146	43	146	46	4391649476201122295	np.linspace(0.5, 1, num=100)	146	19	146	47	6423412282114193386
100	150	19	150	22	-5203301369275818216	my_map.tissot(lon_0=lon_edex_mean, lat_0=lat_edex_mean, radius_deg=eddy_radius_degree,\n              npts=100, fc='#cccccc', ec='none', zorder=1)	149	0	150	58	4074994673106612548
100	151	43	151	46	8880316462848063586	np.linspace(0.5, 1, num=100)	151	19	151	47	-6175397419892770879
100	152	43	152	46	-4575692613487130275	np.linspace(0.5, 1, num=100)	152	19	152	47	-9215220356211096656
100	157	52	157	55	-6201609341444053511	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	147	13	157	56	-2869984644699322532
100	158	51	158	54	5987446782454074265	np.histogram(df['Flux lower D'], bins=100, range=(-10,10), weights=np.ones_like(df['Mean diff'])/float(len(df['Mean diff'])))	158	13	158	138	-1028026389135402188
100	159	43	159	46	2738991117107945645	np.linspace(0.5, 1, num=100)	159	19	159	47	-3508198302331548589
100	162	55	162	58	358595160252927298	np.random.choice(np.arange(10000), size=100)	162	15	162	59	-5262250447066582418
100	165	28	165	31	177458452750249318	plt.scatter(x[:2], y[:2], s=100, c='red', label='Tall students')	165	0	165	64	-8030988311986645206
100	167	28	167	31	-3630816581657988561	plt.scatter(x[2:], y[2:], s=100, c='blue', label='Short students')	167	0	167	66	-5808350034702800138
100	168	17	168	20	6893919249837785280	AdaBoostClassifier(base_estimator=None,\n    n_estimators=100,\n    learning_rate=1.0,\n    algorithm='SAMME.R',\n    random_state=0)	167	6	171	19	6217791255254211484
100	172	48	172	51	-6009463589290740997	np.histogram(df['Mean diff'], bins=100, range=(-5,5), weights=np.ones_like(df['Mean diff'])/float(len(df['Mean diff'])))	172	13	172	133	122605096231323974
100	176	50	176	53	-7892435673104900727	sample_probabilities(probs, ratname, sample = 100)	176	4	176	54	-5485680815543838665
100	177	38	177	41	-506485396627419195	sample_correct_rate(rat, sample = 100)	177	4	177	42	-5353364706708988932
100	185	33	185	36	-7913094586027649492	KMeans(n_clusters=4, n_init=100)	185	5	185	37	6104743429927288181
100	186	62	186	65	3758293115851833683	np.histogram(df['Flux with catalysis Std'], bins=100, range=(0,5), weights=np.ones_like(df['Std diff'])/float(len(df['Std diff'])))	186	13	186	144	-6709009571041804050
100	189	44	189	47	7928284480068160918	plt.hist(feat.flat[feat.flat > 0], bins=100)	189	4	189	48	-412941283346767957
100	200	44	200	47	-5247641873244869896	plt.hist(feat.flat[feat.flat > 0], bins=100)	200	4	200	48	5724951016822109371
100	200	55	200	58	-3951618152518356700	np.histogram(df['Flux lower D Std'], bins=100, range=(0,0.05), weights=np.ones_like(df['Std diff'])/float(len(df['Std diff'])))	200	13	200	140	-8152967118155149546
100	204	103	204	106	-1902088637153236256	model_tf_idf.query(wiki[wiki['name'] == 'Barack Obama'], label='name', k=100)	204	30	204	107	8407319911129220332
100	211	43	211	46	6744817495911188517	np.linspace(0.5, 1, num=100)	211	19	211	47	2760610124395536044
100	212	43	212	46	5662586882833103380	np.linspace(0.5, 1, num=100)	212	19	212	47	6517413675812803424
100	213	43	213	46	1048557955809649236	np.linspace(0.5, 1, num=100)	213	19	213	47	-813886912694057966
100	215	54	215	57	5868065867727296149	manifold.MDS(n_components=2, n_init=1, max_iter=100)	215	6	215	58	-466724360669131111
100	215	89	215	92	-6399262826795822449	plt.scatter(all_centroid["x"],         all_centroid["y"],         c="g", zorder=2, s=100)	215	4	215	93	7377727079367765918
100	216	77	216	80	2557418217014924631	KMeans(n_clusters = 5, random_state = 0,init='k-means++',max_iter = 100)	216	9	216	81	-93560221250628329
100	216	89	216	92	-6844093939160538066	plt.scatter(all_centroidweighted["x"], all_centroidweighted["y"], c="r", zorder=2, s=100)	216	4	216	93	8428329796300536488
100	220	91	220	94	-1704530250840761744	plt.scatter(topN_centroidweighted["x"], topN_centroidweighted["y"], c="m", zorder=2, s=100)	220	4	220	95	-1631311168509988455
100	221	91	221	94	2900553599669472549	plt.scatter(topN_centroid["x"],         topN_centroid["y"],         c="y", zorder=2, s=100)	221	4	221	95	6538590467234555823
100	223	99	223	102	-738523844203565867	plt.scatter(topNtile_centroidweighted["x"], topNtile_centroidweighted["y"], c="c", zorder=2, s=100)	223	4	223	103	-1752530546439175677
100	224	99	224	102	-7403142832596183798	plt.scatter(topNtile_centroid["x"],         topNtile_centroid["y"],         c="k", zorder=2, s=100)	224	4	224	103	-4832562188758651614
100	225	26	225	29	-8291881744462175203	ax.scatter(this.cATP, np.mean(this.flux_u + this.flux_b),\n             c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0,\n             label='Glu$^{194}_{\chi_2}$' if scaling==0 else '')	224	4	226	64	500611836144052278
100	226	43	226	46	112466785726719815	np.linspace(0.5, 1, num=100)	226	19	226	47	-7944752429145521579
100	242	101	242	104	-9091418446569638221	model2_tf_idf.query(wiki[wiki['name'] == 'Barack Obama'], label='name', k=100)	242	27	242	105	1719940944405732062
100	259	26	259	29	5133976156923170395	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n             c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0,\n             label='Glu$^{194}_{\chi_2}$' if scaling==0 else '')	258	4	260	64	-7288212080889576576
100	262	32	262	35	621976877278369555	fig.savefig('test2png.png', dpi=100)	262	0	262	36	-5980675947091313790
100	284	13	284	16	-6105055297590049141	hist(-B,bins=100)	284	0	284	17	280283176463468349
100	292	17	292	20	-2510887365519416606	AdaBoostClassifier(base_estimator=None,\n    n_estimators=100,\n    learning_rate=1.0,\n    algorithm='SAMME.R',\n    random_state=0)	291	6	295	19	3879847835911676645
100	293	26	293	29	8606289570088566351	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n             c=cmap[1], s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0,\n             label='Glu$^{194}_{\chi_2}$' if scaling==0 else '')	292	4	294	64	-1606567550353342436
100	296	48	296	51	5219490558647963321	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 100, min_error_reduction=0.0)	295	23	296	77	7899162505430786056
100	317	55	317	58	-1929349621728577632	Basemap(projection = 'ortho', lat_0=50, lon_0=100,\n                resolution='l', area_thresh=1000.0)	317	9	318	51	-1246338715423113811
100	334	30	334	33	6951576042526770005	plt.hist(divergence_all, bins=100)	334	0	334	34	-1652707233612129462
100	350	21	350	24	5115656160183316703	plt.imshow(snow,vmax=100)	350	0	350	25	-2147188273775760518
100	358	22	358	25	-5333474352740314829	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n             c='g', s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	357	4	358	85	-4746189748040777434
100	366	18	366	21	1206038790326676716	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n         c='r', s=100, alpha=1, marker = 'o', edgecolor = 'k', linewidth = 1.0)	365	0	366	79	3855291344375119264
100	383	31	383	34	2417401848043271205	manifold.MDS(2, max_iter=100, n_init=1)	383	6	383	45	-5867606046585449730
100	386	67	386	70	-5374846833003911594	plt.imshow(snow[i],cmap=cmap,interpolation='none',vmin=0.,vmax=100)	386	4	386	71	-7833815694534699667
100	486	22	486	25	-1006429087222742307	ax.scatter(this.catalytic_rate, np.mean(this.flux_u + this.flux_b),\n             c='b', s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	485	4	486	85	-3952300051211583343
100	517	22	517	25	2338796264329336588	ax.scatter(this.offset_factor, np.mean(this.flux_u + this.flux_b),\n             c='g', s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	516	4	517	85	7984320912763148464
100	525	18	525	21	4337461680089991790	ax.scatter(this.offset_factor, np.mean(this.flux_u + this.flux_b),\n         c='r', s=100, alpha=1, marker = 'o', edgecolor = 'k', linewidth = 1.0)	524	0	525	79	3328580635593191323
100	526	88	526	91	2068934978410016659	plt.savefig('/gpfs01/bethge/home/oeberle/Results/offset_influence_0_1200_10.png', dpi = 100)	526	0	526	92	3260307474949238300
100	546	22	546	25	3064192425911297588	ax.scatter(this.cATP, np.mean(this.flux_u + this.flux_b),\n             c='g', s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	545	4	546	85	7189076843882524275
100	564	14	564	17	3227742491229527207	plt.scatter(D_t[:, 0],\n            D_t[:, 1],\n#             c=["b" if v=="Mr. Hi" else "r" for v in nx.get_node_attributes(G, "club").values()],\n#             c=nx.get_node_attributes(G, "value").values(),\n            c = [polbooks_colour_map[k] for k in nx.get_node_attributes(G,"value").values()],\n#             c=nx.get_node_attributes(G, "group").values(),\n#             c="k",\n            s=100)	557	0	564	18	-1498290310260849689
100	565	79	565	82	-5302282102185374618	plt.savefig('/gpfs01/bethge/home/oeberle/Results/offset_influence2.png', dpi = 100)	565	0	565	83	6333909714467888375
100	588	22	588	25	8340456230406573402	ax.scatter(this.load_slope, np.mean(this.flux_u + this.flux_b),\n             c='g', s=100, alpha=0.8, marker = 'o', edgecolor = 'k', linewidth = 1.0)	587	4	588	85	3562562982555487028
100	622	43	622	46	-2710191163233863415	.translate(yoff=100)	622	15	622	47	4250107163743778166
100	748	44	748	47	-2016115281790014635	RandomForestClassifier(n_estimators=100)	748	8	748	48	714926544902597962
100	1050	30	1050	33	1534529016155811675	LinearRegression(maxIter=100, elasticNetParam=0.8)	1050	5	1050	55	5230527457367912547
100	1074	42	1074	45	2300929682355577913	plt.bar(bin_edges[:-1], hist, width = 100)	1074	4	1074	46	-4405566931312707608
100	1205	35	1205	38	-3588399033027682814	LinearRegression(maxIter=100, elasticNetParam=0.8, labelCol="label", featuresCol = "features",\n                          predictionCol="prediction_lr")	1205	10	1206	56	1546084091642469398
100	1286	45	1286	48	2893408209019482853	gensim.models.ldamodel.LdaModel(corpus=mm,\n                                      id2word=dictionary,\n                                      num_topics=50,\n                                      update_every=1,\n                                      chunksize=10000,\n                                      passes=100)	1281	6	1286	49	7036574731868352903
100	1502	34	1502	37	-5965860590149126459	LinearRegression(maxIter=100, elasticNetParam=0.80, labelCol="label", featuresCol="pca_features",\n                      predictionCol = "prediction")	1502	9	1503	51	-6337022507967815887
150	58	47	58	50	8463752366269245816	netx.train( targetData, bal.T, epochs = 150, show = 30, goal =0.2)	58	7	58	73	1015187188201023494
150	82	24	82	27	-4693409456732516701	np.random.seed(seed=150)	82	4	82	28	3645627186228036707
2500	267	56	267	60	8188551560586189798	np.random.choice(np.arange(10000), size=2500)	267	16	267	61	-1706554558515340776
50	11	43	11	45	3164250003886046734	Basemap(projection='ortho', lat_0=50, lon_0=-20,\n              resolution='l', area_thresh=1000.0)	11	9	12	49	-7226940376843506435
50	13	30	13	32	5591126438898767460	text(.4,0.45,' - 2', fontsize=50)	13	0	13	33	4540482477756959825
50	14	31	14	33	1031992868199167730	text(.33,0.13,' - 3', fontsize=50)	14	0	14	34	-3294566735442550129
50	20	43	20	45	5794152504400989819	Basemap(projection='ortho', lat_0=50, lon_0=-20,\n              resolution='l', area_thresh=1000.0)	20	9	21	49	-6561150018105795321
50	20	45	20	47	-2495616105893909384	cv2.xfeatures2d.SIFT_create(nfeatures=50)	20	7	20	48	-5212980475750112688
50	23	43	23	45	-5934884573666030041	Basemap(projection='ortho', lat_0=50, lon_0=-100,\n              resolution='l', area_thresh=1000.0)	23	9	24	49	4410829943281391875
50	32	43	32	45	4833842411784669173	Basemap(projection='ortho', lat_0=50, lon_0=-20,\n              resolution='l', area_thresh=1000.0)	32	9	33	49	5505889177225759014
50	35	43	35	45	-7479426745294766957	Basemap(projection='ortho', lat_0=50, lon_0=-100,\n              resolution='l', area_thresh=1000.0)	35	9	36	49	-2009546522501161486
50	43	53	43	55	4760028493009051338	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	36	13	46	56	-4609451283332274812
50	50	43	50	45	421044716202131984	Basemap(projection='ortho', lat_0=50, lon_0=-100,\n              resolution='l', area_thresh=1000.0)	50	9	51	49	9099861773073577471
50	52	26	52	28	-4001543483703277198	plot_dist('dsi_dg', bins =50, plot_range=[-1,5],log=False)	52	0	52	58	-7424065675934757512
50	52	57	52	59	7835696312514838305	net.train( targetData, bal.T, epochs = 500, show = 50, goal =0.2)	52	6	52	71	-6876464549516138706
50	52	59	52	61	474123215231547023	solver.change_settings(learning_rate=0.01,num_episodes=50)	52	4	52	62	-2035072964222568846
50	62	58	62	60	7537895735722003295	Basemap(llcrnrlon=0,llcrnrlat=-50,urcrnrlon=360,urcrnrlat=50,projection='mill')	62	0	62	79	4758132665796981063
50	65	33	65	35	2337575575689905785	TruncatedSVD(n_components=50, random_state=0)	65	7	65	52	-4300682596563219482
50	79	41	79	43	1823763443411777925	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'l', area_thresh = 1000,\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	79	9	82	32	8596503024335138880
50	79	42	79	44	4787152693101223364	frontiere(f, X_test, y_pred, w=None, step=50, alpha_choice=1)	79	0	79	61	841005217914756798
50	91	56	91	58	-8315708608545506946	plt.scatter( lambda_1_true, lambda_2_true, c = "k", s = 50 )	91	0	91	60	-4922198903408312542
50	94	42	94	44	5742990971022782054	frontiere(f, X_test, y_pred, w=None, step=50, alpha_choice=1)	94	0	94	61	1692962304581988552
50	95	64	95	66	-8827172418166996686	plt.title('Combined Regular Season and Playoffs Data', fontsize=50)	95	0	95	67	6339078981391669679
50	95	100	95	102	2677147871540238443	datavis.animate(training_step, iterations=10000+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)	95	0	95	129	589201280056976940
50	97	41	97	43	-3389420667543795739	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'l', area_thresh = 0.1,\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	97	9	100	32	-3005191117477244044
50	99	52	99	54	-1774923024446546402	ax1.hist(theft_desc_word_count_small.tolist(), bins=50,histtype='bar' )	99	0	99	71	698030862989264688
50	101	56	101	58	5908609681551139526	plt.scatter( lambda_1_true, lambda_2_true, c = "k", s = 50 )	101	0	101	60	-1206163021298205994
50	103	50	103	52	-5144241912176896547	ax2.hist(theft_desc_word_count_mid.tolist(), bins=50,histtype='bar' )	103	0	103	69	-5133829448681498320
50	107	52	107	54	-3817181878945741861	ax3.hist(theft_desc_word_count_large.tolist(), bins=50,histtype='bar' )	107	0	107	71	-6925384414068611153
50	108	31	108	33	1800388495947484246	plt.title('Playoffs', fontsize=50)	108	0	108	34	-5821366524110840549
50	110	34	110	36	6737009678574662086	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
50	111	53	111	55	34757364941868346	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	104	13	114	56	-4357225614281537730
50	113	56	113	58	-6149241033422863930	plt.scatter( lambda_1_true, lambda_2_true, c = "k", s = 50 )	113	0	113	60	-732701280426664600
50	115	41	115	43	1637804086733187568	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	115	9	118	32	-4093210978899430732
50	116	81	116	83	-8267723451711225647	binaryUtils.diskAverage(s,r_out=3.0,bins=50,avgFlag=True)	116	40	116	97	-7244932113197378403
50	118	32	118	34	-3170885445634307679	plt.scatter(X3[:,0], X3[:,1], s=50, c=Y3, cmap=plt.cm.get_cmap('coolwarm', 2))	118	0	118	78	-2774657334904840832
50	119	59	119	61	-2459601483588661807	solver.change_settings(learning_rate=0.01,num_episodes=50)	119	4	119	62	5476921692751020544
50	121	31	121	33	-6984311568446924517	draw_signs(image_sample_size = 50, sign=np.argmin(hist[0]))	121	0	121	59	893354695042587107
50	124	56	124	58	7495763168992766824	plt.scatter( lambda_1_true, lambda_2_true, c = "k", s = 50 )	124	0	124	60	8312994435953533988
50	126	31	126	33	-2548817843891086399	draw_signs(image_sample_size = 50, sign=np.argmax(hist[0]))	126	0	126	59	2986255419878669971
50	133	41	133	43	-7980638780970869897	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	133	9	136	32	5557992257497168085
50	142	53	142	55	9216253576182989810	np.random.choice(np.arange(10000), size=50)	142	13	142	56	8088063566794949859
50	153	41	153	43	-2660687910268486065	ax.scatter(c_mean[0, 0], c_mean[0, 1], s=50, c='r')	153	0	153	51	4358646092018314380
50	154	53	154	55	-589693179009072826	SimpleRLPolicyGradientSolver(model, box,\n                                        update_rule='adam',\n                                        optim_config={\n                                            'learning_rate': 0.01,\n                                            'decay_rate': 1\n                                        },\n                                        init_rule='xavier',\n                                        num_episodes=50,\n                                        verbose=False,\n                                        supervised = False,\n                                        print_every=100)	147	13	157	56	-2869984644699322532
50	155	41	155	43	804536497349247789	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	155	9	158	32	8658093629239907608
50	158	41	158	43	-78323991409681560	ax.scatter(c_mean[1, 0], c_mean[1, 1], s=50, c='b')	158	0	158	51	-1366080221235627720
50	162	51	162	53	-4731833251114615977	ax.scatter3D(X[:, 0], X[:, 1], X[:, 2], c=y, s=50, marker="o", cmap='GnBu')	162	4	162	79	-6656723691967852629
50	162	59	162	61	-1660570721328344409	solver.change_settings(learning_rate=0.01,num_episodes=50)	162	4	162	62	3614535570655366502
50	171	15	171	17	-3609848220332861155	model.fit_generator(\n        train_generator,\n        steps_per_epoch=2000 // batch_size,\n        epochs=50,\n        validation_data=validation_generator,\n        validation_steps=800 // batch_size)	168	0	173	43	6420448193278954490
50	172	41	172	43	1292557398921850492	ax.scatter(c_mean[0, 0], c_mean[0, 1], s=50, c='r')	172	0	172	51	-5172733943950989868
50	177	41	177	43	-771113589865016183	ax.scatter(c_mean[1, 0], c_mean[1, 1], s=50, c='b')	177	0	177	51	6298936096978152359
50	177	41	177	43	3531693697360846920	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	177	9	180	32	7793756400611613911
50	202	41	202	43	4869600628859540693	Basemap(projection='lcc', lat_0=50, lon_0=-20,\n    resolution = 'i', area_thresh = 0.1, # i = intermediate resoltion, f = full resolution (might take a while!)\n    llcrnrlon=-2, llcrnrlat=50.5,\n    urcrnrlon=0, urcrnrlat=50.8)	202	9	205	32	940559479158808541
50	210	62	210	64	-8415663726014475813	pl.scatter(finalData['logUnits'], finalData['logEnergy'], s = 50, c = 'm', label='Actual Energy')	210	0	210	97	2341144310038671316
50	214	29	214	31	2529039026958679123	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color,\n               min_font_size=50, max_font_size=350)	212	5	214	51	-4958717031281068490
50	232	62	232	64	-7802920709459055150	pl.scatter(finalData['logEnergy'], finalData['logUnits'], s = 50, c = 'm', label='Actual Units')	232	0	232	96	5909621279098683220
50	255	13	255	15	3843717592949299427	dict(s=50, linewidth=.5, alpha = .8)	255	6	255	42	-8654527208677810202
50	257	62	257	64	7620693753032505748	pl.scatter(finalData['logUnits'], finalData['logEnergy'], s = 50, c = 'm', label='Actual Energy')	257	0	257	97	-5055878085685501645
50	264	46	264	48	5671008775244607854	binaryUtils.disk_scale_height(s,bins=50,gamma=1.4, mu=2.35)	264	9	264	68	-7266302994267739036
50	266	63	266	65	4899998540379523002	L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))	266	14	266	101	-5946685312802678040
50	278	29	278	31	-696389882063467502	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color2,\n               min_font_size=50, max_font_size=400)	276	5	278	51	6643972869516067525
50	279	57	279	59	-7081320733731674770	plt.scatter(points[:,0], points[:,1], linewidth=2, s=50, color='white', edgecolor='black', zorder=10)	279	4	279	105	-5637123221761941515
50	279	62	279	64	3942477921582315503	pl.scatter(finalData['logEnergy'], finalData['logUnits'], s = 50, c = 'm', label='Actual Units')	279	0	279	96	3727479482530986861
50	288	62	288	64	6878778899918715901	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	288	8	288	65	656766383827902049
50	291	41	291	43	-309543952525547514	scatter( data,1-assign_trace.mean(axis=0), cmap=cmap,\n        c=assign_trace.mean(axis=0), s = 50)	290	0	291	44	888127537973599020
50	293	75	293	77	4887346942196250310	sns.kdeplot(x1["r_Av fg%"], x1["r_ascore"],cmap = 'Spectral_r', n_levels = 50)	293	0	293	78	111437135034680420
50	313	19	313	21	-8342550555423222201	ax.hist(freq, bins=50,range=(0,100),normed=False)	313	0	313	49	-4867203624745933656
50	317	45	317	47	-2838158359071019883	Basemap(projection = 'ortho', lat_0=50, lon_0=100,\n                resolution='l', area_thresh=1000.0)	317	9	318	51	-1246338715423113811
50	325	41	325	43	8985213805764950963	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	325	0	325	55	-4610991424073830671
50	338	65	338	67	-6245595230146713033	ds_dis_subset.sigma_i.T.plot.contourf(cmap='bwr', levels=50)	338	8	338	68	3030622303945253738
50	346	41	346	43	2924246592522758580	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	346	0	346	55	-5087244531249955742
50	349	33	349	35	-1564211221831955776	plt.hlines(y = 0, xmin=0, xmax = 50)	349	0	349	36	-6257640178602341443
50	356	62	356	64	-4290426194208177108	ds_dis_subset.ct_i.T.plot.contourf(cmap='bwr', levels=50)	356	8	356	65	-5062656828196319028
50	377	62	377	64	7170072767461689062	ds_dis_subset.sa_i.T.plot.contourf(cmap='bwr', levels=50)	377	8	377	65	-21014232547504769
50	398	66	398	68	7505942783305487649	ds_dis_subset.oxygen_i.T.plot.contourf(cmap='bwr', levels=50)	398	8	398	69	5474446129993502065
50	409	23	409	25	7649297992729340337	nx.draw(G, node_size = 50, node_color = 'g')	409	0	409	44	-1247828311716697704
50	417	62	417	64	-2451249382626545782	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	417	8	417	65	3655740941668474552
50	420	23	420	25	3258851882109963279	nx.draw(H, node_size = 50, node_color='b')	420	0	420	42	6800188023142372862
50	429	23	429	25	7387366415193052902	nx.draw(I, node_size = 50, node_color='m')	429	0	429	42	-3451243788811679092
50	430	62	430	64	-2777942584226541033	ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)	430	8	430	65	-1297565595430734842
50	436	23	436	25	-8033052357573637084	nx.draw(J, node_size = 50, node_color='r')	436	0	436	42	5339649060855028550
50	441	63	441	65	-3648339963311201288	L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))	441	14	441	101	-6045862827087451637
50	443	23	443	25	-6978603322968606888	nx.draw(K, node_size = 50, node_color='y')	443	0	443	42	5658479294690718133
50	525	41	525	43	-2729085498775011490	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	525	0	525	55	-8586694503134461945
50	586	98	586	100	-3878372494141663631	bbmodel.fit(X_train_sample, [bbox_train_sample[:,i] for i in range(4)], batch_size= 32, nb_epoch= 50, verbose=2)	586	0	586	112	-7866280002810193536
50	722	41	722	43	1062766159986331176	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	722	0	722	55	-6748398069857227842
50	764	23	764	25	412158573453645394	PCA(n_components=50)	764	6	764	26	1131343086299196272
50	953	41	953	43	-1711503934720225861	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	953	0	953	55	6591770985517324848
50	988	75	988	77	-2060635975121505721	sns.kdeplot(win['team1_adjtempo'], win['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False, size = 5, aspect = 10,n_levels=50)	987	0	988	78	-1208705493962606294
50	992	73	992	75	-4428509919741454944	sns.kdeplot(loss['team1_adjtempo'], loss['Adjusted RPI'],cmap="Spectral_r",\n            shade=True, shade_lowest=False,size = 5,aspect = 10,n_levels=50)	991	0	992	76	2187852039882625447
50	1121	43	1121	45	-2640853007032525379	gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)	1121	8	1121	68	-5755679163829373569
50	1231	41	1231	43	-2649032440610105049	plt.scatter(temperature, D, color="k", s=50, alpha=0.5)	1231	0	1231	55	-6152741752927290978
50	1257	36	1257	38	-888771518451203923	plt.hist(lengths, normed=True, bins=50)	1257	0	1257	39	-6237344621783154911
50	1283	49	1283	51	-8300353651514683820	gensim.models.ldamodel.LdaModel(corpus=mm,\n                                      id2word=dictionary,\n                                      num_topics=50,\n                                      update_every=1,\n                                      chunksize=10000,\n                                      passes=100)	1281	6	1286	49	7036574731868352903
50	1291	41	1291	43	782605485993175703	lda.print_topics(topics=50)	1291	17	1291	44	5056532734705496073
50	1324	99	1324	101	40957553903947168	interact(pert_const.ptracers['nordicseas_50m'][:,:,:,:],matplotlib.cm.hot,-1,0,0,100,time1=0,time2=50)	1324	0	1324	102	-4325125842083220493
9	30	51	30	52	716802674114305930	plt.tick_params(axis='both', which='major', length=9)	30	0	30	53	-7611184250169776917
9	35	61	35	62	-4278496056914324668	pd.read_excel(url+'/pinc08_2_1_1.xls',header=9)	35	16	35	63	496922867056825830
9	36	64	36	65	-5611971606153665181	pd.read_excel(url+'/pinc08_2_1_4.xls', header=9)	36	18	36	66	-3844001163442339021
9	37	64	37	65	5738765808766515444	pd.read_excel(url+'/pinc08_2_1_6.xls', header=9)	37	18	37	66	6006723038473039081
9	38	67	38	68	-8013037627955749860	pd.read_excel(url+'/pinc08_2_1_9.xls', header=9)	38	21	38	69	-3818053194264108725
9	39	64	39	65	-4913408441236730301	pd.read_excel(url+'/pinc08_2_1_8.xls', header=9)	39	18	39	66	-5148403673488281934
9	44	64	44	65	9096529734991440281	pd.read_excel(url+'/pinc08_3_1_1.xls', header=9)	44	18	44	66	-143538400661506198
9	45	66	45	67	-2294066079250543092	pd.read_excel(url+'/pinc08_3_1_4.xls', header=9)	45	20	45	68	-2425445721914990796
9	46	66	46	67	-6292069319662373223	pd.read_excel(url+'/pinc08_3_1_6.xls', header=9)	46	20	46	68	727467460141042435
9	47	69	47	70	-3799246089026411003	pd.read_excel(url+'/pinc08_3_1_9.xls', header=9)	47	23	47	71	2594091513270894316
9	48	66	48	67	-1026347014993861703	pd.read_excel(url+'/pinc08_3_1_8.xls', header=9)	48	20	48	68	-5268401044980685107
9	101	19	101	20	114300781779051698	sh.cell_value(rowx=9,colx = 0)	101	0	101	30	-3942147808169811469
9	398	24	398	25	7856806534832147827	plt.clabel(CS, fontsize=9, inline=1)	398	0	398	36	2040321736911236875
9	407	24	407	25	-9112810262190769470	plt.clabel(CS, fontsize=9, inline=1)	407	0	407	36	-2289176966538127860
9	417	24	417	25	9212053257592691314	plt.clabel(CS, fontsize=9, inline=1)	417	0	417	36	1262263026211807309
66	350	72	350	74	-5060697047765493193	StratifiedKFold(y_temp, n_folds=10, shuffle=True, random_state=66)	350	9	350	75	3245634889605426771
128	98	49	98	52	-7365083862299577771	self.model.fit(\n            X, y, epochs=self.epochs, batch_size=128, callbacks=[checkpoint])	97	8	98	77	-7392014136833709480
128	111	46	111	49	-181969140994810726	model.fit(X_train, y_train, batch_size=128, epochs=10,\n          validation_split=0.2, callbacks=[checkpointer],\n          verbose=2, shuffle=True)	111	7	113	34	-1052891680331590484
128	144	68	144	71	-869079117426252929	conv_layer(h_pool1,   name='conv2_1', n_filters=128)	144	20	144	72	-7357682005977129182
128	145	68	145	71	110707933935333042	conv_layer(h_conv2_1, name='conv2_2', n_filters=128)	145	20	145	72	-1478278740746748634
128	148	42	148	45	-5342811638368836167	dict(batch_size = 128, im_shape = [227, 227], split = 'train', ml_root = ml_root, data_path = data_path, lexicon = data_list)	148	24	148	149	3961962479722334919
128	153	42	153	45	5264441865580340541	dict(batch_size = 128, im_shape = [227, 227], split = 'val', ml_root = ml_root, data_path = data_path, lexicon = data_list)	153	24	153	147	4827112126138213449
8	39	56	39	57	2254804146569557213	plt.plot(np.arange(1, 101), ss_sat.W1, 'ko', markersize=8)	39	0	39	58	-8067636730013451488
8	49	58	49	59	-8839943316869420303	plt.plot(np.arange(1, 101), ss_unsat.W1, 'ko', markersize=8)	49	0	49	60	-7457983838702366166
8	50	61	50	62	-1519002738954661637	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	50	0	50	63	-3035758443783020284
8	51	49	51	50	-3362506024138449627	ax1.set_ylabel("Departure Diversions\n",fontsize=8)	51	0	51	51	-5229171536460812259
8	51	61	51	62	-1155976828103690729	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	51	0	51	63	7181635582432038803
8	52	49	52	50	8843805483672093374	ax1.set_ylabel("Departure Diversions\n",fontsize=8)	52	0	52	51	-4761929991373303956
8	54	64	54	65	20485211163594432	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	54	0	54	66	4397103362290202681
8	55	49	55	50	-1445786123677695118	ax2.set_ylabel("Departure Diversions\n",fontsize=8)	55	0	55	51	-5341276631350721159
8	55	64	55	65	-4622477034826760444	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	55	0	55	66	8486413509403477259
8	56	49	56	50	2425452381410680970	ax2.set_ylabel("Departure Diversions\n",fontsize=8)	56	0	56	51	-3643400217515220310
8	58	60	58	61	3313030574428362744	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	58	0	58	62	-8946280272457331389
8	59	49	59	50	489422075022679184	ax3.set_ylabel("Departure Diversions\n",fontsize=8)	59	0	59	51	3439679405330742291
8	59	60	59	61	3175037426377756666	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	59	0	59	62	8962628942683293823
8	60	49	60	50	-3486151863599990280	ax3.set_ylabel("Departure Diversions\n",fontsize=8)	60	0	60	51	3487566691286892031
8	61	33	61	34	-8332615547192939925	fig.suptitle(title, fontsize=8)	61	4	61	35	-1033663058044247658
8	62	51	62	52	2441421108255493230	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	62	0	62	53	5503765647292606041
8	63	49	63	50	6774657699649925890	ax4.set_ylabel("Departure Diversions\n",fontsize=8)	63	0	63	51	2011105704327490515
8	63	51	63	52	-5801243996471620409	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	63	0	63	53	4664994892179785250
8	64	49	64	50	1771131816779369032	ax4.set_ylabel("Departure Diversions\n",fontsize=8)	64	0	64	51	7895498951691492140
8	66	48	66	49	-6902057945977043051	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	66	0	66	50	-7049976798422025423
8	67	48	67	49	6874080140053066073	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	67	0	67	50	-8894227352483103702
8	67	49	67	50	5021337655276196638	ax5.set_ylabel("Departure Diversions\n",fontsize=8)	67	0	67	51	-5201432852681298652
8	68	49	68	50	-1216609898743801187	ax5.set_ylabel("Departure Diversions\n",fontsize=8)	68	0	68	51	389972463304078772
8	70	50	70	51	781509770313863409	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	70	0	70	52	5837369270157966110
8	71	49	71	50	3379278051849640162	ax6.set_ylabel("Departure Diversions\n",fontsize=8)	71	0	71	51	-2678414581082797341
8	71	50	71	51	4437604296624073479	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	71	0	71	52	9207423907139553257
8	72	49	72	50	-5493229844835919396	ax6.set_ylabel("Departure Diversions\n",fontsize=8)	72	0	72	51	-6861952156178653565
8	74	51	74	52	-9027017543077624835	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	74	0	74	53	-332266128350225694
8	75	49	75	50	8525137761684360762	ax7.set_ylabel("Departure Diversions\n",fontsize=8)	75	0	75	51	2274829004968363100
8	75	51	75	52	-5323943681569872167	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	75	0	75	53	-8812967933691024198
8	76	49	76	50	-1969151663797901269	ax7.set_ylabel("Departure Diversions\n",fontsize=8)	76	0	76	51	-8874925384803739589
8	78	50	78	51	3197854728743311717	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	78	0	78	52	-6099102239577705403
8	79	49	79	50	9168524826746897912	ax8.set_ylabel("Departure Diversions\n",fontsize=8)	79	0	79	51	-8083416750118422739
8	79	50	79	51	5241010750662022998	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	79	0	79	52	9156253897750857735
8	80	49	80	50	-6627841742584106704	ax8.set_ylabel("Departure Diversions\n",fontsize=8)	80	0	80	51	-2845217341450256555
8	86	19	86	20	-5833983620414916302	sh.cell_value(rowx=8,colx = 0)	86	0	86	30	6805192037892254588
8	89	61	89	62	4711780505856901171	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	89	0	89	63	-3035258037922652119
8	90	52	90	53	5273602365850376761	ax1.set_ylabel("Departure Cancellations\n",fontsize=8)	90	0	90	54	-4247568975645055293
8	90	61	90	62	5170648521592782174	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	90	0	90	63	-6765379224493738516
8	91	52	91	53	4711156086799488900	ax1.set_ylabel("Departure Cancellations\n",fontsize=8)	91	0	91	54	6236811456853493010
8	91	62	91	63	-9074039311593086756	cv2.connectedComponentsWithStats(~bw, connectivity = 8)	91	9	91	64	4428638810844714036
8	92	61	92	62	-8960720780730219313	plt.plot(np.arange(1, 101), ss_quad_sat.W1, 'ko', markersize=8)	92	0	92	63	3994414759783581699
8	93	64	93	65	-8051225142891885363	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	93	0	93	66	6796119329380740990
8	94	40	94	41	8739631042658624020	ax[0].plot(k_0[:,i],'-x',markersize=8,label=labels[i],color=colors[i])	94	4	94	74	7695630884035129277
8	94	52	94	53	8909315695018812194	ax2.set_ylabel("Departure Cancellations\n",fontsize=8)	94	0	94	54	-8804040248627619064
8	94	64	94	65	-962493919880648813	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	94	0	94	66	-2591904929614197054
8	95	52	95	53	5159623129770687981	ax2.set_ylabel("Departure Cancellations\n",fontsize=8)	95	0	95	54	-5433988858280825203
8	96	40	96	41	-2987030926133330934	ax[1].plot(k_1[:,i],'-x',markersize=8,label=labels[i],color=colors[i])	96	4	96	74	-91154651071948165
8	97	60	97	61	7882577714701640365	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	97	0	97	62	-206527259295806766
8	98	52	98	53	-7250231364403871319	ax3.set_ylabel("Departure Cancellations\n",fontsize=8)	98	0	98	54	5742407716237552364
8	98	60	98	61	5456012608460131304	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	98	0	98	62	-8854475485709709031
8	99	52	99	53	-8958495558858926723	ax3.set_ylabel("Departure Cancellations\n",fontsize=8)	99	0	99	54	6986657752680643406
8	101	51	101	52	493960846624848271	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	101	0	101	53	-2966701054071896351
8	102	51	102	52	-7363516888982751579	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	102	0	102	53	-7490264702632501450
8	102	52	102	53	2957491209502452877	ax4.set_ylabel("Departure Cancellations\n",fontsize=8)	102	0	102	54	3110948545199459412
8	102	63	102	64	-8591307584518074940	plt.plot(np.arange(1, 101), ss_quad_unsat.W1, 'ko', markersize=8)	102	0	102	65	5961003080553624806
8	103	17	103	18	-5230705822170554270	fig.scatter(source=lda_src, x='x', y='y',\n            size=8, line_color='black', line_alpha=0.5,\n            fill_color='color')	102	0	104	31	-5257334578748382170
8	103	52	103	53	6456595227025877565	ax4.set_ylabel("Departure Cancellations\n",fontsize=8)	103	0	103	54	270378316821013573
8	105	48	105	49	4630669853626978321	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	105	0	105	50	-8033103233663609442
8	106	48	106	49	-3828711664705196903	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	106	0	106	50	-7984455599491399763
8	106	52	106	53	6349634505668493934	ax5.set_ylabel("Departure Cancellations\n",fontsize=8)	106	0	106	54	-4428765733252832150
8	107	25	107	26	-2511454190754577074	bx.tick_params(labelsize=8)	107	0	107	27	-5892367367953133265
8	107	51	107	52	2893811757221998180	plt.legend('train',loc = 'upper right', fontsize = 8)	107	0	107	53	-946503250983561875
8	107	52	107	53	-4356198653984185856	ax5.set_ylabel("Departure Cancellations\n",fontsize=8)	107	0	107	54	-82797031377234690
8	109	50	109	51	-7597180766259760537	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	109	0	109	52	-7191569976007340011
8	110	50	110	51	-8745170451456554813	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	110	0	110	52	293510620377226335
8	110	52	110	53	-3251977781870609996	ax6.set_ylabel("Departure Cancellations\n",fontsize=8)	110	0	110	54	2412929108692815630
8	111	52	111	53	-6725508011431213722	ax6.set_ylabel("Departure Cancellations\n",fontsize=8)	111	0	111	54	9011197910324226326
8	113	51	113	52	4207213124036553469	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	113	0	113	53	-1143485705188460221
8	113	73	113	74	3449576121649084724	plt.plot(np.arange(1, 101), ss_quad_sat.W1 - ss_sat.W1, 'ko', markersize=8)	113	0	113	75	6767509467704312178
8	114	51	114	52	-4081257713664153771	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	114	0	114	53	-9148893383499579625
8	114	52	114	53	63125022992341306	ax7.set_ylabel("Departure Cancellations\n",fontsize=8)	114	0	114	54	-5359150083282511558
8	115	52	115	53	3880371781809866197	ax7.set_ylabel("Departure Cancellations\n",fontsize=8)	115	0	115	54	-5794076189122674549
8	116	46	116	47	-1562616217604316151	ax1.tick_params('both', which='major', length=8, width=1)	116	0	116	57	1122850074783823134
8	117	50	117	51	6547815599428638954	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	117	0	117	52	1650363421393523158
8	118	50	118	51	-2594757503011000904	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	118	0	118	52	8485251193803007892
8	118	52	118	53	-1446760055220984068	ax8.set_ylabel("Departure Cancellations\n",fontsize=8)	118	0	118	54	-5596237751434153336
8	119	52	119	53	-2524371764691137409	ax8.set_ylabel("Departure Cancellations\n",fontsize=8)	119	0	119	54	2724401104231258845
8	123	77	123	78	8671855331310252976	plt.plot(np.arange(1, 101), ss_quad_unsat.W1 - ss_unsat.W1, 'ko', markersize=8)	123	0	123	79	-841819015233095875
8	128	61	128	62	-5704521138058050459	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	128	0	128	63	2147080371900167059
8	129	47	129	48	2449022056748289980	ax1.set_ylabel("Arrival Diversions\n",fontsize=8)	129	0	129	49	-6326926968312422290
8	129	61	129	62	-7310149068377685219	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	129	0	129	63	5038361242173352398
8	130	46	130	47	6929071258063804778	ax1.tick_params('both', which='major', length=8, width=1)	130	0	130	57	3655823880282572057
8	130	47	130	48	-6834464645904188267	ax1.set_ylabel("Arrival Diversions\n",fontsize=8)	130	0	130	49	970498671408837973
8	131	49	131	50	1437469888900089522	sm.graphics.influence_plot(ols_model, size=8)	131	6	131	51	-2633299962686840665
8	132	64	132	65	-5741132766188690541	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	132	0	132	66	2933809090850048019
8	133	47	133	48	-5923668489958116360	ax2.set_ylabel("Arrival Diversions\n",fontsize=8)	133	0	133	49	8910157753680240279
8	133	64	133	65	7497555644034357642	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	133	0	133	66	-4679693921964336332
8	134	47	134	48	8102233331355399379	ax2.set_ylabel("Arrival Diversions\n",fontsize=8)	134	0	134	49	3290925379638880183
8	136	25	136	26	-4120030134175815143	cx.tick_params(labelsize=8)	136	0	136	27	8251086050692673694
8	136	60	136	61	-966166783495197813	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	136	0	136	62	-4558176988129951777
8	137	25	137	26	3270882738918682960	fig.scatter(source=src, x='x', y='y', fill_color='color',\n                    size=8, line_alpha=0.5, line_color='black')	136	8	137	63	2648762627058030416
8	137	47	137	48	7868562920262945990	ax3.set_ylabel("Arrival Diversions\n",fontsize=8)	137	0	137	49	3072961377047842342
8	137	60	137	61	4486005789140280097	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	137	0	137	62	1475901241457553622
8	138	47	138	48	9094843677608404596	ax3.set_ylabel("Arrival Diversions\n",fontsize=8)	138	0	138	49	-4908662051588254693
8	140	51	140	52	1109698829870917906	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	140	0	140	53	-6243242265639796312
8	141	47	141	48	3669228668566891601	ax4.set_ylabel("Arrival Diversions\n",fontsize=8)	141	0	141	49	2078917728684100658
8	141	48	141	49	-7439314700913947695	processor(vtpredict, model, nprocessor=1, timeslice='auto', vis_slices=31,\n                         oversampling=4, facets=8, wstep=advice['w_sampling_primary_beam'])	140	15	141	91	8017141038555901416
8	141	51	141	52	4641211057471815409	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	141	0	141	53	8610125060235706635
8	142	15	142	16	-8168982035346753531	plt.legend(loc=8)	142	0	142	17	1285672016936366346
8	142	47	142	48	-4990123480102307229	ax4.set_ylabel("Arrival Diversions\n",fontsize=8)	142	0	142	49	2607767548774004015
8	144	48	144	49	-5227350225379624186	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	144	0	144	50	-6474547781542441043
8	145	47	145	48	8797047041860720973	ax5.set_ylabel("Arrival Diversions\n",fontsize=8)	145	0	145	49	322052959831490373
8	145	48	145	49	3923766085162137611	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	145	0	145	50	-6639711188869322848
8	146	47	146	48	-8108599553208570684	ax5.set_ylabel("Arrival Diversions\n",fontsize=8)	146	0	146	49	-7008929446756940822
8	148	50	148	51	-6727303673333121604	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	148	0	148	52	8992121640349883643
8	149	46	149	47	-6899588006543790685	ax1.tick_params('both', which='major', length=8, width=1)	149	0	149	57	3906196640348417477
8	149	47	149	48	8523356718650041915	ax6.set_ylabel("Arrival Diversions\n",fontsize=8)	149	0	149	49	598135211425481181
8	149	50	149	51	-6127029269193213059	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	149	0	149	52	-7401424250640960637
8	150	47	150	48	7421109929511294000	ax6.set_ylabel("Arrival Diversions\n",fontsize=8)	150	0	150	49	-8572964892947430637
8	152	51	152	52	5877028803876975088	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	152	0	152	53	-7390470020202117655
8	153	47	153	48	-7832819932129537363	ax7.set_ylabel("Arrival Diversions\n",fontsize=8)	153	0	153	49	2042462354961047320
8	153	51	153	52	-7503253431128291242	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	153	0	153	53	4369979802434608781
8	154	47	154	48	-5647193133465736221	ax7.set_ylabel("Arrival Diversions\n",fontsize=8)	154	0	154	49	-3078727439064596341
8	156	50	156	51	-4388015188905828184	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	156	0	156	52	-5248711942555699859
8	157	9	157	10	-5693347646066442765	log_data.plot(kind='box', subplots=True, layout=(3,2), sharex=False, sharey=False,\nfontsize=8)	156	0	157	11	3170444961094405716
8	157	47	157	48	-2647464201614161032	ax8.set_ylabel("Arrival Diversions\n",fontsize=8)	157	0	157	49	-8873818419216679348
8	157	50	157	51	-512072792720742145	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	157	0	157	52	-6301789198957574145
8	158	47	158	48	6895445430674408218	ax8.set_ylabel("Arrival Diversions\n",fontsize=8)	158	0	158	49	-2778581464587079687
8	167	61	167	62	-1037703943068472335	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	167	0	167	63	5532574989915564113
8	168	50	168	51	-4467356917877693671	ax1.set_ylabel("Arrival Cancellations\n",fontsize=8)	168	0	168	52	2322374405027210964
8	168	61	168	62	-905609153917799391	ax1.set_xlabel("\nAverage Delay for Gate Departure",fontsize=8)	168	0	168	63	5761607156172872410
8	169	50	169	51	-238702970736580555	ax1.set_ylabel("Arrival Cancellations\n",fontsize=8)	169	0	169	52	-6438814068810230460
8	171	64	171	65	-4010605505109692085	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	171	0	171	66	3406978987205587726
8	172	50	172	51	-6564894519872860297	ax2.set_ylabel("Arrival Cancellations\n",fontsize=8)	172	0	172	52	-6333088789875876810
8	172	64	172	65	-7817303547264063546	ax2.set_xlabel("\nAverage Delay for Airport Departure",fontsize=8)	172	0	172	66	-4337841547719201857
8	173	50	173	51	-1380714793882998298	ax2.set_ylabel("Arrival Cancellations\n",fontsize=8)	173	0	173	52	4764525262108856194
8	175	60	175	61	3956629076884278093	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	175	0	175	62	5311555550221621430
8	176	50	176	51	-98821463013028706	ax3.set_ylabel("Arrival Cancellations\n",fontsize=8)	176	0	176	52	-136098489316663952
8	176	60	176	61	2489826353019156629	ax3.set_xlabel("\nAverage Delay for Gate Arrivals",fontsize=8)	176	0	176	62	-883696618119095375
8	177	18	177	19	-399111572315442617	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=['o', 'o']),\n           size = 8, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	176	4	177	83	4015445777837850583
8	177	50	177	51	2901751093641689057	ax3.set_ylabel("Arrival Cancellations\n",fontsize=8)	177	0	177	52	7638805937406767050
8	179	51	179	52	6646426480392377200	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	179	0	179	53	-4231227415566824979
8	180	50	180	51	-6036383013367734274	ax4.set_ylabel("Arrival Cancellations\n",fontsize=8)	180	0	180	52	-2750955043660442539
8	180	51	180	52	4213647421602174699	ax4.set_xlabel("\nAverage Airborne Delay",fontsize=8)	180	0	180	53	4380217828447783790
8	181	50	181	51	-4524023917010840212	ax4.set_ylabel("Arrival Cancellations\n",fontsize=8)	181	0	181	52	-3351448778269932064
8	183	48	183	49	-8926540844283733252	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	183	0	183	50	643582323728651942
8	184	48	184	49	-2778951939316180710	ax5.set_xlabel("\nAverage Block Delay",fontsize=8)	184	0	184	50	7433185858293716827
8	184	50	184	51	-6501379239432020641	ax5.set_ylabel("Arrival Cancellations\n",fontsize=8)	184	0	184	52	-8311646671600184559
8	185	50	185	51	-3902068449592553557	ax5.set_ylabel("Arrival Cancellations\n",fontsize=8)	185	0	185	52	4613102090571755455
8	187	50	187	51	-5369410415267882159	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	187	0	187	52	-6781500144938920210
8	188	50	188	51	-4382530238979423	ax6.set_xlabel("\nAverage Taxi Out Time",fontsize=8)	188	0	188	52	7220301624060677095
8	188	50	188	51	4729548667450896589	ax6.set_ylabel("Arrival Cancellations\n",fontsize=8)	188	0	188	52	-375783722810699670
8	189	50	189	51	-8837026071978687951	ax6.set_ylabel("Arrival Cancellations\n",fontsize=8)	189	0	189	52	-3580644464523739965
8	191	43	191	44	4713298617681099516	fig.scatter(X_iso[:, 0], X_iso[:, 1], size=8, alpha=0.8, line_color='black',\n            fill_color=pal.linear_map(y, seqcolors))	191	0	192	52	4685401958031439462
8	191	51	191	52	-1620094950810020236	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	191	0	191	53	-6374168406824027121
8	192	50	192	51	6204466865740037150	ax7.set_ylabel("Arrival Cancellations\n",fontsize=8)	192	0	192	52	-2751136213396662050
8	192	51	192	52	-7091445754009048757	ax7.set_xlabel("\nAverage Taxi Out Delay",fontsize=8)	192	0	192	53	775016783881861343
8	193	50	193	51	1502769793906200699	ax7.set_ylabel("Arrival Cancellations\n",fontsize=8)	193	0	193	52	-5910385522028622767
8	195	50	195	51	7364567722722137236	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	195	0	195	52	-5316900636752573432
8	196	50	196	51	-5430595819828180351	ax8.set_xlabel("\nAverage Taxi In Delay",fontsize=8)	196	0	196	52	1927576331661385788
8	196	50	196	51	4896427515865051139	ax8.set_ylabel("Arrival Cancellations\n",fontsize=8)	196	0	196	52	6506582859012021577
8	197	50	197	51	4781662255043016175	ax8.set_ylabel("Arrival Cancellations\n",fontsize=8)	197	0	197	52	2278496431221494756
8	201	50	201	51	-6948010920366580365	sm.graphics.influence_plot(ols_model2, size=8)	201	6	201	52	-6265962220418300408
8	205	18	205	19	1348145027490766575	sns.FacetGrid(data = genome_stats, sharex=False, hue_kws=dict(marker=["o", 'o']),\n           size = 8, aspect = 4, palette=sns.xkcd_palette(colors), hue = 'paralog')	204	4	205	83	-2212431255073768163
8	223	62	223	63	7814792815844322507	KMeans(init='random',n_clusters=Kcents, n_init=5, n_jobs=8)	223	5	223	64	9029266415401378686
8	227	17	227	18	3881092690122683677	fig.scatter(source=src, x='x', y='y', fill_color='color',\n            size=8, line_color='black', line_alpha=0.50)	226	0	227	56	-6899561063814218809
8	231	25	231	26	-6964333956517733412	sn.lmplot(x='tp', y='pb_rich', hue='country', data=df,\n          ci=False, size=8, markers='x',\n          scatter_kws={'s': 100})	230	0	232	33	1594371828869105640
8	239	18	239	19	4806303613476155095	sns.FacetGrid(data = genome_stats[genome_stats['paper1_LG'] == 2], sharex=False, hue_kws=dict(marker=["o", 'o']),\n           size = 8, aspect = 1, palette=sns.xkcd_palette(reversed(colors)), hue = 'paralog')	238	4	239	93	-8855636080202238515
8	239	42	239	43	-7530536630500775431	loglog(2**bins, var_rat1, 'b-o', lw=4, ms=8, label="F469N / F547M")	239	0	239	67	-7540245251168728170
8	239	73	239	74	6914232286331211070	ax1.scatter(agn['MR'], agn['MU_MR'], marker='o', color='r', alpha=0.6, s=8)	239	0	239	75	8422944491344916218
8	240	42	240	43	-4470799646831005393	loglog(2**bins, var_rat2, 'g-o', lw=4, ms=8, label="FQ575N / F547M")	240	0	240	68	8296523403322069540
8	241	52	241	53	-2684969513138574755	loglog(2**bins, np.array(var_rat3), 'r-o', lw=4, ms=8, label="FQ575N' / FQ575N")	241	0	241	80	-5534447510283819778
8	242	68	242	69	-8431940262923997029	loglog(2**bins, var_rat2 - 0.5*np.array(var_rat3), 'g--o', lw=4, ms=8, label="Noise-subtracted")	242	0	242	96	3544779426463737851
8	243	80	243	81	7507074096968786980	loglog(2**bins, var_rat1 - 0.542*(20./18.)*np.array(var_rat3), 'b--o', lw=4, ms=8, label="Noise-subtracted")	243	0	243	108	-1022494361570411340
8	247	25	247	26	7614376049187040124	sn.lmplot(x='tp', y='pb_rich', data=df, logx=True,\n          ci=False, size=8, markers='x',\n          scatter_kws={'s': 100})	246	0	248	33	-9191835371339557598
8	255	81	255	82	-6868664643530227550	ax1.scatter(agn['AVG_MASS'], agn['AVG_SFR'], marker='o', color='r', alpha=0.6, s=8)	255	0	255	83	4692650844590346553
8	274	45	274	46	2104942972762202784	sm.graphics.influence_plot(model, size=8)	274	6	274	47	-1382079041211150333
8	276	66	276	67	3136306230135893173	cv2.connectedComponentsWithStats(tmpimg, connectivity = 8)	276	10	276	68	-7789007913904160529
8	283	70	283	71	-1097502923584464086	cv2.connectedComponentsWithStats(tmplabelimg, connectivity = 8)	283	9	283	72	7108848138671267353
8	298	70	298	71	3811099175592365106	ax.plot(x, x+15, color="purple", lw=1, ls='-', marker='o', markersize=8, markerfacecolor="red")	298	0	298	95	1844061538920874073
8	299	70	299	71	-661209935024065188	ax.plot(x, x+16, color="purple", lw=1, ls='-', marker='s', markersize=8,\n        markerfacecolor="yellow", markeredgewidth=2, markeredgecolor="blue")	299	0	300	76	3735684027595230213
8	305	78	305	79	6764585645885472658	cv2.connectedComponentsWithStats(tmplabelimg, connectivity = 8)	305	17	305	80	-5991947806860865857
8	306	46	306	47	6272052627331894282	sm.graphics.influence_plot(model2, size=8)	306	6	306	48	-1462316658834221774
8	363	42	363	43	-1595167137089759241	loglog(2**bins, var_rat1, 'b-o', lw=4, ms=8, label="F487N / F547M")	363	0	363	67	7290680850656380248
8	364	42	364	43	-3337841705631877684	loglog(2**bins, var_rat2, 'g-o', lw=4, ms=8, label="FQ575N / F547M")	364	0	364	68	7582873215992508395
8	365	52	365	53	-5781226296569658589	loglog(2**bins, np.array(var_rat3), 'r-o', lw=4, ms=8, label="FQ575N' / FQ575N")	365	0	365	80	4538333058581162755
8	366	70	366	71	-5905044578886321364	loglog(2**bins, var_rat2 - 0.542*np.array(var_rat3), 'g--o', lw=4, ms=8, label="Noise-subtracted")	366	0	366	98	-7715590813676572399
8	367	72	367	73	1328259402617204836	loglog(2**bins, var_rat1 - (0.5/8)*np.array(var_rat3), 'b--o', lw=4, ms=8, label="Noise-subtracted")	367	0	367	100	-7948134963923945720
8	415	68	415	69	-1849103490258318802	ax.text(row.x, row.y, "{0:03d}".format(row.stickerID), fontsize=8)	415	4	415	70	4991748648909850146
8	516	68	516	69	-6644904964689555555	ax.text(row.x, row.y, "{0:03d}".format(row.stickerID), fontsize=8)	516	4	516	70	-714015686210350733
75	111	38	111	40	8221892917644374771	display2.plot_ppi('dBZ',vmin=-25,vmax=75)	111	0	111	41	-9181395506443244106
75	151	60	151	62	-3759650580563761555	plt.scatter(challenger_data[:, 0], challenger_data[:, 1], s=75, color="k",alpha=0.5)	151	0	151	84	-5335922479747656914
75	167	37	167	39	-6439819167383106770	display.plot_ppi('dBZ',vmin=-25,vmax=75)	167	0	167	40	2021120921327381960
75	167	64	167	66	-1458198805370496570	plt.scatter(challenger_data[:, 0], challenger_data[:, 1], s=75, color="k", alpha=0.5)	167	4	167	89	610219550181141635
75	185	37	185	39	1442999020088542330	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=1)	185	0	185	48	-3417475230800158610
75	202	37	202	39	759212648876083398	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=0)	202	0	202	48	-1078832887598625434
75	204	37	204	39	8689806332887879794	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=1)	204	0	204	48	-6654751671107252780
75	206	37	206	39	-2745150694055778097	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=2)	206	0	206	48	-1282925691893218194
75	208	37	208	39	-78316949374838164	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=3)	208	0	208	48	-1965368415360285197
75	210	37	210	39	3786219617348803254	display.plot_ppi('dBZ',vmin=-25,vmax=75,sweep=4)	210	0	210	48	6513579083717035187
75	300	37	300	39	44668892451134702	display.plot_ppi('dBZ',vmin=-25,vmax=75)	300	0	300	40	-7532797693041848985
25	18	24	18	26	-3558594777693837024	plot(x,y, c='k', lw=25)	18	4	18	27	-6603752511365779134
25	27	26	27	28	5960809339592819276	setup_text_plots(fontsize=25, usetex=True)	27	0	27	42	3691348585376746777
25	53	65	53	67	-1188592491363957690	tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)	53	5	53	68	-774357996331057342
25	94	26	94	28	1252540882170959462	plt.tick_params(labelsize=25)	94	0	94	29	8249794959490418705
25	104	59	104	61	-5166037375953769339	create_class_visualization(target_y, model, show_every=25)	104	4	104	62	-2760730339206358673
25	107	26	107	28	2839923905094397969	plt.tick_params(labelsize=25)	107	0	107	29	-6425253451258187966
25	108	29	108	31	-2087380525759463809	Solver(model, small_data,\n                  num_epochs=25, batch_size=100,\n                  update_rule='adam',\n                  optim_config={\n                    'learning_rate': 5e-4,\n                  },\n                  verbose=True, print_every=100)	107	11	113	48	6160983272379773386
25	187	34	187	36	-4626479882803218593	manifold.Isomap(n_neighbors=25, n_components=2)	187	6	187	53	1626133110710677441
25	231	30	231	32	-6425165358290252952	np.set_printoptions(precision=25)	231	0	231	33	5972284034919205826
25	254	39	254	41	-6614019010308597453	plt.hist(y, label=['1st', '2nd'], bins=25)	254	0	254	42	8606295623420035334
25	445	40	445	42	-5003822815696733851	ax.scatter(strike, ttm, iv, zdir='z', s=25,\n           c='b', marker='^')	445	0	446	29	-3089428530162990147
25	520	39	520	41	8437914286418580137	animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=25, blit=True)	519	6	520	53	91379602409116105
25	940	98	940	100	-6917136392776735641	sns.kdeplot(win['team1_adjde'], win['Adjusted RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False, size = 10, aspect = 'equal',kind = 'kde',n_levels=25)	939	4	940	101	-1935959028215653032
25	955	98	955	100	-1315517632627163494	sns.kdeplot(win['team1_adjde'], win['RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False, size = 10, aspect = 'equal',kind = 'kde',n_levels=25)	954	4	955	101	6355256911657107609
25	965	84	965	86	-4938376429897698561	sns.kdeplot(loss['team1_adjde'], loss['Adjusted RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False,size = 10, aspect = 'equal',n_levels=25)	964	4	965	87	-2402006676199883176
25	974	84	974	86	1384571897416537109	sns.kdeplot(loss['team1_adjde'], loss['RPI'],cmap="Spectral_r",\n                shade=True, shade_lowest=False,size = 10, aspect = 'equal',n_levels=25)	973	4	974	87	8140729054097177418
25	1075	68	1075	70	523847467843784568	plot_other_features(coef_other[:,i], feature_names_other, top_n=25)	1075	4	1075	71	1032254459212316769
14	8	34	8	36	3877763848270659843	YouTubeVideo('6O43gOxtaWo', start=14)	8	0	8	37	-5132031459297525275
14	29	54	29	56	2722909910991610360	plt.tick_params(axis='both', which='major', labelsize=14)	29	0	29	57	-6411355584629824903
14	42	33	42	35	6515072394825768386	ax.set_title(title, fontsize=14)	42	4	42	36	-5402503911021199688
14	45	39	45	41	6191539724001166418	plt.xlabel('UTC Time (Hours)',fontsize=14)	45	0	45	42	-1574968951311670835
14	46	40	46	42	-2078213250017353801	plt.ylabel('Altitude (Meters)',fontsize=14)	46	0	46	43	-7064785223398201008
14	53	25	53	27	-6389731139530962102	plt.xlabel('x', fontsize=14)	53	0	53	28	3226354919649661232
14	54	25	54	27	4273946355196275030	plt.ylabel('y', fontsize=14)	54	0	54	28	-4598094985237515953
14	57	33	57	35	8797512621456911199	fig.suptitle(title, fontsize=14, fontweight='bold')	57	4	57	55	-4619781621225253319
14	60	97	60	99	-5677858677724157771	plt.colorbar().set_label('Signal (arb.)', rotation=270, verticalalignment='center', fontsize=14)	60	4	60	100	6511050812760249285
14	65	102	65	104	6661164738168863492	plt.colorbar().set_label('Standard Deviation', rotation=270, verticalalignment='center', fontsize=14)	65	4	65	105	2911667611248753965
14	70	87	70	89	-4757950337494965676	plt.colorbar().set_label('SNR', rotation=270, verticalalignment='center', fontsize=14)	70	4	70	90	2422333462333185356
14	75	97	75	99	-8535626790851696206	plt.colorbar().set_label('Signal (arb.)', rotation=270, verticalalignment='center', fontsize=14)	75	4	75	100	6875132002801552063
14	80	87	80	89	-3779125056330056385	plt.colorbar().set_label('SNR', rotation=270, verticalalignment='center', fontsize=14)	80	4	80	90	-5102735535965125224
14	109	27	109	29	-8957763972957550428	plt.xlabel('Time',fontsize=14)	109	0	109	30	-6183421052043941035
14	110	31	110	33	1083067060771818041	plt.ylabel('Altitude',fontsize=14)	110	0	110	34	7781662372389986342
14	148	42	148	44	1465304685800352816	ax1.set_xlabel('UTC Time (Hour)',fontsize=14)	148	0	148	45	893723005113758012
14	149	37	149	39	3577330251223322275	ax1.set_ylabel('Height (m)',fontsize=14)	149	0	149	40	-8921639809816143206
14	169	108	169	110	4976917541739866895	plt.title("Logistic functon  plotted for several values of $\\alpha$ and $\\beta$ parameters", fontsize=14)	169	4	169	111	3472044665434047490
14	188	44	188	46	8987831857599926433	plt.legend(loc='best',frameon=True,fontsize=14)	188	0	188	47	-2614221149769572647
14	220	44	220	46	7122617444422441918	plt.legend(loc='best',frameon=True,fontsize=14,bbox_to_anchor=(1,1))	220	0	220	68	2321040664426707722
14	296	26	296	28	-4500590612305053188	plt.suptitle(("Silhouette analysis for Gaussian Mixture Model clustering on reduced data "\n                  "with n_clusters = %d" % n_clusters),\n                 fontsize=14, fontweight='bold')	294	4	296	48	-1295786877666744264
14	326	45	326	47	1631064838546563887	plt.suptitle("Manifold Learning with %i points, %i neighbors"\n             % (1000, n_neighbors), fontsize=14)	325	0	326	48	-8875818663606361774
14	376	79	376	81	-562732892706093362	decision_tree_create(train_data, features, 'safe_loans', max_depth = 14,\n                                min_node_size = 0, min_error_reduction=-1)	376	10	377	74	-8440472025689625761
14	422	54	422	56	8643019402676245782	plt.text(55, .027, r'$\mu=100,\ \sigma=15$', fontsize=14)	422	0	422	57	-1621317778397420076
14	425	26	425	28	-3238788624160522822	plt.suptitle(("Silhouette Analysis for KMeans Clustering on Sample Data "\n                  "with %d Clusters" % n_clusters),\n                 fontsize=14, fontweight='bold')	423	4	425	48	-2969439471878043151
14	438	26	438	28	-7657557519344609162	plt.suptitle(("Silhouette Analysis for KMeans Clustering on Sample Data "\n                  "with %d Clusters" % n_clusters),\n                 fontsize=14, fontweight='bold')	436	4	438	48	2785915972854484088
14	439	20	439	22	-2919153440214448293	plt.clabel(CS, levels[1::2],  # label every second level\n           inline=1,\n           fmt='%1.1f',\n           fontsize=14)	436	0	439	23	3127135430133223689
14	448	90	448	92	-2142140175538834278	ax1.set_title('Distribution of Average Airport\n Departure Delay by Clusters\n', fontsize=14)	448	0	448	93	-3397417587488924596
14	453	80	453	82	4208792228439832708	ax2.set_title('Distribution of Average Taxi\n Out Time by Clusters\n', fontsize=14)	453	0	453	83	-8910311978267551570
14	458	81	458	83	-3858632699820674018	ax3.set_title('Distribution of Average Taxi\n Out Delay by Clusters\n', fontsize=14)	458	0	458	84	-5722178727676149024
14	461	90	461	92	-7169830266081199419	ax1.set_title('Distribution of Average Airport\n Departure Delay by Clusters\n', fontsize=14)	461	0	461	93	-9142556109423709902
14	466	80	466	82	-8923402902093268588	ax2.set_title('Distribution of Average Taxi\n Out Time by Clusters\n', fontsize=14)	466	0	466	83	-4412095338091334532
14	468	70	468	72	-8252482413008209833	ax1.set_title('Distribution of Cancellations by Clusters\n', fontsize=14)	468	0	468	73	2240291861427547588
14	471	81	471	83	5477764700367050216	ax3.set_title('Distribution of Average Taxi\n Out Delay by Clusters\n', fontsize=14)	471	0	471	84	7559075142464793393
14	473	66	473	68	4464934910443279766	ax2.set_title('Distribution of Diversions by Cluster\n', fontsize=14)	473	0	473	69	-4786826066258281624
14	481	70	481	72	6883658945137721888	ax1.set_title('Distribution of Cancellations by Clusters\n', fontsize=14)	481	0	481	73	2528416749434585894
14	486	66	486	68	8558628088974847992	ax2.set_title('Distribution of Diversions by Cluster\n', fontsize=14)	486	0	486	69	7392476883513367144
14	503	59	503	61	8480684795094583197	ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14, rotation=90)	503	4	503	75	3688606664776194700
14	504	59	504	61	7896081786990128191	ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14, rotation=0)	504	4	504	74	-2470977207986212554
14	594	68	594	70	-2724841016522752581	sns.jointplot(x=xlabel, y=ylabel, data=df, kind="hex",size=14,gridsize=(20,15))	594	9	594	88	-2698500824612153559
14	717	47	717	49	-7779899332380637107	plt.xlabel('Total saliency log(A/B)',size= 14)	717	4	717	50	1886571513888698245
14	719	82	719	84	-6295798182347331024	plt.ylabel(r'RGB standard dev. $log(\frac{\sigma(A)}{\sigma(B)})$', size= 14)	719	8	719	85	-9043126839363432039
40	9	23	9	25	7894376073674611316	ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')	8	10	15	28	1469146321465548167
40	26	41	26	43	-2753510152537736192	plt.scatter(X[:,0], X[:,1], c=y, lw=0, s=40)	26	0	26	44	3236529668444922772
40	62	95	62	97	-7432107171836337257	plt.scatter(train[:,0], train[:,1], color='blue', marker='o',s=40,lw=2,label='train',zorder=1)	62	32	62	126	6840088343666820681
40	63	89	63	91	4153662166062570441	plt.scatter(test[:,0], -0.23+0*test[:,1], color='red', s=40,marker='^',label='test',zorder=1)	63	32	63	125	7805084881851787271
40	64	81	64	83	-5287190261005999555	plt.scatter(test[:,0], test[:,1], color='red', s=40,label='test ground truth',zorder=1)	64	32	64	119	-7554529159740494258
40	70	43	70	45	5493787688711528145	TSNE(n_components=2, perplexity=40, verbose=2)	70	11	70	57	-2086914756320751285
40	91	32	91	34	-5154375484430476641	plt.xlabel('Opponent', fontsize=40)	91	0	91	35	-6413948929647072430
40	92	39	92	41	-2838406373482536234	plt.ylabel('Number of Shots', fontsize=40)	92	0	92	42	-814622002027202056
40	104	32	104	34	-3902710391938587799	plt.xlabel('Opponent', fontsize=40)	104	0	104	35	4508244300172376189
40	105	39	105	41	-8786231638861953673	plt.ylabel('Number of Shots', fontsize=40)	105	0	105	42	99628675358223294
40	109	53	109	55	-5629219942244616328	plt.scatter(test[:,0], 0*test[:,1], color='red', s=40,marker='^',label='test',zorder=1)	109	2	109	89	2912459371922799111
40	154	58	154	60	-2039413004513106675	ax4.set_xticklabels(sorted(list(mechanics_set)), rotation=40, ha='right')	154	0	154	73	-2039550702883981163
40	161	78	161	80	396432956941265867	xgb.train(plst, xgtrain, num_round, evallist, early_stopping_rounds=40, verbose_eval=False)	161	10	161	101	6591864400061675488
40	165	44	165	46	3051877442539219676	ax5.set_xticklabels(top_mechanics, rotation=40, ha='right')	165	0	165	59	-242485007259152247
40	188	38	188	40	-827716989452361597	ax6.set_xticklabels(top_cat, rotation=40, ha='right')	188	0	188	53	-2691076550275295840
40	244	29	244	31	-6616855325608110687	plt.scatter(*XYs.T, c='r', s=40)	244	0	244	32	4579587750343668498
40	246	29	246	31	6691614421574598368	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=300)	244	5	246	51	-8881443613552388378
40	311	29	311	31	7806494337869778388	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=200)	309	5	311	51	1806039752936675104
40	325	57	325	59	1192537162645006810	plt.scatter(xc[:,0],xc[:,1],marker='o',c=color,s=40,alpha=0.5)	325	8	325	70	-5597384862490838799
40	378	95	378	97	-883714769372353155	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(6)], batch_size= 64, nb_epoch= 40,\\n               verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(6)]))	378	0	379	102	6194392437158701180
40	558	44	558	46	-5232737109332918635	ax.scatter(x[:,0], x[:,1], lw=0, s=40)	558	9	558	47	701772488629378913
30	31	42	31	44	-5891828629056542468	scene.TurntableCamera(elevation=30, azimuth=30, up='z', distance=2)	31	10	31	77	7580740277387095602
30	31	54	31	56	-6662300553108930833	scene.TurntableCamera(elevation=30, azimuth=30, up='z', distance=2)	31	10	31	77	7580740277387095602
30	34	60	34	62	-153783651846116533	simpleBox(mode="pro_only",length=50000,block_size=30,random_range=0,trial_per_episode=5,\n                    repeat = True, reward_ratio = 5)	34	10	35	52	-6114426729519423264
30	50	16	50	18	6228505841594425955	df.iplot(kind='histogram', subplots=True, shape=(1, 3),\n         title = "Histogram for estimates with true beta = (-5)",\n         bins = 30,\n         subplot_titles=('FD Estimation', 'FD-FE Estimation','FD-FD Estimation'),\n         filename='cufflinks/fig_1')	48	0	52	36	-7251017190041353540
30	58	59	58	61	-2507514357420460952	netx.train( targetData, bal.T, epochs = 150, show = 30, goal =0.2)	58	7	58	73	1015187188201023494
30	59	35	59	37	1437121431400001045	fig.gca(projection='3d', elev=30, azim=310)	59	5	59	48	5626966996232317333
30	62	31	62	33	-7750732877071282436	plot_dist('peak_dff_dg', bins =30, plot_range=[-5,30],log=False)	62	0	62	64	2162724896051337979
30	84	39	84	41	2878142936403650846	KNeighborsClassifier(n_neighbors=30, weights='uniform', algorithm='kd_tree', leaf_size=30, p=2, metric='minkowski', metric_params=None)	84	6	84	141	3553224379823485797
30	84	93	84	95	-1884285501400059726	KNeighborsClassifier(n_neighbors=30, weights='uniform', algorithm='kd_tree', leaf_size=30, p=2, metric='minkowski', metric_params=None)	84	6	84	141	3553224379823485797
30	89	35	89	37	2896252076948631060	compareMortgages(amt=200000, years=30, fixedRate=0.07,\n                 pts = 3.25, ptsRate=0.05, varRate1=0.045,\n                 varRate2=0.095, varMonths=48)	89	0	91	46	8492541568633850261
30	94	20	94	22	-3239104097797465201	plt.xticks(rotation=30)	94	0	94	23	7150213237761377443
30	94	59	94	61	-7587499920056195610	simpleBox(mode="alternative",length=10000,block_size=30,random_range=0,trial_per_episode=5, repeat = True)	94	6	94	112	-4980187008601103576
30	102	60	102	62	-115331455990559108	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 1)	102	10	103	73	2934476473305307850
30	141	48	141	50	6169062944654458450	twit.word_freq_df.set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	140	0	141	62	-6222178131042975741
30	142	45	142	47	-6223034025888937842	plt.title("log relative frequency", fontsize=30)	142	0	142	48	-3916737838811293925
30	145	60	145	62	-3987387051181868280	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 5)	145	10	146	73	-3269178071910035111
30	152	74	152	76	2718360284796367952	ax.scatter(x_iris[:, 0], x_iris[:, 1], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	152	0	152	77	-6259104832034614547
30	157	74	157	76	-9206264098927296238	ax.scatter(x_iris[:, 0], x_iris[:, 1], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	157	0	157	77	-9122185221937297140
30	163	38	163	40	-8712132982339181696	g.plot_joint(plt.scatter, c="cyan", s=30, linewidth=1, marker="+")	163	0	163	66	7069746542993961024
30	171	74	171	76	3728713358703946393	ax.scatter(x_iris[:, 2], x_iris[:, 3], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	171	0	171	77	4076265054361232790
30	176	74	176	76	6133724915830541432	ax.scatter(x_iris[:, 2], x_iris[:, 3], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)	176	0	176	77	7728321624954925774
30	190	48	190	50	-4050612363220229234	twit.word_freq_df.set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	189	0	190	62	-8423863249698398220
30	191	45	191	47	-4303254580816826459	plt.title("log relative frequency", fontsize=30)	191	0	191	48	4962503562577540634
30	191	67	191	69	-7218866102700724830	N.histogram2d(inac['AVG_MASS'], inac['AVG_SFR'], bins=30, range=((8,12.5),(-2,2)), normed=True)	191	13	191	108	5879609046089419792
30	192	70	192	72	1911602879762276373	N.histogram2d(inac['MR'], inac['MU']-inac['MR'], bins=30, range=((-24,-18),(0.5,3.5)), normed=True)	192	16	192	115	-6950940936244460621
30	195	20	195	22	2956836732036249452	plt.xticks(rotation=30)	195	0	195	23	1318673614795536743
30	248	48	248	50	2291846437643588991	twit.word_freq_df.set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	247	0	248	62	8469878195678326632
30	249	45	249	47	-9109718915730232634	plt.title("log relative frequency", fontsize=30)	249	0	249	48	-2059289090440226424
30	262	59	262	61	-7371093358560064168	plt.hist( center_trace[:, i], color = colors[i],bins = 30,\n            histtype="stepfilled" )	262	4	263	35	-4107937597658835529
30	267	58	267	60	3345897611792002540	plt.hist( std_trace[:, i], color = colors[i],  bins = 30,\n            histtype="stepfilled"  )	267	4	268	36	4562318377110671110
30	274	48	274	50	-8912888906415922935	twit.word_freq_df[twit.word_freq_df['background occurrences']>background_cutoff].sort_values("log relative frequency", ascending=True).set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	273	0	274	62	3751798602034286354
30	275	45	275	47	-4695903949737384671	plt.title("log relative frequency", fontsize=30)	275	0	275	48	-68462850564850405
30	280	88	280	90	-6116428257458606898	ax2.scatter(reduced_data['Dimension 1'], reduced_data['Dimension 2'], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	280	4	281	25	4793996401955718291
30	285	48	285	50	6851544345378002623	twit.word_freq_df[twit.word_freq_df['background occurrences']>background_cutoff].sort_values("log relative frequency", ascending=True).set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	284	0	285	62	-3164344411298872524
30	286	45	286	47	-7036983054995146529	plt.title("log relative frequency", fontsize=30)	286	0	286	48	-5816002586764134189
30	296	48	296	50	-821760863215629966	twit.word_freq_df[twit.word_freq_df['background occurrences']>background_cutoff].sort_values("log relative frequency", ascending=True).set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	295	0	296	62	-3773085894131939024
30	297	45	297	47	-8042232084554555751	plt.title("log relative frequency", fontsize=30)	297	0	297	48	-8770000309283507948
30	307	48	307	50	-7535480267504493323	twit.word_freq_df[twit.word_freq_df['background occurrences']>background_cutoff].sort_values("log relative frequency", ascending=True).set_index("word")["log relative frequency"][-num_words_to_plot:].plot.barh(figsize=(20,\n                num_words_to_plot/2.), fontsize=30, color="c")	306	0	307	62	-7093405785798566788
30	308	45	308	47	-495213787686652188	plt.title("log relative frequency", fontsize=30)	308	0	308	48	3929215436949369758
30	357	47	357	49	-22770898988300729	plt.setp(plt.gca().get_xticklabels(), rotation=30)	357	0	357	50	221435698037819638
30	371	47	371	49	-633246415052788067	plt.setp(plt.gca().get_xticklabels(), rotation=30)	371	0	371	50	98150049544993578
30	394	47	394	49	4509407533753089945	plt.setp(plt.gca().get_xticklabels(), rotation=30)	394	0	394	50	7155216665227467426
30	407	48	407	50	-277349384778267802	ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	407	4	408	25	-7141654245981384788
30	407	56	407	58	-959114409193183738	plt.legend(parties, bbox_to_anchor=(0.3, 1), fontsize = 30)	407	0	407	59	4435524857430837372
30	413	41	413	43	1048234608854948919	KNeighborsClassifier(n_neighbors = 30, algorithm = 'auto', weights = 'uniform')	413	6	413	85	-4021987143808661766
30	420	48	420	50	1429492622587740424	ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors)	420	4	421	25	6988696462127109826
30	433	59	433	61	-6130161559462507337	plt.legend(parties, bbox_to_anchor=(0.3, 0.25), fontsize = 30)	433	0	433	62	163340940046049210
30	459	59	459	61	6404459662965722479	plt.legend(parties, bbox_to_anchor=(0.3, 0.25), fontsize = 30)	459	0	459	62	-1137092586088757885
30	514	86	514	88	8902278792538257536	plt.legend(["0-25%","25-50%","50-75%","75-100%"], bbox_to_anchor=(.17, 1), fontsize = 30)	514	0	514	89	4830560062348228792
30	523	56	523	58	5869897300977035412	sns.plt.title('Fanduel Point Distribution',fontsize=30)	523	4	523	59	8986968540937355948
30	539	84	539	86	6986901727480430451	plt.legend(["0-25%","25-50%","50-75%","75-100%"], bbox_to_anchor=(1, 1), fontsize = 30)	539	0	539	87	-7138949074467966763
30	562	45	562	47	-6481911429757671763	sns.plt.title('Regression Plot',fontsize=30)	562	4	562	48	3945956576645676273
30	576	84	576	86	-2118768479620084111	plt.legend(["0-25%","25-50%","50-75%","75-100%"], bbox_to_anchor=(1, 1), fontsize = 30)	576	0	576	87	4554952881398561288
30	714	65	714	67	-2468710352800033659	plot_important_features(coef_model2, feature_names_model2, top_n=30)	714	0	714	68	-7763018198221519583
30	969	23	969	25	9067695891623657981	PCA(n_components=30)	969	6	969	26	2946362414290683648
350	42	63	42	66	1878456567737617297	VideoClip(make_frame, duration=1).resize(width=350)	42	16	42	67	-1634927080760086758
350	51	17	51	20	3130866694210582738	ax.scatter(group['X'], group['S'], marker=symbols[j], color=colors[i-1],\n               s=350, label=label)	50	4	51	34	-7769917375596772051
350	214	47	214	50	1470876123638231824	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color,\n               min_font_size=50, max_font_size=350)	212	5	214	51	-4958717031281068490
600	8	39	8	42	-1766594712807956360	Image("img/instance_limits.png", width=600)	8	0	8	43	8647628896789030594
600	9	51	9	54	-4836511114209930771	Image(filename='figures/input_output.png', width = 600)	9	0	9	55	2048433162352617302
600	25	25	25	28	-341570607651846277	figure(\n            plot_width = 600,\n            plot_height = 600,\n        )	24	20	27	9	-2495343909275282667
600	26	26	26	29	2903156718390829059	figure(\n            plot_width = 600,\n            plot_height = 600,\n        )	24	20	27	9	-2495343909275282667
600	28	29	28	32	-8794696611695500139	Image("img/kpair.png", width=600)	28	0	28	33	8072819781411627710
600	38	68	38	71	-3856799605838202449	ig.imagegrid_figure(images=[ digits.images[i][::-1, :] for i in range(num_imgs) ],\n                          text=[ str(digits.target[i]) for i in range(num_imgs) ],\n                          figure_title=None, palette=Greys9[::-1],\n                          figure_plot_width=760, figure_plot_height=600,\n                          text_color='red', padding=0.1,\n                          grid_size=(10, 8))	35	6	40	44	1931467805568606249
600	71	43	71	46	258846003729948121	savefig('components_v_reads_full.png', dpi=600)	71	0	71	47	8668120481021810214
600	82	53	82	56	-717901127746816959	Image(filename = 'figures/conductivity.png', width = 600)	82	0	82	57	-7863253815182488691
600	102	43	102	46	-3949924586566167564	savefig('components_v_reads_norm.png', dpi=600)	102	0	102	47	-7507509843159716357
600	185	63	185	66	6241339607765455243	savefig('images/components_v_reads_paired_and_single.png', dpi=600)	185	0	185	67	-39322011066056844
600	203	60	203	63	-9114825014224588786	savefig('largest_component_size_paired_and_single.png', dpi=600)	203	0	203	64	-9171959216706418115
255	136	58	136	61	-7213213730935240208	plt.imshow(solid_gray_img, cmap=plt.cm.gray, vmin=0, vmax=255)	136	0	136	62	-8064750085561427835
255	365	61	365	64	7940942137985067701	plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=255, cmap="gray")	365	8	365	78	4707507146001975366
255	370	66	370	69	7387179115694152032	plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=255, cmap="gray")	370	8	370	83	6852027473834083322
255	425	32	425	35	-2337975200518786768	plt.imshow(im, vmin=0, vmax=255, cmap="gray")	425	4	425	49	-6725333441163896584
255	550	32	550	35	557839445704105412	plt.imshow(im, vmin=0, vmax=255, cmap="gray")	550	4	550	49	8707142656364543840
10000	31	26	31	31	-4745777031800297889	mc.sample(iter=50000,burn=10000)	31	0	31	32	5067228822862641813
10000	40	42	40	47	-662739357034894882	RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)	40	6	40	75	-3743061046454617844
10000	49	14	49	19	-2714357531198905161	M.sample(iter=10000, burn=5000, thin=2)	49	0	49	39	7307386832071018896
10000	78	70	78	75	5214945420766802325	invgamma.rvs(a=t.dists[j][0],scale=t.dists[j][1],size=10000)	78	16	78	76	-9089535277524814620
10000	94	42	94	47	8549070660732129041	simpleBox(mode="alternative",length=10000,block_size=30,random_range=0,trial_per_episode=5, repeat = True)	94	6	94	112	-4980187008601103576
10000	96	55	96	60	-7089551477338770274	RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)	96	19	96	88	2756579958262133220
10000	102	43	102	48	3744231908229111378	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 1)	102	10	103	73	2934476473305307850
10000	109	43	109	48	6190883616474023591	linspace(0.1, 1000.0, num=10000)	109	17	109	49	-5980436480780359146
10000	126	42	126	47	-102388132262622211	np.random.multivariate_normal(mean=[1, 2, 3],\n                                     cov=[[1, -.75, .6],\n                                          [-.75, 1, 0],\n                                          [.6, 0 ,1]],\n                                     size=10000)	122	7	126	48	104929688991865781
10000	127	34	127	39	-4383398399621708268	ecoreg.robust_lin_reg(df, var_map, plot_trace=False,\n                            plot_vars=True, mcmc='slice',\n                            steps=10000)	125	6	127	40	-3073862563825318858
10000	145	43	145	48	-3435434592956180370	simpleBox(mode="pro_only",length=10000,block_size=30,random_range=0,\n                    trial_per_episode=5, repeat = True, reward_ratio = 5)	145	10	146	73	-3269178071910035111
10000	166	14	166	19	-3470151711642191742	S.sample(iter=10000, burn=500)	166	0	166	30	3612413812353417828
10000	222	34	222	39	-8858016403836176391	ecoreg.robust_lin_reg(df, var_map, plot_trace=True,\n                            plot_vars=True, mcmc='slice',\n                            steps=10000)	220	6	222	40	-5760213178630892029
10000	266	40	266	45	-4710964494622191567	linspace(0, 100.0, num=10000)	266	17	266	46	-9162633905203235674
10000	311	15	311	20	2587701022435777333	vae.fit(S, S,\n        shuffle=True,\n        epochs=10000,\n        batch_size=batch_size,\n        validation_split=0, verbose=False)	309	0	313	42	191792115908829916
10000	321	18	321	23	-753346450619796570	ax.hist(freq,bins=10000,range=(0,100),normed=False)	321	0	321	51	-7678747014994547216
10000	337	41	337	46	-3028401246592125848	linspace(60, 200.0, num=10000)	337	17	337	47	5851995526470529430
10000	374	22	374	27	-3369105156214286283	plt.scatter(-0, 25, s=10000, alpha=0.3, c = 'r' )	374	0	374	49	620429429582470959
10000	436	40	436	45	-8905456626788375477	linspace(10, 50.0, num=10000)	436	17	436	46	6940397149909789321
10000	513	43	513	48	-8282663132046828249	linspace(0.1, 1000.0, num=10000)	513	17	513	49	-6705569521059119784
10000	1285	48	1285	53	-2416059021871449763	gensim.models.ldamodel.LdaModel(corpus=mm,\n                                      id2word=dictionary,\n                                      num_topics=50,\n                                      update_every=1,\n                                      chunksize=10000,\n                                      passes=100)	1281	6	1286	49	7036574731868352903
100000	21	12	21	18	3493229534372842288	SVC(C=100000, random_state=241, kernel="linear")	21	6	21	54	-5000556258995571724
100000	24	40	24	46	-2248170313273613975	mock_data_generation(M=100000, seed=42)	24	17	24	56	-8318773454207453224
100000	59	43	59	49	4546215015834378718	np.random.normal(5, 15, size=100000)	59	14	59	50	1805539795920827585
100000	297	14	297	20	-8543435837969577483	S.sample(iter=100000, burn=500)	297	0	297	31	-8910952077814834253
100000	701	19	701	25	-3198271862451413166	df.sample(n=100000)	701	7	701	26	3197115892918735086
100000	702	19	702	25	-8734784686179665722	df.sample(n=100000)	702	7	702	26	101737374792092888
100000	703	19	703	25	3149390196038609530	df.sample(n=100000)	703	7	703	26	-1069492214461894082
256	148	68	148	71	-4893461114472187310	conv_layer(h_pool2,   name='conv3_1', n_filters=256)	148	20	148	72	4998923736357354519
256	149	68	149	71	2047444522315559670	conv_layer(h_conv3_1, name='conv3_2', n_filters=256)	149	20	149	72	819264348029110796
256	150	68	150	71	161430214182906662	conv_layer(h_conv3_2, name='conv3_3', n_filters=256)	150	20	150	72	-3784501362706788114
512	153	68	153	71	742021748236894993	conv_layer(h_pool3,   name='conv4_1', n_filters=512)	153	20	153	72	-319057428157489760
512	154	68	154	71	-6231504307804719553	conv_layer(h_conv4_1, name='conv4_2', n_filters=512)	154	20	154	72	-184226918338558746
512	155	68	155	71	-2159320419306226322	conv_layer(h_conv4_2, name='conv4_3', n_filters=512)	155	20	155	72	5860334869324441034
512	158	68	158	71	3579771746469275973	conv_layer(h_pool4,   name='conv5_1', n_filters=512)	158	20	158	72	3206949586117094774
512	159	68	159	71	6244121033220778834	conv_layer(h_conv5_1, name='conv5_2', n_filters=512)	159	20	159	72	3965529655678121114
512	160	68	160	71	-8375770788955331877	conv_layer(h_conv5_2, name='conv5_3', n_filters=512)	160	20	160	72	8721508642059069435
60	135	37	135	39	-7767804023124012405	plt.scatter(X, Y, zorder=3, c='r', s=60)	135	0	135	40	2726770031031432254
60	190	37	190	39	8098005117100429795	plt.scatter(X, Y, zorder=3, c='r', s=60)	190	0	190	40	-4971426208755726634
60	348	42	348	44	-8046566977542433664	ImageSequenceClip(data.images, fps=60)	348	7	348	45	-5823153035242040013
60	352	20	352	22	8196918332439500430	plt.xticks(rotation=60, fontsize = 12)	352	0	352	38	8024096565987094916
60	463	63	463	65	-2232596749989779132	fig.suptitle("Dimensional Plots - Political Party", fontsize = 60,y = 1,verticalalignment = "bottom" )	463	0	463	102	-702850609515704279
60	537	81	537	83	-236361161544200029	gmap.scatter(df_crime.latitude.values,df_crime.longitude.values, '#3B0B39', size=60, marker=False)	537	0	537	98	-1411729044510396374
60	567	67	567	69	-6425578226845297842	fig.suptitle("Dimensional Plots - Presidential Rating", fontsize = 60,y = 1,verticalalignment = "bottom" )	567	0	567	106	-3169009767698323184
60	678	52	678	54	-4397698473994247007	fig.suptitle("Dimensional Plots - Year", fontsize = 60,y = 1,verticalalignment = "bottom" )	678	0	678	91	483962630431335773
18	26	36	26	38	4122679087411873958	plt.xlabel(rate1_name, fontsize=18)	26	4	26	39	4727374419201107588
18	27	36	27	38	8890436861873516001	plt.ylabel(rate2_name, fontsize=18)	27	4	27	39	8775237261328253335
18	28	66	28	68	8534819675895953520	plt.title(curve_name + ' for house price > 200,000', fontsize=18)	28	4	28	69	3148089573469483730
18	43	50	43	52	6751152014235455864	plt.suptitle('Integral of $\!f(2x)$',fontsize=18)	43	4	43	53	-7421008473692469083
18	47	50	47	52	-1657934113861553406	model_all.get('coefficients').print_rows(num_rows=18)	47	0	47	53	6499174290661595094
18	96	43	96	45	3267015295072669735	plt.xlabel('Number of neighbors', fontsize=18)	96	0	96	46	-7370317663730089498
18	97	32	97	34	-1137512747295766618	plt.ylabel('Accuracy', fontsize=18)	97	0	97	35	6110460254396174632
18	98	74	98	76	3566438466657508449	plt.title('Performance of KNN with varying number of neighbors', fontsize=18)	98	0	98	77	-7272545985567733312
18	101	20	101	22	-7974255414380361819	plt.xticks(fontsize=18)	101	0	101	23	1631030029576046790
18	137	39	137	41	1134492338607081569	ax1.set_xlabel('Distance (m)',fontsize=18)	137	0	137	42	-8346174543667972281
18	138	44	138	46	-6271304484601657838	ax2.set_xlabel('Position ($\mu$m)',fontsize=18)	138	0	138	47	-4568502218553525807
18	140	37	140	39	-930855585575246414	ax1.set_ylabel('Energy (J)',fontsize=18)	140	0	140	40	-8941506925179649146
18	141	37	141	39	-8873894596136129138	ax2.set_ylabel('Power (MW)',fontsize=18)	141	0	141	40	-5381751247370516429
18	143	49	143	51	-8649665540204121685	ax3.set_xlabel('Wavenumber $k/k_{res}$',fontsize=18)	143	0	143	52	122816370951043338
18	144	44	144	46	3587237774687519877	ax4.set_xlabel('Position ($\mu$m)',fontsize=18)	144	0	144	47	1735090761518503156
18	145	60	145	62	1909904062122495037	ax.set_ylabel('Distance (m)',fontsize=18)	145	22	145	63	6151577882622153024
18	147	43	147	45	519089449718953933	ax.set_ylabel(r'$w$', fontsize=18)	147	12	147	46	4825853800132186180
18	147	53	147	55	4502010682530515391	(model_temp.get('coefficients')).print_rows(num_rows=18)	147	0	147	56	-3824706408999920174
18	151	45	151	47	-6769578081503201852	ax3.set_title('Energy [normalized]',fontsize=18)	151	0	151	48	1860511114667443714
18	152	44	152	46	885132491918224191	ax4.set_title('Power [normalized]',fontsize=18)	152	0	152	47	-6194132336429220625
18	154	46	154	48	8111981279589261293	ax.set_xlabel(r'$\tau$', fontsize=18)	154	12	154	49	-7520600152215655267
18	171	43	171	45	-1143508085198968283	ax.set_ylabel(r'$w$', fontsize=18)	171	12	171	46	-6214022792129973357
18	178	46	178	48	-2725149203810628539	ax.set_xlabel(r'$\tau$', fontsize=18)	178	12	178	49	2433984626968104045
18	178	47	178	49	-6301670942886815190	ax.set_xlabel('Position ($\mu$m)',fontsize=18)	178	4	178	50	9207667635579816483
18	179	51	179	53	-1739066099568517729	ax.set_ylabel('Electron energy (MeV)',fontsize=18)	179	4	179	54	2166118649599106700
18	182	38	182	40	-833539045857995206	ax.set_xlabel(r'$\alpha$', fontsize = 18)	182	0	182	41	-4573160659663833431
18	183	33	183	35	-7234358855038380142	ax.set_ylabel(r'$y$', fontsize = 18)	183	0	183	36	8876789332859699218
18	194	43	194	45	-9200817454455943562	ax.set_ylabel(r'$w$', fontsize=18)	194	12	194	46	6786766538666295079
18	199	43	199	45	-1344471661751108608	plt.xlabel('False Positive Rate', fontsize=18)	199	0	199	46	8210603879351868399
18	200	42	200	44	-6742419336602745586	plt.ylabel('True Positive Rate', fontsize=18)	200	0	200	45	6197003160809564084
18	201	46	201	48	-6431144268325923844	ax.set_xlabel(r'$\tau$', fontsize=18)	201	12	201	49	1951719997635278523
18	201	76	201	78	-8793229924949915999	plt.title('Receiver operating characteristic for high/low income', fontsize=18)	201	0	201	79	-5241422977167749257
18	205	38	205	40	-4350319149227905428	ax.set_xlabel(r'$\alpha$', fontsize = 18)	205	0	205	41	1003626063870950190
18	206	33	206	35	-5666834811667319268	ax.set_ylabel(r'$y$', fontsize = 18)	206	0	206	36	2401009379287506113
18	301	71	301	73	-1529380531515334214	fig.suptitle("Salt anomaly during perturbation",x=1.,y=2.,fontsize=18)	301	4	301	74	5758063591494657741
18	315	51	315	53	6520073845276873454	ax.set_xlabel('X-coordinate ($\mu$m)',fontsize=18)	315	4	315	54	-2258217154172190263
18	317	48	317	50	-1554098992406637462	ax0.set_ylabel('R-coordinate ($\mu$m)',fontsize=18)	317	0	317	51	-4689165913010612944
18	318	61	318	63	-811905905472546091	ax1.set_ylabel('Electron Lorentz factor $\gamma_e$',fontsize=18)	318	0	318	64	1167045136089360604
18	319	47	319	49	155949289938593180	ax2.set_ylabel('$a_0$, $n_e$ (norm.)',fontsize=18)	319	0	319	50	2990048476099442093
18	332	46	332	48	7085157045709359262	ax.set_xticklabels([r'$\alpha$',r'$\beta$',r'$\gamma$',r'$\delta$',\n                   r'$\epsilon$'], fontsize = 18)	331	0	332	49	6591566573000910333
18	337	62	337	64	-1999454040431873233	ax.set_yticklabels(['$%.1f$' % y for y in yticks], fontsize = 18)	337	0	337	65	-2386521303059243333
18	345	71	345	73	8976815716647388063	fig.suptitle("Salt anomaly during perturbation",x=1.,y=2.,fontsize=18)	345	4	345	74	-9083510726994679767
18	360	80	360	82	8799936649329415272	pl.title('Color maps Age in years, Size maps tital/residential units', fontsize=18)	360	0	360	83	4291691954603278226
18	377	41	377	43	-723313578781092107	ax1.set_ylabel(r'area $(m^2)$', fontsize=18, color='blue')	377	0	377	58	7592432930553021242
18	383	43	383	45	-6683749293402631248	ax2.set_ylabel(r'volume $(m^3)$', fontsize=18, color='red')	383	0	383	59	-197246942687643340
18	430	59	430	61	-8180915260232525044	plt.subplot2grid((20,20), (0,0), colspan=19, rowspan=18, sharex=ax2)	430	6	430	74	5453243124963380752
18	449	48	449	50	-8121648002385069097	plt.subplot2grid((20,20), (0,19), rowspan=18)	449	6	449	51	-2106041610190843863
18	803	79	803	81	3467972193334057102	fig.suptitle("Freshwater content difference"+" "+method,x=1.,y=2.,fontsize=18)	803	4	803	82	485115656039227481
18	848	78	848	80	-8672592509147673599	fig.suptitle("Freshwater content top 1000m difference",x=1.,y=2.,fontsize=18)	848	4	848	81	-1451853535148568694
18	893	57	893	59	2528094330385958771	fig.suptitle("Freshwater content",x=1.,y=2.,fontsize=18)	893	4	893	60	-6368075158763407173
18	936	57	936	59	2760177125666706918	fig.suptitle("Freshwater content",x=1.,y=2.,fontsize=18)	936	4	936	60	-4105643602588102704
18	974	49	974	51	-5070712061378635255	fig.suptitle(titlesd[var],x=1.,y=2.,fontsize=18)	974	4	974	52	7094398717088691570
18	1042	56	1042	58	8445230312077480236	fig.suptitle('Mixed layer depth',x=1.,y=2.,fontsize=18)	1042	4	1042	59	-5501750532685741544
18	1618	60	1618	62	7145539769608539595	fig.suptitle("Tracer at "+ptracer,x=1.3,y=5.95,fontsize=18)	1618	4	1618	63	-3611332913807587777
18	1843	79	1843	81	1665135711756770288	fig.suptitle("Difference "+var+" Layer thickness",x=1.1,y=1.7,fontsize=18)	1843	8	1843	82	-5105895265134392164
18	1845	65	1845	67	-3791120540862054691	fig.suptitle(var+" Layer thickness",x=1.1,y=1.7,fontsize=18)	1845	8	1845	68	-938735448635426963
45	52	20	52	22	-2710035146402237550	plt.xticks(rotation=45, ha='center')	52	0	52	36	-2085000079520647693
45	123	62	123	64	-6668670698209681746	plt.setp(ax.get_xticklabels(), visible=True, rotation=45, ha='right')	123	8	123	77	5346953884470480577
45	138	24	138	26	7189022430043990884	plt.xticks(rotation=45, ha='center')	138	4	138	40	9167226440931309056
45	141	18	141	20	-8200098002729863095	ax.view_init(elev=45, azim=120)	141	0	141	31	6783735597758571781
45	341	20	341	22	7873019286335034289	plt.xticks(rotation=45, ha='center')	341	0	341	36	-1376139734263452662
8000	375	22	375	26	7327074244204769788	plt.scatter(45, 21, s=8000, alpha=0.3, c = 'r' )	375	0	375	48	-2331375069851583616
21	81	80	81	82	-7413215622400737014	np_methods.ssd_bboxes_select(\n            rpredictions, rlocalisations, ssd_anchors,\n            select_threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)	79	33	81	96	-5826376325475962999
21	111	35	111	37	5647530826212332813	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
21	237	77	237	79	5611758519414853431	simple_model.coefficients.sort('value', ascending=False).print_rows(num_rows=21)	237	0	237	80	-2557407672276211995
64	45	95	45	97	-5605656810433683237	mx.model.FeedForward(ctx=mx.cpu(), symbol=fea_symbol, numpy_batch_size=64,\n                                             arg_params=model.arg_params, aux_params=model.aux_params,\n                                             allow_extra_params=True)	45	24	47	69	-3194321904258423673
64	140	68	140	70	788862208731024750	conv_layer(self.tf_x, name='conv1_1', n_filters=64)	140	20	140	71	6356473998029618561
64	141	68	141	70	6898134904943139801	conv_layer(h_conv1_1, name='conv1_2', n_filters=64)	141	20	141	71	8484663344172313050
64	378	81	378	83	1786263834397354219	model.fit(X_train_sample, [y_train_sample[:,i,:] for i in range(6)], batch_size= 64, nb_epoch= 40,\\n               verbose=2, validation_data=(X_valid_sample, [y_valid_sample[:,i,:] for i in range(6)]))	378	0	379	102	6194392437158701180
64	443	81	443	83	2063901790403348253	anim.save('vae_{}to{}.gif'.format(start, end), writer='imagemagick', fps=12, dpi=64)	443	0	443	84	-6256341000573797089
64	482	85	482	87	8819147678962644635	anim.save('vae_all_{}to{}.gif'.format(start, end), writer='imagemagick', fps=10, dpi=64)	482	0	482	88	-1497845107189350081
64	568	97	568	99	-549023760269067845	anim.save('vae_{}to{}_dim{}.gif'.format(start, end, n_latent), writer='imagemagick', fps=12, dpi=64)	568	0	568	100	-1459748535430917866
5000	49	26	49	30	2756397352831769903	M.sample(iter=10000, burn=5000, thin=2)	49	0	49	39	7307386832071018896
5000	76	23	76	27	-7847876218744665809	R.sample(10000, burn = 5000, thin = 5)	76	0	76	38	1046007465089263218
5000	101	38	101	42	-6117139664620644514	oml.tasks.list_tasks(size=5000)	101	12	101	43	7801704593861642928
5000	112	37	112	41	-4670023138758951592	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
5000	124	64	124	68	947744233352822773	ax.axvspan(obs_times[0], obs_times[1], ymin=-5000, ymax=5000, color='white')	124	8	124	84	5151253955155628421
5000	282	56	282	60	-6723483504845519738	np.random.choice(np.arange(10000), size=5000)	282	16	282	61	-6975727079260161542
11	115	37	115	39	3578335176711734755	display2.plot_ppi('ZDR',vmin=-7,vmax=11)	115	0	115	40	6375396707349534110
11	171	36	171	38	7838303461285052445	display.plot_ppi('ZDR',vmin=-7,vmax=11)	171	0	171	39	-100751411408422692
11	189	36	189	38	6412906920239443411	display.plot_ppi('ZDR',vmin=-7,vmax=11,sweep=1)	189	0	189	47	6958275227470495976
11	260	51	260	53	-7419502805436873664	plt.hist(nearest_neighbors_cosine['length'], 50, color='b', edgecolor='None', histtype='stepfilled', normed=True,\n         label='100 NNs of Obama (cosine)', zorder=11, alpha=0.8)	259	0	260	65	-40386166885092605
11	304	36	304	38	-4149026405566733827	display.plot_ppi('ZDR',vmin=-7,vmax=11)	304	0	304	39	339337230987760221
11	311	45	311	47	-2726532544184799185	np.logspace(-10, 0, num = 11)	311	19	311	48	4585176907816489499
80	69	29	69	31	5400136472456323793	plt.figure(figsize=(8,6),dpi=80)	69	0	69	32	-5999348453985580457
80	83	33	83	35	-1156397800234225584	plt.figure(figsize=(10,6), dpi = 80)	83	0	83	36	1534879515582603080
80	91	31	91	33	-8401344988299654825	plt.figure(figsize= (10,6),dpi=80)	91	0	91	34	-2316941011764629917
80	101	31	101	33	-8597872750388545552	plt.figure(figsize= (10,6),dpi=80)	101	0	101	34	6185868960982736042
80	113	31	113	33	-6203589850077685346	plt.figure(figsize= (10,6),dpi=80)	113	0	113	34	8543819847920579137
80	125	31	125	33	-999252259322187302	plt.figure(figsize= (10,6),dpi=80)	125	0	125	34	-482826309958065200
80	145	31	145	33	5845290561227871334	plt.figure(figsize= (10,6),dpi=80)	145	0	145	34	773381520511557298
80	168	31	168	33	6534110310138352590	plt.figure(figsize= (10,6),dpi=80)	168	0	168	34	-72891355889333701
80	200	31	200	33	-1008388133146572564	plt.figure(figsize= (10,6),dpi=80)	200	0	200	34	514949324478178041
80	202	50	202	52	5133829561824269583	plt.figure(figsize=(12,6), dpi=80)	202	19	202	53	8270353454519880884
80	234	31	234	33	2602660896659905038	plt.figure(figsize= (10,6),dpi=80)	234	0	234	34	6347745203507310051
80	296	31	296	33	-2799784003197966550	self.ax.scatter(support_vectors[:, 0], support_vectors[:, 1],\n                             s=80, edgecolors="k", facecolors="none")	295	13	296	69	6954204285321867438
80	708	14	708	16	-4945056171956448113	plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n            s=80, facecolors='none')	707	0	708	36	189407431048473416
120	135	70	135	73	-1464383112792000564	KernelPCA(n_components=4, degree=2, gamma=.000001, coef0=120)	135	13	135	74	-2535834234939777556
120	136	66	136	69	-8060313117611155267	autocorrelation(sp_x_cell, sp_y_cell, x_cell, y_cell, nbins = 120, occupancy_normalization = True)	136	4	136	102	8522490655289012435
120	141	27	141	30	-1113387820068637951	ax.view_init(elev=45, azim=120)	141	0	141	31	6783735597758571781
120	493	31	493	34	-2963604715987296924	Basemap(projection='robin', resolution='l',area_thresh = 1000.0,\n                lat_0=0, lon_0=120)	492	9	493	35	8711651054332721735
120	533	31	533	34	5623364346782095202	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
13	58	38	58	40	-3182670170504875021	np.logspace(1,7,num=13)	58	18	58	41	6533462452922745696
13	75	18	75	20	-4996108396009485407	recommend(item_id=13, num=5)	75	0	75	28	1125451643776759403
13	445	30	445	32	-7156630184006098636	plt.rc('ytick', labelsize=13)	445	4	445	33	-751301679762012143
13	497	30	497	32	-1217892669745781773	plt.rc('ytick', labelsize=13)	497	4	497	33	8774864028826450252
13	615	30	615	32	4297485852825580968	plt.rc('ytick', labelsize=13)	615	4	615	33	2205022671330093011
13	627	30	627	32	-2042026067870151472	plt.rc('ytick', labelsize=13)	627	4	627	33	1974980388752350855
13	815	43	815	45	-8225052906222249758	LatentDirichletAllocation(n_topics = 13, learning_method='batch')	815	6	815	71	5914862260574769529
50000	31	15	31	20	8750728085442640686	mc.sample(iter=50000,burn=10000)	31	0	31	32	5067228822862641813
50000	34	43	34	48	1537520994945587722	simpleBox(mode="pro_only",length=50000,block_size=30,random_range=0,trial_per_episode=5,\n                    repeat = True, reward_ratio = 5)	34	10	35	52	-6114426729519423264
50000	147	29	147	34	1312307000787125981	svm.LinearSVC(max_iter=50000, verbose=1)	147	6	147	46	-3815622864876185836
50000	273	69	273	74	-7661820295539046044	oe_to_dat(example_path, outfile=outfile, channels=tt, chunk_size=50000)	273	4	273	75	-1339723180738217783
50000	443	48	443	53	2792111699663164179	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 50000, min_error_reduction=-1)	442	10	443	78	2101942890823207548
300	29	36	29	39	452114739920373353	plt.figure(figsize=(8,6), dpi=300)	29	6	29	40	-7089790240784609648
300	40	23	40	26	2136367195669451717	scatter_matrix (nrg, s=300, figsize=(16, 16), diagonal='kde')	40	0	40	61	-7563970354458404988
300	55	50	55	53	-3138302162600428029	xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)	55	6	55	74	7398172325393511404
300	58	36	58	39	-3680914354981851862	plt.figure(figsize=(8,6), dpi=300)	58	6	58	40	-5980745063996992027
300	62	23	62	26	1579976988670198543	scatter_matrix (nrg, s=300, figsize=(16, 16))	62	0	62	45	-147868937349226397
300	82	40	82	43	6828581762334916455	plt.figure(figsize=(6*1.2,6), dpi=300)	82	6	82	44	8683514858993897615
300	96	35	96	38	-2731499557172880278	scatter_matrix (allmales['all'], s=300, figsize=(16, 16), diagonal='kde')	96	0	96	73	3514019011208007455
300	105	59	105	62	-2111609951807357500	plt.savefig('injuries_by_hour.png',bbox_inches='tight',dpi=300)	105	0	105	63	-1817235080102822084
300	120	107	120	110	-5737528137413094556	clf.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], verbose=True, eval_metric='l2', early_stopping_rounds=300)	120	4	120	111	-6631588900410370820
300	134	52	134	55	-3009217606619172905	bk.figure(title="n_neighbors = %d" % (i+2),\n                        plot_width=340, plot_height=300)	133	14	134	56	-9101895811456257852
300	142	40	142	43	-8775820243614710117	plt.figure(figsize=(6*1.2,6), dpi=300)	142	6	142	44	-925478144348058612
300	143	62	143	65	1858256103390483883	plt.savefig('injuries_by_weekday.png',bbox_inches='tight',dpi=300)	143	0	143	66	-4010481884741589292
300	153	36	153	39	-7315861184802816054	plt.savefig('images/paper.jpg', dpi=300)	153	0	153	40	-6329854656471004578
300	156	40	156	43	-1280862260822826543	plt.figure(figsize=(6*1.2,6), dpi=300)	156	6	156	44	-1622041676444838622
300	166	60	166	63	-5519681737532028881	plt.savefig('injuries_by_month.png',bbox_inches='tight',dpi=300)	166	0	166	64	1858701476470094903
300	170	40	170	43	2652350979615959705	plt.figure(figsize=(6*1.2,6), dpi=300)	170	6	170	44	1465731615068617325
300	184	40	184	43	2233079015131541695	plt.figure(figsize=(6*1.2,6), dpi=300)	184	6	184	44	1689943040835892660
300	198	40	198	43	-6877118119447504558	plt.figure(figsize=(6*1.2,6), dpi=300)	198	6	198	44	5734966235239066944
300	202	55	202	58	-7331893187011153327	np.random.choice(np.arange(10000), size=300)	202	15	202	59	-7364299220699032701
300	213	40	213	43	-7832993640934985933	plt.figure(figsize=(6*1.2,6), dpi=300)	213	6	213	44	-484159964761410433
300	246	47	246	50	2242637494685166523	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=300)	244	5	246	51	-8881443613552388378
300	249	40	249	43	-3484318707992730458	plt.figure(figsize=(6*1.2,6), dpi=300)	249	6	249	44	-302371390741972494
300	283	40	283	43	-2641078473819094342	plt.figure(figsize=(6*1.2,6), dpi=300)	283	6	283	44	-3553632900918801088
300	304	16	304	19	1077814542436769976	ax1.hist2d(electrons.Data['coords'][0],electrons.Data['momenta'][0],weights=electrons.Data['weights'],\n           bins=300,vmin=-0.0005,cmap=plt.cm.Reds_r,range=[ax0.get_xlim(),[0.05,20]])	303	0	304	85	-9174808845757944759
300	349	36	349	39	-264110351982902296	plt.figure(figsize=(8,6), dpi=300)	349	6	349	40	6498521023161290540
300	425	36	425	39	-1853264637173482078	plt.figure(figsize=(8,6), dpi=300)	425	6	425	40	-3056583892481361463
300	450	82	450	85	-6984726635131855714	ipyd.Image(url='vae_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=300, width=300)	450	0	450	97	4220819905626639369
300	450	93	450	96	-2518817970940483332	ipyd.Image(url='vae_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=300, width=300)	450	0	450	97	4220819905626639369
300	469	36	469	39	216464487281498844	plt.figure(figsize=(8,6), dpi=300)	469	6	469	40	5321476878390286026
300	508	36	508	39	-1726479561227487016	plt.figure(figsize=(8,6), dpi=300)	508	6	508	40	-5847151353584945991
300	537	36	537	39	-8096858073499133554	plt.figure(figsize=(8,6), dpi=300)	537	6	537	40	9092136119595561169
300	576	36	576	39	-7948594723833400276	plt.figure(figsize=(8,6), dpi=300)	576	6	576	40	382764571242822040
300	597	16	597	19	-1296994676900487355	plt.hist2d((df_mxe['cs1']), (df_mxe['cs2bottom']/100),\n           bins=300, norm=matplotlib.colors.LogNorm(),range=([0,1000],[0,2000]))	596	0	597	80	-3812297243524354373
300	632	75	632	78	-5782089759859400992	should_continue_training(min_valid_error_epoch, epoch_num, min_epoch=300)	632	6	632	79	3132337721749447095
300	672	16	672	19	5554487712429266965	plt.hist2d((df_cs['cs1']), (df_cs['cs2bottom']/100),\n           bins=300, norm=matplotlib.colors.LogNorm(), range=([0,2000],[0,4000]))	671	0	672	81	-5584570603693985054
300	963	75	963	78	805432240446539301	should_continue_training(min_valid_error_epoch, epoch_num, min_epoch=300)	963	6	963	79	-7013400392063731797
300	1120	75	1120	78	762052933219800760	should_continue_training(min_valid_error_epoch, epoch_num, min_epoch=300)	1120	6	1120	79	-2433909278229985706
19592	105	91	105	96	4566507239031783006	viz.pics.pil.load_image_portion(experiment, (1260, 1380, 1870, 1970), frame=19592)	105	15	105	97	8988233129215074769
19473	103	90	103	95	-750900375701088664	viz.pics.pil.load_image_portion(experiment, (1260, 1380, 1870, 1970), frame=19473)	103	14	103	96	8232282909493990995
750	71	27	71	30	5872195262077286522	bk.figure(title='PCA Projection - digits dataset',\n                x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=560)	69	6	71	48	-3286209521089249655
750	101	27	101	30	-814234619175608635	bk.figure(title='LDA Projection - digits dataset',\n                x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=500)	99	6	101	48	-1507773890266659778
750	178	26	178	29	-5168890594976261293	bk.figure(title='PCA Projection - S-Curve',\n               x_axis_label='c1', y_axis_label='c2',\n               plot_width=750, plot_height=500)	176	6	178	47	-2557690135001772447
750	190	27	190	30	-3833559375182022583	bk.figure(title='Isomap - S-Curve', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=400)	189	6	190	48	5184953220000253137
750	202	27	202	30	-2425731734236900266	bk.figure(title='LocallyLinearEmbedding - S-Curve', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=400)	201	6	202	48	7985347003410819607
750	225	27	225	30	6953894114372304100	bk.figure(title='t-SNE - digits dataset', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=450)	224	6	225	48	8136380298158223913
19	414	48	414	50	-5181442898187176594	plt.subplot2grid((20,20), (18,0), colspan=19, rowspan=2)	414	6	414	62	-7551571044590947242
19	430	47	430	49	4292903837627196664	plt.subplot2grid((20,20), (0,0), colspan=19, rowspan=18, sharex=ax2)	430	6	430	74	5453243124963380752
360	62	44	62	47	-8847472381771236496	Basemap(llcrnrlon=0,llcrnrlat=-50,urcrnrlon=360,urcrnrlat=50,projection='mill')	62	0	62	79	4758132665796981063
360	117	38	117	41	-2175957053005496055	display2.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	117	0	117	50	7160287107557398832
360	119	39	119	42	4447220734063467093	display1.plot_ppi('sPhiDP',vmin=0,vmax=360)	119	0	119	43	886474461644079658
360	173	37	173	40	6413944768566515576	display.plot_ppi('PhiDP',vmin=0,vmax=360)	173	0	173	41	4168859209340830449
360	191	37	191	40	-395451169760747714	display.plot_ppi('PhiDP',vmin=0,vmax=360,sweep=1)	191	0	191	49	9188366317665067491
360	193	40	193	43	6183483926521790236	display1.plot_ppi('sdPhiDP',vmin=0,vmax=360)	193	0	193	44	-6190453704109777063
360	306	38	306	41	4722575498593964361	display.plot_ppi('uPhiDP',vmin=0,vmax=360)	306	0	306	42	-1274873083979653313
24	92	29	92	31	691510321334767767	plt.xlabel("t [s]", fontsize=24)	92	0	92	32	-8023721689049582475
24	93	45	93	47	-1576288740748140302	plt.ylabel(u"f(t) = (t  2)$^2$", fontsize=24)	93	0	93	48	-5174041918043329238
24	102	29	102	31	-6141079802004693134	plt.xlabel("t [s]", fontsize=24)	102	0	102	32	-8690101047490180326
24	103	45	103	47	2986654212368845020	plt.ylabel(u"f(t) = (t  2)$^2$", fontsize=24)	103	0	103	48	-2620412208431870881
24	115	32	115	34	-4629418390437952658	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
24	524	46	524	48	2089640872697663228	sns.plt.xlabel('Fanduel Points', fontsize=24)	524	4	524	49	-2874790329143014567
24	525	43	525	45	5290018656640865653	sns.plt.ylabel('Probability', fontsize=24)	525	4	525	46	-1717858047806293004
24	563	53	563	55	178114808666153596	sns.plt.xlabel(xlabel.replace('_',' '), fontsize=24)	563	4	563	56	-8793058907391604519
24	564	53	564	55	2510546327536915295	sns.plt.ylabel(ylabel.replace('_',' '), fontsize=24)	564	4	564	56	1769050477930782355
800	4	19	4	22	-6911456681969580923	canvas(width=800, height=800)	4	6	4	35	-317989801042807428
800	4	31	4	34	-2396904326665465301	canvas(width=800, height=800)	4	6	4	35	-317989801042807428
800	13	38	13	41	4919518054430632694	Image("img/security_group.png", width=800)	13	0	13	42	3013905490545682532
800	18	27	18	30	-6829327630122220382	Image("img/ami.png", width=800)	18	0	18	31	-56704087630384856
800	22	57	22	60	8235935445251459699	AdaBoostClassifier(random_state=1,n_estimators=800,learning_rate=0.9,algorithm='SAMME',\n                             base_estimator=DecisionTreeClassifier(max_depth=3))	22	10	23	80	1100203830827759889
800	48	47	48	50	1653668957925243262	Image(filename = 'figures/priors.png', width = 800)	48	0	48	51	7741527106737464849
800	53	20	53	23	-7416596355117477886	canvas(width=800, height=800)	53	7	53	36	-7875663283499874510
800	53	32	53	35	2304891215585988314	canvas(width=800, height=800)	53	7	53	36	-7875663283499874510
800	67	15	67	18	-5357063087845533269	Plot(\n    x_range=xdr,\n    y_range=ydr,\n    title="",\n    plot_width=800,\n    plot_height=400,\n    outline_line_color=None,\n    toolbar_location=None,\n)	63	7	71	1	-4586682221883798721
800	92	51	92	54	4918238735132505131	Image(filename = 'figures/posteriors.png', width = 800)	92	0	92	55	1310360166847675042
800	102	20	102	23	-1095028644643649229	canvas(width=800, height=800)	102	7	102	36	-1516182803719572733
800	102	32	102	35	-8874188442409786549	canvas(width=800, height=800)	102	7	102	36	-1516182803719572733
17	173	52	173	54	-8343709402888439490	KFold(len(x_train), shuffle=True, random_state=17)	173	5	173	55	1535937306564191011
33	125	133	125	135	7458514821743307651	train_test_split(np.array(log_df[x_cols]), np.array(log_df['click']), test_size=0.3, random_state=33)	125	35	125	136	-7728683823404009577
36	356	94	356	96	746571615377942589	plt.title('Frequencies and Prices of Top %d CPT Codes in One Surgical Center' % n, fontsize = 36)	356	0	356	97	-814438521045966638
23	20	41	20	43	-6183189098765700982	make_blobs(n_samples=400, centers=23, random_state=42)	20	7	20	61	8355410366299839104
23	58	45	58	47	2126442735269993998	make_blobs(n_samples=400, centers=23, random_state=42+n)	58	11	58	67	-5717479585512472059
23	90	45	90	47	-4412099132765231219	make_blobs(n_samples=400, centers=23, random_state=42+n)	90	11	90	67	-1413492864098101230
42	17	114	17	116	-1870071432666466688	train_test_split(X_raw, y_raw, test_size= 1./3, random_state=42)	17	53	17	117	1088246537410738046
42	20	58	20	60	4339490068129313310	make_blobs(n_samples=400, centers=23, random_state=42)	20	7	20	61	8355410366299839104
42	24	53	24	55	7893908310379032405	mock_data_generation(M=100000, seed=42)	24	17	24	56	-8318773454207453224
42	25	105	25	107	-6967340496866593299	train_test_split(features, labels, test_size=0.25, random_state=42)	25	41	25	108	4454398088239380425
42	57	93	57	95	-25118516423265777	train_test_split(x_train, y_train,\n                                                                test_size=0.15, random_state=42,\n                                                                stratify=y_train)	56	47	58	81	9021162538672841880
42	76	87	76	89	4570465271626526791	train_test_split(X, y, test_size=0.33, random_state=42)	76	35	76	90	1232173859373477470
42	93	75	93	77	3736932175459783217	random_projection.SparseRandomProjection(n_components=2, random_state=42)	93	5	93	78	-7488334484764784218
42	103	111	103	113	3982244414346309505	RFC(n_estimators=n_estimators, criterion='entropy', n_jobs=-1, random_state=42)	103	35	103	114	5342976739712488702
42	106	86	106	88	54424875102866387	cross_validation.train_test_split(x, y, random_state=42, stratify=y,\n                                                                   test_size=0.20)	106	33	107	82	8854900058634634309
42	118	29	118	31	8747123706756174902	LGBMRegressor(max_depth=50,\n                        num_leaves=21,\n                        n_estimators=5000,\n                        min_child_weight=1,\n                        learning_rate=0.001,\n                        nthread=24,\n                        subsample=0.80,\n                        colsample_bytree=0.80,\n                        seed=42)	110	10	118	32	5722090990335641956
42	119	107	119	109	-7149275270103454818	RFC(n_estimators=n_estimators, class_weight='balanced', criterion='entropy', n_jobs=-1, random_state=42)	119	6	119	110	-4452306926157998591
42	204	87	204	89	-6715647247940027942	train_test_split(X, y, test_size=0.33, random_state=42)	204	35	204	90	1184443264724363855
42	266	87	266	89	7838776429084019411	train_test_split(X, y, test_size=0.33, random_state=42)	266	35	266	90	4761317276414914722
42	301	125	301	127	-2367605237849197848	train_test_split(X_train, y_train, test_size= 0.2, random_state=42)	301	61	301	128	-2774617314059510571
42	311	45	311	47	-1102512742224653738	train_test_split(\n    scaled_X, y, test_size=0.2, random_state=42)	310	35	311	48	7604939578824092468
42	424	92	424	94	-4835498951457194231	train_test_split(norm128_X_train, y_train,\n                                                               test_size=0.20, random_state=42)	423	37	424	95	-8035741983558493810
42	500	104	500	106	-1217099340348623301	train_test_split(X_train, y_train, bbox_train, test_size= 0.2, random_state=42)	500	28	500	107	6917170366384312450
42	729	98	729	100	2494440606262557944	train_test_split(df_balanced, test_size = 0.1, random_state=42)	729	38	729	101	-1662845253292342869
42	732	93	732	95	-2418227963162807892	train_test_split(df_injured, test_size = 0.1, random_state=42)	732	34	732	96	4793945442519037990
42	735	73	735	75	1490838569659684122	train_test_split(df_1, test_size = 0.1, random_state=42)	735	20	735	76	6058255671621224680
31	140	86	140	88	-5407992291015887288	processor(vtpredict, model, nprocessor=1, timeslice='auto', vis_slices=31,\n                         oversampling=4, facets=8, wstep=advice['w_sampling_primary_beam'])	140	15	141	91	8017141038555901416
31	164	88	164	90	-8379304838050618302	processor(vt, targetimage, timeslice='auto', padding=2, oversampling=4,\n                         facets=4, wstack=advice['w_sampling_primary_beam'], vis_slices=31,\n                         wstep=advice['w_sampling_primary_beam'])	163	15	165	65	618035739375703242
48	21	37	21	39	-3610948415934664716	plt.savefig('fig/plot_001A.png', dpi=48, transparent=True)	21	0	21	58	-4635916625875893230
48	91	43	91	45	-5388570883593508690	compareMortgages(amt=200000, years=30, fixedRate=0.07,\n                 pts = 3.25, ptsRate=0.05, varRate1=0.045,\n                 varRate2=0.095, varMonths=48)	89	0	91	46	8492541568633850261
400	20	28	20	31	-7871358715275783589	make_blobs(n_samples=400, centers=23, random_state=42)	20	7	20	61	8355410366299839104
400	50	22	50	25	-1577037412535213757	nx.draw(g, pos,\n            node_size=400, node_color=[colors[i]]*nx.number_of_nodes(g),\n            vmin=0.0, vmax=1.0, alpha=0.2,\n            with_labels=True)	49	4	52	29	4493933756514861035
400	50	28	50	31	2684229779418002921	tabla_SML['Edad'].hist(bins=400)	50	0	50	32	-3237957563616805075
400	58	32	58	35	7801398788963634048	make_blobs(n_samples=400, centers=23, random_state=42+n)	58	11	58	67	-5717479585512472059
400	68	16	68	19	7379818794946964235	Plot(\n    x_range=xdr,\n    y_range=ydr,\n    title="",\n    plot_width=800,\n    plot_height=400,\n    outline_line_color=None,\n    toolbar_location=None,\n)	63	7	71	1	-4586682221883798721
400	77	49	77	52	3106776428184135080	ax[1].hexbin(teff,mag,bins='log',gridsize=400,mincnt=1)	77	7	77	62	-3571683260291060670
400	89	90	89	93	8926297834199575173	np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)	89	33	89	94	-4178035205260011827
400	90	32	90	35	8958882345757907658	make_blobs(n_samples=400, centers=23, random_state=42+n)	90	11	90	67	-1413492864098101230
400	181	45	181	48	4788358507272406845	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	181	9	183	37	1022489683466815085
400	190	44	190	47	-5097324898215656655	bk.figure(title='Isomap - S-Curve', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=400)	189	6	190	48	5184953220000253137
400	202	44	202	47	3552347111175435051	bk.figure(title='LocallyLinearEmbedding - S-Curve', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=400)	201	6	202	48	7985347003410819607
400	278	47	278	50	7972681622807207903	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color2,\n               min_font_size=50, max_font_size=400)	276	5	278	51	6643972869516067525
400	305	45	305	48	-3306943133119041136	RandomForestClassifier(n_estimators=400,\n    random_state=0,\n    criterion='entropy', max_depth=5)	305	9	307	37	-4441842696448961912
400	453	23	453	26	7469147617806722190	nx.draw(J, node_size = 400, node_color='y')	453	0	453	43	5369813419990521035
400	470	16	470	19	-1370422276386026129	plt.hist2d((df_ambe['cs1']), (df_ambe['cs2bottom']/100),\n           bins=400, norm=matplotlib.colors.LogNorm(), range=([0,1000],[0,2000]))	469	0	470	81	1453929669075498313
400	488	86	488	89	1854429278870875054	ipyd.Image(url='vae_all_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=400, width=400)	488	0	488	101	-3403959933146162434
400	488	97	488	100	4800504059369539711	ipyd.Image(url='vae_all_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=400, width=400)	488	0	488	101	-3403959933146162434
70	40	20	40	22	2217892829159932496	plt.xticks(rotation=70)	40	0	40	23	5064637686528367010
70	59	20	59	22	1706265593342899176	plt.xticks(rotation=70)	59	0	59	23	-8697774447601132479
70	75	20	75	22	-8234726313649332945	plt.xticks(rotation=70)	75	0	75	23	-2822597361266191692
70	76	20	76	22	9175151376706374825	plt.xticks(rotation=70)	76	0	76	23	-692334271872882660
70	91	20	91	22	-4721423305663304948	plt.xticks(rotation=70)	91	0	91	23	6321896901543088864
70	92	20	92	22	2915075959278679935	plt.xticks(rotation=70)	92	0	92	23	-3001268332275431483
70	107	20	107	22	-7897039219993661611	plt.xticks(rotation=70)	107	0	107	23	-9211231602533539585
70	123	20	123	22	3297940469007290157	plt.xticks(rotation=70)	123	0	123	23	7541803426625648770
70	139	20	139	22	-5585879509120092851	plt.xticks(rotation=70)	139	0	139	23	-6952564052728547738
70	149	51	149	53	-8070225773059774036	ax[1].hist2d(vx,vy,bins=70,alpha=0,range=[[-120,120],[-120,60]])	149	27	149	91	-4634810491605689203
70	155	20	155	22	8645900955725179161	plt.xticks(rotation=70)	155	0	155	23	-157917487000385236
70	167	20	167	22	-5164548058704586325	plt.xticks(rotation=70)	167	0	167	23	-3808206969587727973
70	189	20	189	22	3009223314505848269	plt.xticks(rotation=70)	189	0	189	23	1713889736458317410
70	206	20	206	22	-3030395212842569481	plt.xticks(rotation=70)	206	0	206	23	-5326431875466127265
70	218	20	218	22	-3359705871542749240	plt.xticks(rotation=70)	218	0	218	23	-7304296884533823592
70	237	20	237	22	-1272381687743866518	plt.xticks(rotation=70)	237	0	237	23	2872245570098970631
70	254	20	254	22	-5558579526882610055	plt.xticks(rotation=70)	254	0	254	23	-8564749987432282754
70	266	20	266	22	3636744630477853794	plt.xticks(rotation=70)	266	0	266	23	-7270447645922096668
70	286	20	286	22	-3865659846770480242	plt.xticks(rotation=70)	286	0	286	23	1457881328966674370
70	303	20	303	22	7793528927372007681	plt.xticks(rotation=70)	303	0	303	23	-2624666410404663536
70	315	20	315	22	9169847419421634885	plt.xticks(rotation=70)	315	0	315	23	6110420712074629320
70	335	20	335	22	-1001038556614215867	plt.xticks(rotation=70)	335	0	335	23	-2308196786572190010
70	352	20	352	22	-4755171705616262735	plt.xticks(rotation=70)	352	0	352	23	7067393933664147982
70	363	20	363	22	7371713962021788958	plt.xticks(rotation=70)	363	0	363	23	-8631097938302344278
70	383	20	383	22	2527981247422019770	plt.xticks(rotation=70)	383	0	383	23	8100304121769719637
70	400	20	400	22	5382760976939781611	plt.xticks(rotation=70)	400	0	400	23	7347528691331399476
70	411	20	411	22	-392760328025634895	plt.xticks(rotation=70)	411	0	411	23	-7226892850405338903
70	421	51	421	53	-6011741140022312693	fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n                              color=True, funneled=False, slice_=None,\n                              download_if_missing=False)	421	13	423	56	793348033059461343
70	433	20	433	22	7666960178726305321	plt.xticks(rotation=70)	433	0	433	23	6170029037420853629
70	450	20	450	22	2948742026001398229	plt.xticks(rotation=70)	450	0	450	23	427541156491641206
70	462	20	462	22	7889736233551974234	plt.xticks(rotation=70)	462	0	462	23	-3727437613976600648
70	487	24	487	26	8705733650052870211	plt.xticks(rotation=70)	487	4	487	27	-7307630267301888804
70	502	24	502	26	-6920157782538220426	plt.xticks(rotation=70)	502	4	502	27	8326835839258340559
70	511	24	511	26	-2320063749768985670	plt.xticks(rotation=70)	511	4	511	27	4567924463341875415
70	534	26	534	28	6774692639453203276	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
70	711	58	711	60	-1155516841991365988	ax.set_xticklabels(feature_names[important], rotation=70, ha="right")	711	4	711	73	3091097178794943162
70	732	63	732	65	5409503332041902621	ax.set_xticklabels(feature_names[important_coef], rotation=70, ha="right")	732	4	732	78	-7538071421547629250
70	1065	63	1065	65	-4569130349428297405	ax.set_xticklabels(feature_names[important_coef], rotation=70, ha="right")	1065	4	1065	78	3559093274166004709
200000	26	48	26	54	5627240031144469692	fa.train(X, Y, learning_rate=0.05, n_epochs=200000, report_frequency=200000)	26	4	26	80	-4997663746917800461
200000	26	73	26	79	7566656423456793345	fa.train(X, Y, learning_rate=0.05, n_epochs=200000, report_frequency=200000)	26	4	26	80	-4997663746917800461
200000	50	48	50	54	2414169188882182806	fa.train(X, Y, learning_rate=0.05, n_epochs=200000, report_frequency=200000)	50	4	50	80	2310228572878479589
200000	50	73	50	79	5409457029936771433	fa.train(X, Y, learning_rate=0.05, n_epochs=200000, report_frequency=200000)	50	4	50	80	2310228572878479589
200000	79	70	79	76	-6759684539051447969	fa.train(X, Y, learning_rate=0.05, n_epochs=2000000, report_frequency=200000)	79	0	79	77	8546719768092812509
200000	89	21	89	27	-6919823858527271469	compareMortgages(amt=200000, years=30, fixedRate=0.07,\n                 pts = 3.25, ptsRate=0.05, varRate1=0.045,\n                 varRate2=0.095, varMonths=48)	89	0	91	46	8492541568633850261
200000	95	60	95	66	-1778021975260374601	TfidfVectorizer(max_df=0.8, max_features=200000,\n                                 min_df=0.01, stop_words='english',\n                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))	95	19	97	94	-252283597117808196
200000	100	70	100	76	-959333767385824999	fa.train(X, Y, learning_rate=0.05, n_epochs=2000000, report_frequency=200000, lambda_l2=0.005)	100	0	100	94	-8071703370381615530
2000	20	40	20	44	6718979252162528327	hc.sample.df_timeseries(N=3, Nb_bd=2000)	20	5	20	45	-199428737668036561
2000	56	59	56	63	791916967751929473	solver.change_settings(learning_rate=0.01,num_episodes=2000)	56	4	56	64	8510917969280408156
2000	128	73	128	77	5054151873429380823	nc1.train(learning_rate=0.1, n_epochs=40000,\n              X_train=X3, Y_train=Y3, batch_size=len(Y), print_frequency=2000,\n              n_in=2, n_out=2, n_hidden=i, n_layers=2)	127	4	129	54	-3621392733447045574
2000	155	73	155	77	9035986750024396143	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
2000	164	73	164	77	2244590724957587320	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
2000	252	56	252	60	1084959477012057565	np.random.choice(np.arange(10000), size=2000)	252	16	252	61	5992765920158704345
2000	441	48	441	52	-5496672023173048854	decision_tree_create(train_data, features, 'safe_loans', max_depth = 6,\n                                min_node_size = 2000, min_error_reduction=-1)	440	10	441	77	6130476014748318774
2000	533	27	533	31	3642027815311155235	fit1((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1,cutoff=0.2)	533	0	533	71	1551108491435502961
2000	543	27	543	31	-1161129733863007002	fit2((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1,cutoff=0.2)	543	0	543	71	7075271638523091699
2000	555	29	555	33	-2023840661657561710	fit((xdataR,ydataR),itr = 2000, alpha=1.0, xmin=-3, xmax=1, cutoff=0.2)	555	0	555	74	-3109979336477302602
90	9	14	9	16	2306766218053663532	text(.5,0,'''\nSPEED\nLIMIT\n$\int^{28}_{27}\!f(2x)\mathrm{d}x$\n''', fontsize=90,\n     name='Arial Black',\n     horizontalalignment='center')	6	0	11	34	685571110457719964
90	66	62	66	64	6728581858450307713	plt.xticks(range(len(sorted_values)),sorted_keys,rotation=90)	66	4	66	65	-48434910690690936
90	100	87	100	89	-3040676700235700963	widgets.Checkbox(description = text.value, value=True, width=90)	100	26	100	90	-5567303873153720787
90	121	52	121	54	878557329861075715	plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)	121	0	121	67	-3934763009691706448
90	157	52	157	54	-8497028658585270395	plt.xticks(range(len(list_fams)),list_fams,rotation=90,fontsize=10)	157	0	157	67	5392588869502803694
90	219	50	219	52	3468252093159650221	plt.pie(np.random.random(4), labels=['Dogs', 'Cats', 'Rabbits', 'Bats'], colors=['c', 'r', 'y', 'g'],\n       autopct='%1.1f%%', shadow=True, startangle=90)	218	0	219	53	-9046746995105994053
90	236	13	236	15	4521991739503080165	dict(s=90, linewidth=.5, alpha = .5)	236	6	236	42	-1849114809217313834
90	246	75	246	77	-7154407497337567991	plt.pie(sizes, autopct='%1.0f%%', colors=colors, labels=labels, startangle=90)	246	0	246	78	-4503575103052388927
90	259	50	259	52	3662390095924769354	plt.pie(np.random.random(4), labels=['Dogs', 'Cats', 'Rabbits', 'Bats'], colors=['c', 'r', 'y', 'g'],\n       autopct='%1.1f%%', shadow=True, startangle=90)	258	5	259	53	2080607901957168883
90	456	20	456	22	1558731279381042018	plt.xticks(rotation=90)	456	0	456	23	-3601608151634867470
90	490	72	490	74	2824680560589152069	ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=12, rotation=90)	490	4	490	75	-9220869846897449587
90	503	72	503	74	2773498631773623040	ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14, rotation=90)	503	4	503	75	3688606664776194700
90	520	33	520	35	-5760315992926080804	p.set_xticklabels(labs, rotation=90)	520	0	520	36	1584129020195260875
90	527	33	527	35	6423407616527537841	p.set_xticklabels(labs, rotation=90)	527	0	527	36	-2701374870247782690
90	639	33	639	35	-2033136920932307362	p.set_xticklabels(labs, rotation=90)	639	0	639	36	3071914190150501317
90	685	33	685	35	8225138517483801400	p.set_xticklabels(labs, rotation=90)	685	0	685	36	-3202809804735210034
55	534	68	534	70	-2441014444458152987	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
55	1121	65	1121	67	8269100614568452314	gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)	1121	8	1121	68	-5755679163829373569
99	50	49	50	51	5123795127758499473	sns.heatmap(pcts, annot=True, linewidth=.1, vmax=99, fmt='.1f', cmap='YlOrRd', square=True, cbar=False)	50	0	50	103	9162575895907239222
99	75	42	75	44	-735194657849510599	sns.heatmap(percentiles, vmin=1, vmax=99, annot=True)	75	4	75	57	6796659196746609956
99	339	49	339	51	-4995419667412498807	sns.heatmap(pcts, annot=True, linewidth=.1, vmax=99, fmt='.1f', cmap='YlOrRd', square=True, cbar=False)	339	0	339	103	-552790262429311197
144	93	14	93	17	-3495229957280138313	ax.scatter(x, resid[group.index], marker=symbols[j], color=colors[i-1],\n            s=144, edgecolors='black')	92	4	93	38	-705751883367113610
144	159	14	159	17	5718890913831761330	ax.scatter(X[idx], resid[idx], marker=symbols[j], color=colors[i-1],\n            s=144, edgecolors='black')	158	4	159	38	-9125337996187553712
144	214	14	214	17	7056692937753745011	ax.scatter(X[idx], resid[idx], marker=symbols[j], color=colors[i-1],\n            s=144, edgecolors='black')	213	4	214	38	-8843196308927915146
144	231	14	231	17	-1342992967626325923	ax.scatter(X[idx], S[idx], marker=symbols[j], color=colors[i-1],\n            s=144, edgecolors='black')	230	4	231	38	2300180074666565778
1000000	59	76	59	83	847432136982540794	c.search_reads(read_group_ids=[read_group.id], start=0, end=1000000, reference_id=reference.id)	59	16	59	111	710237981902430416
2000000	79	44	79	51	-1499135306636260992	fa.train(X, Y, learning_rate=0.05, n_epochs=2000000, report_frequency=200000)	79	0	79	77	8546719768092812509
2000000	100	44	100	51	-2533216411812799765	fa.train(X, Y, learning_rate=0.05, n_epochs=2000000, report_frequency=200000, lambda_l2=0.005)	100	0	100	94	-8071703370381615530
123	77	50	77	53	673459705237860713	FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n                            weight_scale=5e-2, dtype=np.float64,\n                            dropout=dropout, seed=123)	75	10	77	54	6563878305222964934
123	119	95	119	98	-2514980474659381932	train_test_split(train_x, train_y, test_size=0.2,random_state=123)	119	33	119	99	-6511791614895058197
123	127	62	127	65	8936032880293226784	RandomForestClassifier(criterion='entropy', n_estimators=500,\n                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n                            max_features='auto', random_state=123, n_jobs=1)	125	5	127	76	3605409359274810544
123	138	85	138	88	4225398665750985967	StratifiedShuffleSplit(train_y, n_iter=10, test_size=0.2,\n                                                       train_size=None, random_state=123)	137	32	138	89	-7420353396887594154
700	23	28	23	31	4494084719464872441	Image("img/spot.png", width=700)	23	0	23	32	-6763617305366521770
700	213	22	213	25	1163306303782057876	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color,\n               min_font_size=50, max_font_size=350)	212	5	214	51	-4958717031281068490
700	245	22	245	25	945061664873247452	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=300)	244	5	246	51	-8881443613552388378
700	277	22	277	25	-909933582142129444	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color2,\n               min_font_size=50, max_font_size=400)	276	5	278	51	6643972869516067525
700	310	22	310	25	7082248673311878676	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=200)	309	5	311	51	1806039752936675104
241	21	33	21	36	7314961910852254877	SVC(C=100000, random_state=241, kernel="linear")	21	6	21	54	-5000556258995571724
241	56	42	56	45	778962404313279711	DecisionTreeClassifier(random_state=241)	56	6	56	46	-1047089349821697196
241	62	57	62	60	5951580732038237542	KFold(y.size, n_folds=5, shuffle=True, random_state=241)	62	5	62	61	4943645416325930024
241	63	40	63	43	-2257606728442377740	SVC(kernel='linear', random_state=241)	63	6	63	44	486420470306151797
3000	319	49	319	53	7886952025527924033	deepdream(img_pre, 7, model, learning_rate=3000)	319	6	319	54	5784514901793064220
250	14	66	14	69	-2261454365727165897	Image(filename = 'figures/drawing_tree_conductivity.png', width = 250)	14	0	14	70	1560343733787973471
250	100	67	100	70	-484252622532044172	GradientBoostingClassifier(learning_rate=0.005, n_estimators=250,\n                                max_depth=10, subsample=0.5,\n                                max_features=0.5)	100	6	102	49	6862921282232108663
54	492	92	492	94	8483854094074205238	get_images('train/digitStruct_train.csv', './train/', height=54, width=54, crop=0)	492	31	492	113	4949278090222586280
54	492	102	492	104	-6629828231759349131	get_images('train/digitStruct_train.csv', './train/', height=54, width=54, crop=0)	492	31	492	113	4949278090222586280
54	493	88	493	90	7096600116463150260	get_images('test/digitStruct_test.csv', './test/', height=54, width=54, crop=0)	493	30	493	109	7140907702625357988
54	493	98	493	100	2681037059731328591	get_images('test/digitStruct_test.csv', './test/', height=54, width=54, crop=0)	493	30	493	109	7140907702625357988
3826	177	46	177	50	-8846247777750486608	section_data_df.to_crs(epsg=3826)	177	18	177	51	-2075783566484144626
3826	181	45	181	49	-2166931125115257067	start.to_crs(epsg=3826)	181	27	181	50	7603866323349447071
3826	185	41	185	45	-3570835274272138946	end.to_crs(epsg=3826)	185	25	185	46	3474586103797511157
160	96	24	96	27	4029126206951272672	np.random.seed(seed=160)	96	4	96	28	4089610251814797898
160	101	28	101	31	-3741899048006765293	np.random.seed(seed=160)	101	8	101	32	-6548799965594407857
1024	44	47	44	51	-3036586653815305165	r.iter_content(chunk_size=1024)	44	21	44	52	6937964559993426893
1024	87	93	87	97	-6348849761846490111	Camera(f=0.200, fstop=3.0, well=100., pixel_size=9e-6, width=1536, height=1024)	87	19	87	98	530998612573433807
1024	88	98	88	102	7556003521977316826	Camera(f=0.200, fstop=1.8, well=100., pixel_size=9e-6, width=1536, height=1024)	88	24	88	103	-3586754298781349461
1024	168	40	168	44	6934171127609880400	fc_layer(h_pool5, name='fc1',\n                         n_output_units=1024,  ## original: 4096\n                         dropout=self.keep_prob_fc1,\n                         activation_fn=tf.nn.relu)	167	16	170	50	2682225928590612672
1024	175	40	175	44	2551016548223057227	fc_layer(h_fc1, name='fc2',\n                         n_output_units=1024, ## original: 4096\n                         dropout=self.keep_prob_fc2,\n                         activation_fn=tf.nn.relu)	174	16	177	50	1419526141602092171
5001	22	41	22	45	-6699600444846476016	nx.gnp_random_graph(100 , 0.05, seed=5001)	22	4	22	46	286204876508562180
2118982	12	50	12	57	2703198964732129247	Binomial('data', n=4138349, p=theta, value=2118982, observed=True)	12	7	12	73	-9186132424357833232
4138349	12	26	12	33	-468186850728959721	Binomial('data', n=4138349, p=theta, value=2118982, observed=True)	12	7	12	73	-9186132424357833232
227	365	94	365	97	-8470903208296819925	predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value = 227)	365	24	365	98	-8900614331285295316
227	409	94	409	97	6696586421410817335	predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value = 227)	409	24	409	98	1594306808600678904
140	72	54	72	57	3559221063011609161	Basemap(projection='ortho', lat_0=-30, lon_0=140,\n              resolution='l', area_thresh=1000.0)	72	9	73	49	-7805623395759372296
140	90	54	90	57	6086322917403337544	Basemap(projection='robin', lat_0=-30, lon_0=140,\n              resolution='l', area_thresh=1000.0)	90	9	91	49	-8250135261069140982
140	256	56	256	59	6217188059808837322	Basemap(projection='robin', lat_0=-30, lon_0=140,\n              resolution='l', area_thresh=1000.0)	256	11	257	49	-8567923485175013727
140	316	54	316	57	-8846801943569051125	Basemap(projection='robin', lat_0=-30, lon_0=140,\n              resolution='l', area_thresh=1000.0)	316	9	317	49	6115860359137629720
140	335	54	335	57	-3119417385715787879	Basemap(projection='robin', lat_0=-30, lon_0=140,\n              resolution='l', area_thresh=1000.0)	335	9	336	49	-3114221510594352566
140	534	53	534	56	5856783422607763581	Basemap(projection='merc', resolution = 'l', area_thresh = 1000.0,\n                lat_0=0, lon_0=120,\n                llcrnrlon=70, llcrnrlat=0, urcrnrlon=140, urcrnrlat=55)	532	9	534	71	-7053989446755775180
450	225	44	225	47	1223372347250794174	bk.figure(title='t-SNE - digits dataset', x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=450)	224	6	225	48	8136380298158223913
650	148	46	148	49	-6966573079320044744	ax[1].hexbin(vx,vy,bins='log',gridsize=650,mincnt=1)	148	7	148	59	-6545072670191545726
1600	213	33	213	37	2533014640301678807	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color,\n               min_font_size=50, max_font_size=350)	212	5	214	51	-4958717031281068490
1600	245	33	245	37	-4206230123015555128	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=300)	244	5	246	51	-8881443613552388378
1600	277	33	277	37	-6721136729566337151	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=single_color2,\n               min_font_size=50, max_font_size=400)	276	5	278	51	6643972869516067525
1600	310	33	310	37	-5764090017927958163	WordCloud(relative_scaling=0.7, prefer_horizontal=1.0, background_color="white",\n               height=700, width=1600, font_path=font, color_func=topic59_color,\n               min_font_size=40, max_font_size=200)	309	5	311	51	1806039752936675104
270	60	55	60	58	7976192929781470598	plt.colorbar().set_label('Signal (arb.)', rotation=270, verticalalignment='center', fontsize=14)	60	4	60	100	6511050812760249285
270	65	60	65	63	6355208627896303046	plt.colorbar().set_label('Standard Deviation', rotation=270, verticalalignment='center', fontsize=14)	65	4	65	105	2911667611248753965
270	70	45	70	48	7891972419566035749	plt.colorbar().set_label('SNR', rotation=270, verticalalignment='center', fontsize=14)	70	4	70	90	2422333462333185356
270	75	55	75	58	1994685298121424727	plt.colorbar().set_label('Signal (arb.)', rotation=270, verticalalignment='center', fontsize=14)	75	4	75	100	6875132002801552063
270	80	45	80	48	-7504466657648079868	plt.colorbar().set_label('SNR', rotation=270, verticalalignment='center', fontsize=14)	80	4	80	90	-5102735535965125224
441	34	438	34	441	955492868457179337	hax.init(experiment="XENON100", main_data_paths = ['/cfs/klemming/nobackup/w/wittweg/','/cfs/klemming/nobackup/w/wittweg/Co60/', '/cfs/klemming/projects/xenon/xenon100/processed/pax_v4.4.0/run_10/', '/cfs/klemming/projects/xenon/xenon100/root/pax441/run_10','/cfs/klemming/projects/xenon/xenon100/root/pax441/run_10','/cfs/klemming/projects/xenon/xenon100/processed/pax_v4.4.0/run_10/'], pax_version_policy='loose', old_pax_class_version=441, old_pax_classes_dir = '/cfs/klemming/nobackup/w/wittweg/hax_notebooks')	34	0	34	514	-5986098632633813510
187	380	27	380	30	-6416704451673443087	FastICA(n_components=187)	380	6	380	31	9155493339831511794
4096	180	79	180	83	3153449882901804879	vgg16.vgg16(imgs, numClasses = 1000, isPreprocessed = False, fc_size=4096)	180	10	180	84	2527019013000777942
72	77	38	77	40	6333410901453192105	plt.savefig("plot_example.png", dpi = 72)	77	0	77	41	9142808768905903336
72	376	83	376	85	5815716263525711889	plt.savefig("fig/style_{:s}.png".format(temp_style), transparent=True, dpi=72)	376	8	376	86	-2684571511430458781
72	387	72	387	74	8334172642026910949	plt.savefig("fig/imshow_{:s}.png".format(cm), transparent=True, dpi=72)	387	4	387	75	4231160659789877655
6000	312	14	312	18	-7488909837458185869	plt.ylim(ymax=6000)	312	0	312	19	-213604255437661937
310	59	44	59	47	6445809436112950556	fig.gca(projection='3d', elev=30, azim=310)	59	5	59	48	5626966996232317333
6379	22	45	22	49	-2923961738411190439	redis.StrictRedis(host='localhost', port=6379, db=1)	22	4	22	56	7569286207406513812
760	38	44	38	47	-2050543223103127431	ig.imagegrid_figure(images=[ digits.images[i][::-1, :] for i in range(num_imgs) ],\n                          text=[ str(digits.target[i]) for i in range(num_imgs) ],\n                          figure_title=None, palette=Greys9[::-1],\n                          figure_plot_width=760, figure_plot_height=600,\n                          text_color='red', padding=0.1,\n                          grid_size=(10, 8))	35	6	40	44	1931467805568606249
390	27	21	27	24	7904962735300278460	ax.view_init( azim = 390)	27	0	27	25	-8389834550115779011
390	50	21	50	24	8152971606599220669	ax.view_init( azim = 390)	50	0	50	25	-5580492889281886359
240	4	43	4	46	-587876040531102294	Image(filename='figures/IHCP.png', width = 240)	4	0	4	47	8822791626535046902
40000	127	42	127	47	2804550428720609317	nc1.train(learning_rate=0.1, n_epochs=40000,\n              X_train=X3, Y_train=Y3, batch_size=len(Y), print_frequency=2000,\n              n_in=2, n_out=2, n_hidden=i, n_layers=2)	127	4	129	54	-3621392733447045574
40000	154	38	154	43	3584782143464633223	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=1, n_layers=2)	154	0	156	50	8040540417472743758
40000	163	38	163	43	1203723289107934956	nc2.train(learning_rate=0.1, n_epochs=40000,\n          X_train=Xproj, Y_train=Y3, batch_size=len(Y3), print_frequency=2000,\n          n_in=4, n_out=2, n_hidden=5, n_layers=2)	163	0	165	50	1308828550627967189
340	134	35	134	38	3832166973195541871	bk.figure(title="n_neighbors = %d" % (i+2),\n                        plot_width=340, plot_height=300)	133	14	134	56	-9101895811456257852
560	71	44	71	47	-3736326685562317827	bk.figure(title='PCA Projection - digits dataset',\n                x_axis_label='c1', y_axis_label='c2',\n                plot_width=750, plot_height=560)	69	6	71	48	-3286209521089249655
96	29	33	29	35	-5640991119109671267	savefig('fig/plot_001B.png', dpi=96, transparent=True)	29	0	29	54	4862476532997284885
96	38	29	38	31	6137909410774282153	savefig('plot_001C.png', dpi=96, transparent=True)	38	0	38	50	-4866915233669438826
96	50	37	50	39	8995203024237548235	plt.savefig('fig/plot_001D.png', dpi=96, transparent=True)	50	0	50	58	-3833073160879445346
96	58	37	58	39	3277007905385780577	plt.savefig('fig/plot_001E.png', dpi=96, transparent=True)	58	0	58	58	-9199254315600703306
96	66	37	66	39	-671164771595851849	plt.savefig('fig/plot_001F.png', dpi=96, transparent=True)	66	0	66	58	-1706770367256883502
96	78	55	78	57	5187028659547131158	plt.savefig("fig/plot_002A.png", transparent=True, dpi=96)	78	0	78	58	-8360170370844177228
96	86	55	86	57	-440885846308625398	plt.savefig("fig/plot_002B.png", transparent=True, dpi=96)	86	0	86	58	-4303065637653569640
96	94	55	94	57	2999289573692467196	plt.savefig("fig/plot_002C.png", transparent=True, dpi=96)	94	0	94	58	2236729740684257868
96	105	55	105	57	5776592005233864650	plt.savefig("fig/plot_002D.png", transparent=True, dpi=96)	105	0	105	58	4837580861169459126
96	118	55	118	57	945648697512461738	plt.savefig("fig/plot_002E.png", transparent=True, dpi=96)	118	0	118	58	-483198658837795964
96	129	55	129	57	5925050557008803127	plt.savefig("fig/plot_002F.png", transparent=True, dpi=96)	129	0	129	58	1938252690504265624
96	141	55	141	57	1522912845775185917	plt.savefig("fig/plot_002F.png", transparent=True, dpi=96)	141	0	141	58	-211996787568084895
96	155	55	155	57	4507905839258259796	plt.savefig("fig/plot_002G.png", transparent=True, dpi=96)	155	0	155	58	8547223982583929114
96	170	55	170	57	6975198661418069066	plt.savefig("fig/plot_002H.png", transparent=True, dpi=96)	170	0	170	58	-429552542552951328
96	215	56	215	58	2970442135983857417	plt.savefig("fig/ex_scatter.png", transparent=True, dpi=96)	215	0	215	59	-7446851068475675694
18607	714	48	714	53	-78477263643006708	df_notinjured.sample(n=18607)	714	25	714	54	2633124473801319924
2016	116	114	116	118	1533827096364716856	train_test_split(new_data,data['Detergents_Paper'],test_size=0.25,random_state=2016)	116	35	116	119	496863099454677273
2016	119	47	119	51	-5060217566426099615	DecisionTreeRegressor(random_state=2016)	119	12	119	52	-887381721742556123
1536	87	80	87	84	-7696025521123013367	Camera(f=0.200, fstop=3.0, well=100., pixel_size=9e-6, width=1536, height=1024)	87	19	87	98	530998612573433807
1536	88	85	88	89	3898223018905802541	Camera(f=0.200, fstop=1.8, well=100., pixel_size=9e-6, width=1536, height=1024)	88	24	88	103	-3586754298781349461
753	358	71	358	74	4048670421167160722	results_ARIMA.predict(start = p + q - 1, end= 753, dynamic= True)	358	25	358	90	6761248307001479150
432542	129	56	129	62	-577918653942696587	fetch_olivetti_faces(shuffle=True, random_state=432542)	129	8	129	63	-3815613973248541019
8080	9	27	9	31	-928412044755009194	run(host='localhost', port=8080, debug=True)	9	0	9	44	8433043271378547300
500000	84	84	84	90	-7883550746354405641	method(0.5,start_lambda, max_number_iterations=500000)	84	37	84	91	-1177887209665706381
500000	85	85	85	91	4876524424954566016	method(0.2,start_lambda, max_number_iterations=500000)	85	38	85	92	6701234338217226703
500000	86	87	86	93	-3992824710482631436	method(0.25,start_lambda, max_number_iterations=500000)	86	39	86	94	-3663478439321462085
316	82	30	82	33	5678348194685583026	SVC(C= 316)	82	23	82	34	-5235494340280589748
6001	293	36	293	40	7119767083022701236	np.linspace(0, 6000, num=6001, endpoint=True)	293	11	293	56	-8048338818284700552
45000	98	53	98	58	-8309804560960523020	CIFAR10(which_set='train', start=0, stop=45000)	98	12	98	59	-4460895166963593108
3232	124	87	124	91	-4458199764937207409	Camera(f=0.050, fstop=1.2, well=44., pixel_size=7.4e-6, width=3232, height=4864)	124	25	124	105	-4453073329800210902
3232	132	88	132	92	3711051743378904915	Camera(f=0.135, fstop=2.0, well=44., pixel_size=7.4e-6, width=3232, height=4864)	132	26	132	106	-8738920563441244989
3232	138	92	138	96	-3803871740349835239	Camera(f=0.200, fstop=2.8, well=44., pixel_size=7.4e-6, width=3232, height=4864)	138	30	138	110	-1006356240051504785
3232	144	92	144	96	2375516831919528959	Camera(f=0.200, fstop=2.0, well=44., pixel_size=7.4e-6, width=3232, height=4864)	144	30	144	110	8527976949267406311
4864	124	100	124	104	-765446272386415124	Camera(f=0.050, fstop=1.2, well=44., pixel_size=7.4e-6, width=3232, height=4864)	124	25	124	105	-4453073329800210902
4864	132	101	132	105	8261667350233430178	Camera(f=0.135, fstop=2.0, well=44., pixel_size=7.4e-6, width=3232, height=4864)	132	26	132	106	-8738920563441244989
4864	138	105	138	109	-2188114053967481938	Camera(f=0.200, fstop=2.8, well=44., pixel_size=7.4e-6, width=3232, height=4864)	138	30	138	110	-1006356240051504785
4864	144	105	144	109	-8079466509548485676	Camera(f=0.200, fstop=2.0, well=44., pixel_size=7.4e-6, width=3232, height=4864)	144	30	144	110	8527976949267406311
===============
